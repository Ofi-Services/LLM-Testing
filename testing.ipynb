{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from db_create import CargaDeArchivos\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "a= CargaDeArchivos()\n",
    "a.run_carga()\n",
    "db_conn= a.conn\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the workflow, including the question, schema, database connection,\n",
    "    relevance, SQL query, query result, and other metadata.\n",
    "    \"\"\"\n",
    "    original_question: str\n",
    "    questions: List[str] = []\n",
    "    db_conn: None\n",
    "    relevance: str\n",
    "    sql_querys: List[str] = []\n",
    "    query_results: List[str] = []\n",
    "    sql_error: List[bool]= []\n",
    "    final_answer: str\n",
    "    attempts: int\n",
    "    chat_history: List[str] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relevance(state: State):\n",
    "    \"\"\"\n",
    "    Determines whether the user's question is relevant to the database schema.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with relevance information.\n",
    "    \"\"\"\n",
    "    question = state[\"original_question\"]\n",
    "    print(f\"Checking relevance of the question: {question}\")\n",
    "\n",
    "    # Retrieve chat history\n",
    "    chat_history_entries = state.get(\"chat_history\", [])\n",
    "    \n",
    "    chat_history= relevant_entries(chat_history_entries)  # Get the last 3 relevant entries\n",
    "    print(f\"Chat history for relevance check:\\n{chat_history}\")\n",
    "    # System prompt including instructions on chat history usage\n",
    "    system = f\"\"\"\n",
    "    You are an assistant that determines whether a given question is related to querying the following database schema.\n",
    "    A question is considered **relevant** only if it is structured in a way that could be used to extract data from the database.\n",
    "    \n",
    "    General conversations, greetings, and small talk are **not relevant**, even if they contain words related to business or databases.\n",
    "\n",
    "    ### **How to Use Chat History:**\n",
    "    - If the user's question is a **follow-up to a previous relevant question**, consider it relevant if it maintains the context.\n",
    "    - If the conversation was **not relevant before**, and the new question is vague or generic, it remains **not relevant**.\n",
    "    - Do **not** assume relevance unless the question clearly indicates a database query.\n",
    "\n",
    "    ### **Database Schema**  \n",
    "    #### Table: \"cases\"\n",
    "    - \"id\" (VARCHAR): Primary key.\n",
    "    - \"insurance\" (BIGINT): Foreign key to insurance.\n",
    "    - \"avg_time\" (DOUBLE): Duration (seconds) from case initiation to closure.\n",
    "    - \"type\" (VARCHAR): Insurance category.\n",
    "    - \"branch\" (VARCHAR): Policy branch.\n",
    "    - \"ramo\" (VARCHAR): Coverage type.\n",
    "    - \"broker\" (VARCHAR): Broker for the policy.\n",
    "    - \"state\" (VARCHAR): Current case state.\n",
    "    - \"client\" (VARCHAR): Client who bought the insurance.\n",
    "    - \"creator\" (VARCHAR): Employee managing the case.\n",
    "    - \"value\" (BIGINT): Insurance monetary value.\n",
    "    - \"approved\" (BOOLEAN): TRUE if approved, else FALSE.\n",
    "    - \"insurance_creation\" (TIMESTAMP_NS): Policy creation timestamp.\n",
    "    - \"insurance_start\" (TIMESTAMP_NS): Coverage start timestamp.\n",
    "    - \"insurance_end\" (TIMESTAMP_NS): Coverage end timestamp.\n",
    "\n",
    "    #### Table: \"activity\"\n",
    "    - \"id\" (BIGINT): Primary key.\n",
    "    - \"case\" (VARCHAR): Foreign key to \"cases\".\"id\".\n",
    "    - \"timestamp\" (TIMESTAMP_NS): Activity timestamp.\n",
    "    - \"name\" (VARCHAR): Name of the activity.\n",
    "    - \"case_index\" (BIGINT): Alias for \"id\".\n",
    "    - \"tpt\" (DOUBLE): Activity duration (seconds).\n",
    "\n",
    "    ### **Relevance Criteria:**\n",
    "    - **A question is considered \"relevant\" if it directly pertains to querying this database schema** for activities, cases, durations, business insights, or other process analysis concepts.\n",
    "    - Questions about **business insights** (e.g., client revenue, broker performance, policy value trends) are relevant.\n",
    "    - If a question **cannot reasonably be translated into a database query**, it is **not relevant**.\n",
    "    - **Common greetings, casual conversation, and generic inquiries (e.g., \"How are you?\" or \"What‚Äôs the weather today?\") are strictly \"not_relevant\"**, even if they contain business-related words.\n",
    "\n",
    "    ### **Chat History (Last Exchanges):**  \n",
    "    {chat_history}\n",
    "\n",
    "    ### **Response Format (STRICT)**\n",
    "    - Respond **ONLY** with one of the following two words:  \n",
    "      - `\"relevant\"`  \n",
    "      - `\"not_relevant\"`  \n",
    "    - Do **NOT** include explanations, variations, or any other text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the human prompt with the user's question\n",
    "    human = f\"Question: {question}\"\n",
    "\n",
    "    # Create a prompt template for the LLM\n",
    "    check_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Invoke the LLM to determine relevance\n",
    "    llm = OllamaLLM(model=\"mistral:latest\", temperature=0.0)\n",
    "    relevance_checker = check_prompt | llm\n",
    "    response = relevance_checker.invoke({}).strip().lower()\n",
    "\n",
    "    # Validate the response to ensure it matches expected outputs\n",
    "    if response not in [\"relevant\", \"not_relevant\"]:\n",
    "        raise ValueError(f\"Unexpected relevance response: {response}\")\n",
    "\n",
    "    # Update the state with the relevance result\n",
    "    state[\"relevance\"] = response\n",
    "    state[\"attempts\"] = 0\n",
    "    print(f\"Relevance determined: {state['relevance']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def reformat_question(state: State):\n",
    "    \"\"\"\n",
    "    Reformats vague follow-ups to be self-contained and \n",
    "    decomposes complex questions into fully-contained sub-questions.\n",
    "    \n",
    "    Args:\n",
    "        state (Dict): Current workflow state.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Updated state with a structured question output.\n",
    "    \"\"\"\n",
    "    original_question = state[\"original_question\"]\n",
    "    # Retrieve chat history\n",
    "    chat_history_entries = state.get(\"chat_history\", [])\n",
    "    \n",
    "    chat_history= relevant_entries(chat_history_entries)  # Get the last 3 relevant entries\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are a business-focused assistant specializing in process mining.\n",
    "    \n",
    "    ### Task 1: **Reformat Vague Questions**\n",
    "    If the user's question references previous messages (e.g., \"And cases?\" or \"What about those?\"),\n",
    "    rewrite it to be fully understandable **without extra context**.\n",
    "\n",
    "    ### Task 2: **Decompose Complex Questions**\n",
    "    If the question contains multiple aspects (e.g., \"How many activities, cases, and users exist?\"),\n",
    "    **split it into fully self-contained sub-questions.**\n",
    "    \n",
    "    ### Chat History (for vague question resolution):\n",
    "    {chat_history}\n",
    "\n",
    "    **Response Format:**\n",
    "    If the question is clear and singular, return it unchanged.\n",
    "    If it needs decomposition, return JSON:\n",
    "    {{\n",
    "      \"sub_questions\": [\"First question?\", \"Second question?\", ...]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    llm = OllamaLLM(model=\"mistral:latest\", temperature=0.1)  \n",
    "\n",
    "    reformat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"User's question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    reformatter = reformat_prompt | llm\n",
    "    result = reformatter.invoke({\"question\": original_question, \"chat_history\": chat_history})\n",
    "\n",
    "    # Try parsing JSON if decomposition is detected\n",
    "    try:\n",
    "        import json\n",
    "        parsed_result = json.loads(result)\n",
    "        if \"sub_questions\" in parsed_result:\n",
    "            state[\"questions\"] = parsed_result[\"sub_questions\"]  # Store list of sub-questions\n",
    "        else:\n",
    "            state[\"questions\"] = result.strip()  # Store single reformatted question\n",
    "    except json.JSONDecodeError:\n",
    "        state[\"questions\"] = result.strip()  # Store as plain text if no JSON structure\n",
    "\n",
    "    print(f\"Processed Question(s): {state['questions']}\")\n",
    "\n",
    "    return state\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "def convert_nl_to_sql(state: State):\n",
    "    \"\"\"\n",
    "    Converts a natural language question into an SQL query based on the database schema.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the generated SQL query.\n",
    "    \"\"\"\n",
    "    questions = state[\"questions\"]\n",
    "    ##PROMPT FOR SQL GENERATION\n",
    "    system = \"\"\"\n",
    "    You are an SQL assistant specialized in DuckDB. Your task is to generate accurate SQL queries based on natural language questions, following the provided schema.\n",
    "\n",
    "    ### Database Schema  \n",
    "    #### Table: \"cases\"\n",
    "    - \"id\" (VARCHAR): Primary key.\n",
    "    - \"insurance\" (BIGINT): Foreign key to insurance.\n",
    "    - \"avg_time\" (DOUBLE): Duration (seconds) from case initiation to closure.\n",
    "    - \"type\" (VARCHAR): Insurance category.\n",
    "    - \"branch\" (VARCHAR): Policy branch.\n",
    "    - \"ramo\" (VARCHAR): Coverage type.\n",
    "    - \"broker\" (VARCHAR): Broker for the policy.\n",
    "    - \"state\" (VARCHAR): Current case state.\n",
    "    - \"client\" (VARCHAR): Client who bought the insurance.\n",
    "    - \"creator\" (VARCHAR): Employee managing the case.\n",
    "    - \"value\" (BIGINT): Insurance monetary value.\n",
    "    - \"approved\" (BOOLEAN): TRUE if approved, else FALSE.\n",
    "    - \"insurance_creation\" (TIMESTAMP_NS): Policy creation timestamp.\n",
    "    - \"insurance_start\" (TIMESTAMP_NS): Coverage start timestamp.\n",
    "    - \"insurance_end\" (TIMESTAMP_NS): Coverage end timestamp.\n",
    "\n",
    "    #### Table: \"activity\"\n",
    "    - \"id\" (BIGINT): Primary key.\n",
    "    - \"case\" (VARCHAR): Foreign key to \"cases\".\"id\".\n",
    "    - \"timestamp\" (TIMESTAMP_NS): Activity timestamp.\n",
    "    - \"name\" (VARCHAR): Name of the activity.\n",
    "    - \"case_index\" (BIGINT): Alias for \"id\".\n",
    "    - \"tpt\" (DOUBLE): Activity duration (seconds).\n",
    "    \n",
    "    ### Query Guidelines  \n",
    "    1. Convert any time differences (e.g., between `insurance_start` and `insurance_creation`) from `INTERVAL` to a numeric type, such as seconds or minutes, for accurate calculations.\n",
    "    2. Use functions like `EXTRACT(EPOCH FROM ...)` to convert `INTERVAL` types into numeric values (e.g., seconds) that can be averaged.\n",
    "    3. **Use Table Aliases**: \"cases\" ‚Üí c, \"activity\" ‚Üí a.\n",
    "    4. **Always Reference Columns with Aliases**: c.\"id\", a.\"case\".\n",
    "    5. **Handle Aggregations**: Include non-aggregated columns in GROUP BY.\n",
    "    6. **Date & Time Calculations**: Use EXTRACT(DAY FROM ...) for durations.\n",
    "    7. **Filtering Conditions**: Use TRUE/FALSE for boolean values.\n",
    "    8. **Use Explicit Joins**: Avoid implicit joins.\n",
    "    9. **Optimize for Performance**: Use indexes, avoid unnecessary calculations, and limit results when needed.\n",
    "    10. **Restrict Queries to Existing Tables**: Only use \"cases\" and \"activity\" tables.\n",
    "    11. **Use JOINS only when necessary**: Avoid unnecessary joins.\n",
    "    ### Output Format  \n",
    "    - Return only the SQL query, with no extra formatting.  \n",
    "    - Do **NOT** include language tags like `sql`, `vbnet`, or any other markers.  \n",
    "\n",
    "    \"\"\"\n",
    "    llm= OllamaLLM(model=\"duckdb-nsql:latest\",temperature=\"0.0\")\n",
    "\n",
    "    convert_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system),\n",
    "                (\"human\", \"Question: {question}\"),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    sql_generator = convert_prompt | llm\n",
    "    querys= []\n",
    "    for question in questions:\n",
    "        print(f\"Converting question to SQL {question}\")\n",
    "        result = sql_generator.invoke({\"question\": question})\n",
    "        message= re.sub(r'^\\s*```sql\\s*|\\s*```$', '', result.strip(), flags=re.IGNORECASE)\n",
    "        querys.append(message) # Append each generated SQL query to the list\n",
    "        print(f\"Generated SQL query: {message}\")\n",
    "    state[\"sql_querys\"] = querys \n",
    "    state[\"executed\"]= [False] * len(state[\"sql_querys\"])  # Initialize executed status for each question # Store the list of SQL queries in the state\n",
    "    print(f\"Generated SQL queries: {state['sql_querys']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def execute_sql(state:State):\n",
    "    \"\"\"\n",
    "    Executes the SQL query on the  database and retrieves the results.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the query results or error information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # If multiple queries are generated, execute them one by one\n",
    "    db_conn = state[\"db_conn\"] \n",
    "    sql_queries = state[\"sql_querys\"]\n",
    "    errors = state.get(\"sql_error\", [True] * len(sql_queries))  # Default: all True (assume they need execution)\n",
    "    results = state.get(\"query_results\", [None] * len(sql_queries))\n",
    "    for i, query in enumerate(sql_queries):\n",
    "        if errors[i] or results[i] is None:  # Execute if error OR never executed before\n",
    "            print(f\"üöÄ Executing query {i}: {query}\")\n",
    "            try:\n",
    "                # Ensure the query targets only the allowed tables\n",
    "                allowed_tables = [\"cases\", \"activity\"]\n",
    "                if not any(table in query.lower() for table in allowed_tables):\n",
    "                    raise ValueError(f\"Query must target only the tables: {', '.join(allowed_tables)}.\")\n",
    "\n",
    "                # Execute the SQL query using the connection\n",
    "                cursor = db_conn.cursor()\n",
    "                cursor.execute(query)\n",
    "\n",
    "                # Fetch results if it's a SELECT query\n",
    "                if query.lower().startswith(\"select\"):\n",
    "                    rows = cursor.fetchall()\n",
    "                    columns = [desc[0] for desc in cursor.description]\n",
    "\n",
    "                    # Format the output\n",
    "                    if rows:\n",
    "                        formatted_result = \"\\n\".join(\n",
    "                            \", \".join(f\"{col}: {row[idx]}\" for idx, col in enumerate(columns))\n",
    "                            for row in rows\n",
    "                        )\n",
    "                        print(\"SQL SELECT query executed successfully.\")\n",
    "                    else:\n",
    "                        formatted_result = \"No results found.\"\n",
    "                        print(\"SQL SELECT query executed successfully but returned no rows.\")\n",
    "\n",
    "                    state[\"query_rows\"] = rows\n",
    "                else:\n",
    "                    formatted_result = \"The action has been successfully completed.\"\n",
    "                    print(\"SQL command executed successfully.\")\n",
    "\n",
    "                results[i]= formatted_result\n",
    "                errors[i]= False # Mark this query as executed successfully\n",
    "\n",
    "            except Exception as e:\n",
    "                results[i]=f\"Error executing SQL query: {str(e)}\" # Store the error message in the results\n",
    "                errors[i]= True # Mark this query as executed with an error\n",
    "                print(f\"Error executing SQL query: {str(e)}\")\n",
    "    state[\"query_results\"] = results  # Store the list of query results in the state\n",
    "    state[\"sql_error\"] = errors  # Store the list of error states in the state\n",
    "    print(f\"SQL query results: {state['query_results']}\")\n",
    "    print(f\"SQL error states: {state['sql_error']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "    \n",
    "def generate_serious_answer(state: State):\n",
    "    \"\"\"\n",
    "    Generates a business-oriented response using SQL query results from sub-questions\n",
    "    to answer the main question.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        \n",
    "    Returns:\n",
    "        State: Updated state with the final answer.\n",
    "    \"\"\"\n",
    "    question = state[\"original_question\"]\n",
    "    sub_questions = state[\"questions\"]\n",
    "    query_results = state[\"query_results\"]  # This is now a list of results, one per sub-question\n",
    "\n",
    "    chat_history_entries = state.get(\"chat_history\", [])\n",
    "    chat_history = relevant_entries(chat_history_entries)  # Get the last 3 relevant entries\n",
    "\n",
    "    # Concatenate each sub-question with its answer\n",
    "    sub_q_results_str = \"\\n\".join(\n",
    "        f\"**{sq}**\\n{qr}\\n\" for sq, qr in zip(sub_questions, query_results)\n",
    "    )\n",
    "\n",
    "    system = f\"\"\"\n",
    "    You are sOFIa, an AI assistant designed by the AI dream team at OFI Services. \n",
    "    Your task is to:\n",
    "    1. Answer the user's **main question** using the SQL results from the **sub-questions**.\n",
    "    2. Provide business insights based on the query results.\n",
    "\n",
    "    ### **Chat History:**  \n",
    "    {chat_history}\n",
    "\n",
    "    ### **Context:**  \n",
    "    - **User's Main Question:** {question}  \n",
    "    - **SQL Results from Sub-Questions:**  \n",
    "    {sub_q_results_str}\n",
    "\n",
    "    ### **Instructions:**  \n",
    "    - Summarize the SQL results in a **clear business-oriented answer**.\n",
    "    - Ensure the answer **directly addresses the main question**.\n",
    "    - Provide **business insights** based on patterns, trends, and potential improvements.\n",
    "    - If relevant, compare values or suggest actions based on findings.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    human_message = f\"Question: {question}\"\n",
    "    \n",
    "    # Use sOFIa to generate a response based on the SQL result\n",
    "    llm = OllamaLLM(model=\"mistral:latest\", temperature=\"0.0\", max_tokens=200)\n",
    "    response = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system),\n",
    "        (\"human\", human_message),\n",
    "    ]) | llm | StrOutputParser()\n",
    "    \n",
    "    # Generate and store the response\n",
    "    message = response.invoke({})\n",
    "    state[\"final_answer\"] = message\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def regenerate_query(state):\n",
    "    \"\"\"\n",
    "    Fixes the SQL query by passing the error message to the SQL model instead of rewriting the user's question.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the fixed query.\n",
    "    \"\"\"\n",
    "    error_state= state[\"sql_error\"]\n",
    "    error_indexes = [index for index, error in enumerate(error_state) if error == True]\n",
    "\n",
    "    llm = OllamaLLM(model=\"mistral:latest\", temperature=0.0)  # Use DuckDB-specific SQL model\n",
    "    print(f\"üîÑ Regenerating query. Attempt {state['attempts'] + 1}\")\n",
    "    for index in error_indexes:\n",
    "        # Fix the SQL query using the error message\n",
    "        query = state[\"sql_querys\"][index]\n",
    "        error = state[\"query_results\"][index]\n",
    "        print(f\"‚ö†Ô∏è Fixing SQL query at index {index}: {query}\")\n",
    "        print(f\"üîç Error encountered: {error}\")\n",
    "\n",
    "        # Dynamic Prompt Generation\n",
    "        sql_fix_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", f\"\"\"You are an expert in SQL for DuckDB.\n",
    "            Your task is to correct the following SQL query based on the error message.\n",
    "\n",
    "            ### **Query to Fix:**\n",
    "            ```sql\n",
    "            {query}\n",
    "            ```\n",
    "\n",
    "            ### **Error Message:**\n",
    "            {error}\n",
    "\n",
    "            Provide a **corrected** SQL query that runs successfully in the following database schema.\n",
    "            ### Database Schema  \n",
    "            #### Table: \"cases\"\n",
    "            - \"id\" (VARCHAR): Primary key.\n",
    "            - \"insurance\" (BIGINT): Foreign key to insurance.\n",
    "            - \"avg_time\" (DOUBLE): Duration (seconds) from case initiation to closure.\n",
    "            - \"type\" (VARCHAR): Insurance category.\n",
    "            - \"branch\" (VARCHAR): Policy branch.\n",
    "            - \"ramo\" (VARCHAR): Coverage type.\n",
    "            - \"broker\" (VARCHAR): Broker for the policy.\n",
    "            - \"state\" (VARCHAR): Current case state.\n",
    "            - \"client\" (VARCHAR): Client who bought the insurance.\n",
    "            - \"creator\" (VARCHAR): Employee managing the case.\n",
    "            - \"value\" (BIGINT): Insurance monetary value.\n",
    "            - \"approved\" (BOOLEAN): TRUE if approved, else FALSE.\n",
    "            - \"insurance_creation\" (TIMESTAMP_NS): Policy creation timestamp.\n",
    "            - \"insurance_start\" (TIMESTAMP_NS): Coverage start timestamp.\n",
    "            - \"insurance_end\" (TIMESTAMP_NS): Coverage end timestamp.\n",
    "\n",
    "            #### Table: \"activity\"\n",
    "            - \"id\" (BIGINT): Primary key.\n",
    "            - \"case\" (VARCHAR): Foreign key to \"cases\".\"id\".\n",
    "            - \"timestamp\" (TIMESTAMP_NS): Activity timestamp.\n",
    "            - \"name\" (VARCHAR): Name of the activity.\n",
    "            - \"case_index\" (BIGINT): Alias for \"id\".\n",
    "            - \"tpt\" (DOUBLE): Activity duration (seconds).\n",
    "                    \"\"\"),\n",
    "            (\"human\", \"Fix the query and return only the corrected SQL, no explanations.\"),\n",
    "        ])\n",
    "\n",
    "        fixer = sql_fix_prompt | llm \n",
    "        # Pass the query and error message to the SQL model for correction\n",
    "        corrected_query = fixer.invoke({\"query\": query, \"error\": error})\n",
    "        state[\"sql_querys\"][index] = corrected_query\n",
    "        print(f\"‚úÖ Fixed SQL query: {corrected_query}\")\n",
    "    state[\"attempts\"] += 1\n",
    "    return state\n",
    "\n",
    "\n",
    "def end_max_iterations(state: State):\n",
    "    \"\"\"\n",
    "    Ends the workflow after reaching the maximum number of attempts.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with a termination message.\n",
    "    \"\"\"\n",
    "    state[\"query_results\"] = \"Please try again.\"\n",
    "    state[\"final_answer\"] = \"I couldn't generate a valid SQL query after 3 attempts. Please try again.\"\n",
    "    print(\"Maximum attempts reached. Ending the workflow.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def generate_funny_response(state: State):\n",
    "    \"\"\"\n",
    "    Generates a playful and humorous response for unrelated questions.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        \n",
    "    Returns:\n",
    "        State: Updated state with the funny response.\n",
    "    \"\"\"\n",
    "    print(\"Generating a funny response for an unrelated question.\")\n",
    "    question = state[\"original_question\"]\n",
    "    chat_history_entries = state.get(\"chat_history\", [])\n",
    "    chat_history = non_relevant_entries(chat_history_entries) # Get the last 3 non-relevant entries\n",
    "    print(f\"Chat history for funny response:\\n{chat_history}\")\n",
    "    system = f\"\"\"You are **sOFIa**, a charming and funny assistant designed by the AI team at OFI Services. \n",
    "    You respond in a playful and lighthearted manner. Your responses should always be fun, engaging, and humorous. \n",
    "    If the user doesn't know you yet, introduce yourself!\n",
    "    \n",
    "    ### **Chat History:**  \n",
    "    {chat_history}\n",
    "    \"\"\"\n",
    "\n",
    "    human_message = f\"Question: {question}\"\n",
    "\n",
    "    # Generate the playful response\n",
    "    funny_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human_message),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    llm = OllamaLLM(model=\"mistral:latest\", temperature=\"0.7\",max_tokens=200)\n",
    "    funny_response = funny_prompt | llm | StrOutputParser()\n",
    "    message = funny_response.invoke({})\n",
    "    state[\"final_answer\"] = message\n",
    "    return state\n",
    "\n",
    "\n",
    "def check_attempts_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on the number of attempts made to generate a valid SQL query.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    if state[\"attempts\"] < 3:\n",
    "        return \"execute_sql\"\n",
    "    else:\n",
    "        error_state= state[\"sql_error\"]\n",
    "        for error in error_state:\n",
    "            if error == False:\n",
    "                return \"generate_serious_answer\"\n",
    "        return \"end_max_iterations\"\n",
    "\n",
    "\n",
    "\n",
    "def execute_sql_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on whether the SQL query execution was successful.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    error_state= state[\"sql_error\"]\n",
    "    for error in error_state:\n",
    "        if error == True:\n",
    "            return \"regenerate_query\"\n",
    "    else:\n",
    "        return \"generate_serious_answer\"\n",
    "\n",
    "\n",
    "    \n",
    "def relevance_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on the relevance of the user's question.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    if state[\"relevance\"].lower() == \"relevant\":\n",
    "        return \"reformat_question\"\n",
    "    else:\n",
    "        return \"generate_funny_response\"\n",
    "    \n",
    "def relevant_entries(chat_history_entries):\n",
    "    \"\"\"\n",
    "    Filters and retrieves the last 3 relevant user questions and their responses in correct order.\n",
    "\n",
    "    Args:\n",
    "        chat_history_entries (list): Full chat history.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the last 3 relevant interactions in correct order.\n",
    "    \"\"\"\n",
    "    relevant_pairs = []\n",
    "    found_count = 0\n",
    "    idx = len(chat_history_entries) - 1\n",
    "\n",
    "    while idx >= 0:\n",
    "        entry = chat_history_entries[idx]\n",
    "\n",
    "        if \"[Relevance: relevant]\" in entry:\n",
    "            user_question = entry  # Store user question\n",
    "\n",
    "            # Look for sOFIa's response **before** storing the question\n",
    "            response_idx = idx + 1  \n",
    "            if response_idx < len(chat_history_entries) and chat_history_entries[response_idx].startswith(\"sOFIa:\"):\n",
    "                sofia_response = chat_history_entries[response_idx]\n",
    "                relevant_pairs.append((user_question, sofia_response))  # Save as a pair\n",
    "                found_count += 1\n",
    "\n",
    "            if found_count >= 3:\n",
    "                break  # Stop after collecting 3 pairs\n",
    "\n",
    "        idx -= 1  # Move backwards in history\n",
    "\n",
    "    # Reverse to maintain chronological order and format correctly\n",
    "    formatted_history = \"\\n\".join(f\"{q}\\n{a}\" for q, a in reversed(relevant_pairs))\n",
    "    return formatted_history\n",
    "\n",
    "def non_relevant_entries(chat_history_entries):\n",
    "    \"\"\"\n",
    "    Filters and retrieves the last 3 non-relevant user questions and their responses in correct order.\n",
    "\n",
    "    Args:\n",
    "        chat_history_entries (list): Full chat history.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the last 3 non-relevant interactions in correct order.\n",
    "    \"\"\"\n",
    "    non_relevant_pairs = []\n",
    "    found_count = 0\n",
    "    idx = len(chat_history_entries) - 1\n",
    "\n",
    "    while idx >= 0:\n",
    "        entry = chat_history_entries[idx]\n",
    "\n",
    "        if \"[Relevance: not_relevant]\" in entry:\n",
    "            user_question = entry  # Store user question\n",
    "\n",
    "            # Look for sOFIa's response **before** storing the question\n",
    "            response_idx = idx + 1  \n",
    "            if response_idx < len(chat_history_entries) and chat_history_entries[response_idx].startswith(\"sOFIa:\"):\n",
    "                sofia_response = chat_history_entries[response_idx]\n",
    "                non_relevant_pairs.append((user_question, sofia_response))  # Save as a pair\n",
    "                found_count += 1\n",
    "\n",
    "            if found_count >= 3:\n",
    "                break  # Stop after collecting 3 pairs\n",
    "\n",
    "        idx -= 1  # Move backwards in history\n",
    "\n",
    "    # Reverse to maintain chronological order and format correctly\n",
    "    formatted_history = \"\\n\".join(f\"{q}\\n{a}\" for q, a in reversed(non_relevant_pairs))\n",
    "    return formatted_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"check_relevance\", check_relevance)\n",
    "workflow.add_node(\"reformat_question\", reformat_question)\n",
    "workflow.add_node(\"convert_to_sql\", convert_nl_to_sql)\n",
    "workflow.add_node(\"execute_sql\",execute_sql)\n",
    "workflow.add_node(\"regenerate_query\",regenerate_query)\n",
    "workflow.add_node(\"generate_funny_response\", generate_funny_response)\n",
    "workflow.add_node(\"generate_serious_answer\",generate_serious_answer)\n",
    "workflow.add_node(\"end_max_iterations\",end_max_iterations)\n",
    "\n",
    "workflow.add_edge(START, \"check_relevance\")\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "        \"check_relevance\",\n",
    "        relevance_router,\n",
    "        {\n",
    "        \"reformat_question\":\"reformat_question\",\n",
    "        \"generate_funny_response\": \"generate_funny_response\"\n",
    "        } \n",
    "\n",
    "    )\n",
    "workflow.add_edge(\"reformat_question\", \"convert_to_sql\")\n",
    "\n",
    "workflow.add_edge(\"convert_to_sql\", \"execute_sql\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "        \"execute_sql\",\n",
    "        execute_sql_router,\n",
    "        {\n",
    "            \"generate_serious_answer\": \"generate_serious_answer\",\n",
    "            \"regenerate_query\": \"regenerate_query\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "        \"regenerate_query\",\n",
    "        check_attempts_router,\n",
    "        {\n",
    "            \"execute_sql\": \"execute_sql\",\n",
    "            \"end_max_iterations\": \"end_max_iterations\",\n",
    "            \"generate_serious_answer\": \"generate_serious_answer\",\n",
    "        },\n",
    "    )\n",
    "workflow.add_edge(\"end_max_iterations\", END)\n",
    "workflow.add_edge(\"generate_serious_answer\",END)\n",
    "workflow.add_edge(\"generate_funny_response\",END)\n",
    "\n",
    "chain= workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state= chain.invoke({\"original_question\":\"Hello?\",\"db_conn\":db_conn})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\n",
    "    chain.get_graph().draw_mermaid_png()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi hi! I'm sOFIa, your assistant!\n",
      "Let's get started by asking a question!\n",
      "Checking relevance of the question: Who is the broker with the most assigned cases?\n",
      "Chat history for relevance check:\n",
      "\n",
      "Relevance determined: relevant\n",
      "Processed Question(s): ['Who are all the brokers in the system?', 'For each broker, how many cases are they assigned?']\n",
      "Converting question to SQL Who are all the brokers in the system?\n",
      "Generated SQL query: SELECT DISTINCT broker FROM activity\n",
      "Converting question to SQL For each broker, how many cases are they assigned?\n",
      "Generated SQL query: SELECT broker, COUNT(*) FROM cases GROUP BY broker\n",
      "Generated SQL queries: ['SELECT DISTINCT broker FROM activity', 'SELECT broker, COUNT(*) FROM cases GROUP BY broker']\n",
      "üöÄ Executing query 0: SELECT DISTINCT broker FROM activity\n",
      "Error executing SQL query: Binder Error: Referenced column \"broker\" not found in FROM clause!\n",
      "Candidate bindings: \"case\"\n",
      "\n",
      "LINE 1: SELECT DISTINCT broker FROM activity\n",
      "                        ^\n",
      "üöÄ Executing query 1: SELECT broker, COUNT(*) FROM cases GROUP BY broker\n",
      "SQL SELECT query executed successfully.\n",
      "SQL query results: ['Error executing SQL query: Binder Error: Referenced column \"broker\" not found in FROM clause!\\nCandidate bindings: \"case\"\\n\\nLINE 1: SELECT DISTINCT broker FROM activity\\n                        ^', 'broker: Laura, count_star(): 4\\nbroker: Priscilla, count_star(): 4\\nbroker: Shane, count_star(): 3\\nbroker: Amy, count_star(): 6\\nbroker: Nicholas, count_star(): 3\\nbroker: Henry, count_star(): 3\\nbroker: Ricky, count_star(): 3\\nbroker: Leslie, count_star(): 1\\nbroker: Edith, count_star(): 8\\nbroker: Dale, count_star(): 2\\nbroker: Sara, count_star(): 2\\nbroker: Nancy, count_star(): 2\\nbroker: Kathleen, count_star(): 3\\nbroker: Natalie, count_star(): 2\\nbroker: Richard, count_star(): 2\\nbroker: Yolanda, count_star(): 1\\nbroker: Carl, count_star(): 1\\nbroker: Thomas, count_star(): 5\\nbroker: Claire, count_star(): 1\\nbroker: Christian, count_star(): 3\\nbroker: Sally, count_star(): 2\\nbroker: Gary, count_star(): 4\\nbroker: Philip, count_star(): 2\\nbroker: Joe, count_star(): 2\\nbroker: Tracy, count_star(): 2\\nbroker: Sharon, count_star(): 1\\nbroker: Felix, count_star(): 3\\nbroker: Ellen, count_star(): 3\\nbroker: Luis, count_star(): 3\\nbroker: Joel, count_star(): 6\\nbroker: Victor, count_star(): 5\\nbroker: Kathryn, count_star(): 2\\nbroker: Spencer, count_star(): 2\\nbroker: Rachel, count_star(): 3\\nbroker: Franklin, count_star(): 2\\nbroker: Melissa, count_star(): 6\\nbroker: Wesley, count_star(): 2\\nbroker: Trevor, count_star(): 1\\nbroker: Helen, count_star(): 2\\nbroker: Adrian, count_star(): 3\\nbroker: Florence, count_star(): 1\\nbroker: Danielle, count_star(): 1\\nbroker: Eli, count_star(): 4\\nbroker: Nolan, count_star(): 3\\nbroker: Sylvia, count_star(): 4\\nbroker: Robert, count_star(): 2\\nbroker: Ava, count_star(): 1\\nbroker: Jeffrey, count_star(): 5\\nbroker: Gregory, count_star(): 4\\nbroker: Felicia, count_star(): 4\\nbroker: Marc, count_star(): 1\\nbroker: Marvin, count_star(): 4\\nbroker: James, count_star(): 3\\nbroker: Tony, count_star(): 2\\nbroker: Steve, count_star(): 2\\nbroker: Betty, count_star(): 3\\nbroker: Neil, count_star(): 5\\nbroker: Russell, count_star(): 2\\nbroker: Isabella, count_star(): 1\\nbroker: Lauren, count_star(): 2\\nbroker: Ted, count_star(): 1\\nbroker: Stephanie, count_star(): 1\\nbroker: Kyle, count_star(): 2\\nbroker: Gavin, count_star(): 2\\nbroker: Norma, count_star(): 1\\nbroker: Caitlin, count_star(): 2\\nbroker: Edgar, count_star(): 5\\nbroker: Karen, count_star(): 2\\nbroker: Cameron, count_star(): 3\\nbroker: Marie, count_star(): 2\\nbroker: Virginia, count_star(): 2\\nbroker: Holly, count_star(): 2\\nbroker: Quincy, count_star(): 1\\nbroker: Clifford, count_star(): 3\\nbroker: Marion, count_star(): 1\\nbroker: Mitchell, count_star(): 2\\nbroker: Benjamin, count_star(): 3\\nbroker: Tamara, count_star(): 2\\nbroker: Kristin, count_star(): 2\\nbroker: Stacy, count_star(): 2\\nbroker: Laverne, count_star(): 1\\nbroker: Ross, count_star(): 2\\nbroker: Wayne, count_star(): 1\\nbroker: Sean, count_star(): 1\\nbroker: Jordan, count_star(): 1\\nbroker: Marshall, count_star(): 3\\nbroker: Vanessa, count_star(): 6\\nbroker: Peter, count_star(): 4\\nbroker: Xavier, count_star(): 4\\nbroker: Paul, count_star(): 5\\nbroker: Alyssa, count_star(): 3\\nbroker: Jean, count_star(): 3\\nbroker: Eric, count_star(): 4\\nbroker: Toni, count_star(): 3\\nbroker: Ruby, count_star(): 4\\nbroker: Lance, count_star(): 6\\nbroker: Clara, count_star(): 5\\nbroker: Emma, count_star(): 2\\nbroker: Ralph, count_star(): 1\\nbroker: Stephen, count_star(): 2\\nbroker: Mason, count_star(): 3\\nbroker: Dawn, count_star(): 1\\nbroker: Jared, count_star(): 1\\nbroker: Shelby, count_star(): 5\\nbroker: Stanley, count_star(): 9\\nbroker: Molly, count_star(): 3\\nbroker: Erik, count_star(): 1\\nbroker: Darlene, count_star(): 3\\nbroker: Sandra, count_star(): 3\\nbroker: Alex, count_star(): 6\\nbroker: Meredith, count_star(): 3\\nbroker: Patricia, count_star(): 2\\nbroker: Hailey, count_star(): 3\\nbroker: Daniel, count_star(): 3\\nbroker: Gretchen, count_star(): 2\\nbroker: Wyatt, count_star(): 1\\nbroker: Lois, count_star(): 4\\nbroker: Brittany, count_star(): 2\\nbroker: Olivia, count_star(): 2\\nbroker: Jacob, count_star(): 1\\nbroker: Steven, count_star(): 6\\nbroker: Eva, count_star(): 3\\nbroker: Hector, count_star(): 2\\nbroker: Kelly, count_star(): 1\\nbroker: Gloria, count_star(): 1\\nbroker: Gene, count_star(): 1\\nbroker: Nathaniel, count_star(): 3\\nbroker: Rebecca, count_star(): 2\\nbroker: Tricia, count_star(): 2\\nbroker: Catherine, count_star(): 1\\nbroker: Geoffrey, count_star(): 1\\nbroker: Cynthia, count_star(): 1\\nbroker: Kevin, count_star(): 1\\nbroker: Brian, count_star(): 1\\nbroker: Mildred, count_star(): 3\\nbroker: Simon, count_star(): 6\\nbroker: Jack, count_star(): 3\\nbroker: Marjorie, count_star(): 3\\nbroker: Trent, count_star(): 2\\nbroker: Hazel, count_star(): 4\\nbroker: Lewis, count_star(): 5\\nbroker: Heather, count_star(): 2\\nbroker: Denise, count_star(): 3\\nbroker: Austin, count_star(): 3\\nbroker: Sidney, count_star(): 1\\nbroker: Hugh, count_star(): 2\\nbroker: Vera, count_star(): 1\\nbroker: Walter, count_star(): 1\\nbroker: Tiffany, count_star(): 4\\nbroker: Madison, count_star(): 2\\nbroker: Suzanne, count_star(): 4\\nbroker: Aaron, count_star(): 5\\nbroker: Herbert, count_star(): 3\\nbroker: Malcolm, count_star(): 2\\nbroker: Sierra, count_star(): 2\\nbroker: Julia, count_star(): 3\\nbroker: Dennis, count_star(): 2\\nbroker: Beverly, count_star(): 2\\nbroker: Doris, count_star(): 5\\nbroker: Judith, count_star(): 1\\nbroker: Sherry, count_star(): 4\\nbroker: Howard, count_star(): 2\\nbroker: Marilyn, count_star(): 2\\nbroker: Christopher, count_star(): 1\\nbroker: Daisy, count_star(): 3\\nbroker: Theresa, count_star(): 2\\nbroker: Grant, count_star(): 4\\nbroker: Christine, count_star(): 2\\nbroker: Maureen, count_star(): 2\\nbroker: Glen, count_star(): 1\\nbroker: Derek, count_star(): 2\\nbroker: Madeline, count_star(): 2\\nbroker: Ethan, count_star(): 1\\nbroker: Gail, count_star(): 1\\nbroker: Terrence, count_star(): 2\\nbroker: Patrick, count_star(): 5\\nbroker: Wanda, count_star(): 5\\nbroker: Elijah, count_star(): 3\\nbroker: Nina, count_star(): 2\\nbroker: Dylan, count_star(): 3\\nbroker: Dakota, count_star(): 3\\nbroker: Alexis, count_star(): 4\\nbroker: Hannah, count_star(): 3\\nbroker: Charles, count_star(): 2\\nbroker: Donna, count_star(): 5\\nbroker: Vincent, count_star(): 3\\nbroker: Albert, count_star(): 2\\nbroker: Katie, count_star(): 2\\nbroker: Louis, count_star(): 2\\nbroker: George, count_star(): 3\\nbroker: Cheryl, count_star(): 6\\nbroker: Joanna, count_star(): 1\\nbroker: Connor, count_star(): 4\\nbroker: Jeremy, count_star(): 3\\nbroker: Edmund, count_star(): 4\\nbroker: Samuel, count_star(): 3\\nbroker: Clayton, count_star(): 3\\nbroker: Tara, count_star(): 1\\nbroker: Rick, count_star(): 1\\nbroker: Glenda, count_star(): 4\\nbroker: Carol, count_star(): 2\\nbroker: Curtis, count_star(): 2\\nbroker: John, count_star(): 1\\nbroker: Jerry, count_star(): 2\\nbroker: Isabel, count_star(): 2\\nbroker: Kenneth, count_star(): 2\\nbroker: Kathy, count_star(): 2\\nbroker: Michelle, count_star(): 6\\nbroker: Faye, count_star(): 3\\nbroker: Tina, count_star(): 2\\nbroker: Monica, count_star(): 6\\nbroker: Lisa, count_star(): 2\\nbroker: Martha, count_star(): 2\\nbroker: Isaiah, count_star(): 1\\nbroker: Alice, count_star(): 2\\nbroker: Ivan, count_star(): 4\\nbroker: Douglas, count_star(): 4\\nbroker: Neal, count_star(): 3\\nbroker: Matthew, count_star(): 1\\nbroker: Rhonda, count_star(): 5\\nbroker: Donald, count_star(): 2\\nbroker: Preston, count_star(): 2\\nbroker: Sue, count_star(): 4\\nbroker: Rosemary, count_star(): 1\\nbroker: Frederick, count_star(): 1\\nbroker: Ella, count_star(): 1\\nbroker: Terry, count_star(): 2\\nbroker: Rose, count_star(): 3\\nbroker: Amber, count_star(): 3\\nbroker: Amanda, count_star(): 3\\nbroker: Julian, count_star(): 5\\nbroker: Bobby, count_star(): 2\\nbroker: Guy, count_star(): 3\\nbroker: Angela, count_star(): 4\\nbroker: Jenna, count_star(): 4\\nbroker: Timothy, count_star(): 5\\nbroker: Geraldine, count_star(): 3\\nbroker: Sonia, count_star(): 1\\nbroker: Quentin, count_star(): 2\\nbroker: Fiona, count_star(): 2\\nbroker: Cindy, count_star(): 3\\nbroker: Jackie, count_star(): 2\\nbroker: Milton, count_star(): 2\\nbroker: Stuart, count_star(): 1\\nbroker: Adam, count_star(): 2\\nbroker: Edward, count_star(): 2\\nbroker: Jennifer, count_star(): 2\\nbroker: Phyllis, count_star(): 2\\nbroker: Keith, count_star(): 1\\nbroker: Diana, count_star(): 3\\nbroker: Aiden, count_star(): 1\\nbroker: Allison, count_star(): 1\\nbroker: Georgia, count_star(): 1\\nbroker: William, count_star(): 2\\nbroker: Lori, count_star(): 4\\nbroker: Charlotte, count_star(): 2\\nbroker: Sheila, count_star(): 4\\nbroker: Sophia, count_star(): 4\\nbroker: Janice, count_star(): 1\\nbroker: David, count_star(): 3\\nbroker: Mark, count_star(): 4\\nbroker: Susan, count_star(): 2\\nbroker: Mandy, count_star(): 3\\nbroker: Elizabeth, count_star(): 1\\nbroker: Debra, count_star(): 2\\nbroker: Valerie, count_star(): 2\\nbroker: Lillian, count_star(): 5\\nbroker: Gerald, count_star(): 2\\nbroker: Dean, count_star(): 1\\nbroker: Zachary, count_star(): 2\\nbroker: Julie, count_star(): 1\\nbroker: Jacqueline, count_star(): 1\\nbroker: Manuel, count_star(): 1\\nbroker: Lydia, count_star(): 2\\nbroker: Crystal, count_star(): 4\\nbroker: Sydney, count_star(): 3\\nbroker: Frank, count_star(): 6\\nbroker: Lynn, count_star(): 1\\nbroker: Sherri, count_star(): 2\\nbroker: Yvonne, count_star(): 2\\nbroker: Kimberly, count_star(): 6\\nbroker: Isaac, count_star(): 1\\nbroker: Michele, count_star(): 2\\nbroker: Craig, count_star(): 3\\nbroker: Willie, count_star(): 1\\nbroker: Joyce, count_star(): 2\\nbroker: Taylor, count_star(): 2\\nbroker: Diane, count_star(): 1\\nbroker: Zoe, count_star(): 3\\nbroker: Brenda, count_star(): 2\\nbroker: Francis, count_star(): 5\\nbroker: Pamela, count_star(): 1\\nbroker: Ryan, count_star(): 1\\nbroker: Kayla, count_star(): 2\\nbroker: Jill, count_star(): 1\\nbroker: Grace, count_star(): 1\\nbroker: Hunter, count_star(): 2\\nbroker: Bruce, count_star(): 1\\nbroker: Alan, count_star(): 3\\nbroker: Gabriel, count_star(): 6\\nbroker: Rosa, count_star(): 2\\nbroker: Ruth, count_star(): 3\\nbroker: Deborah, count_star(): 5\\nbroker: Joshua, count_star(): 3\\nbroker: Shirley, count_star(): 1\\nbroker: Roger, count_star(): 1\\nbroker: Juan, count_star(): 2\\nbroker: Bryan, count_star(): 5\\nbroker: Elaine, count_star(): 1\\nbroker: Billy, count_star(): 2\\nbroker: Sabrina, count_star(): 2\\nbroker: Harry, count_star(): 1\\nbroker: Herman, count_star(): 2\\nbroker: Samantha, count_star(): 4\\nbroker: Claudia, count_star(): 1\\nbroker: Erin, count_star(): 2\\nbroker: Melvin, count_star(): 1\\nbroker: Cody, count_star(): 1\\nbroker: Penny, count_star(): 1\\nbroker: Barbara, count_star(): 3\\nbroker: Gilbert, count_star(): 1\\nbroker: Eleanor, count_star(): 1\\nbroker: Owen, count_star(): 1\\nbroker: Ashley, count_star(): 2\\nbroker: Jason, count_star(): 1\\nbroker: Miranda, count_star(): 1\\nbroker: Leah, count_star(): 8\\nbroker: Peggy, count_star(): 5\\nbroker: Alicia, count_star(): 5\\nbroker: Jessica, count_star(): 2\\nbroker: Nicole, count_star(): 3\\nbroker: Shannon, count_star(): 4\\nbroker: Ian, count_star(): 3\\nbroker: Nathan, count_star(): 2\\nbroker: Oscar, count_star(): 3\\nbroker: Maggie, count_star(): 3\\nbroker: Paula, count_star(): 6\\nbroker: Travis, count_star(): 4\\nbroker: Clarence, count_star(): 4\\nbroker: Renee, count_star(): 1\\nbroker: Rita, count_star(): 4\\nbroker: Joan, count_star(): 1\\nbroker: Lee, count_star(): 3\\nbroker: Frances, count_star(): 2\\nbroker: Lucas, count_star(): 1\\nbroker: Phillip, count_star(): 1\\nbroker: Brandon, count_star(): 3\\nbroker: Erica, count_star(): 1\\nbroker: Jane, count_star(): 3\\nbroker: Linda, count_star(): 1\\nbroker: Morgan, count_star(): 1\\nbroker: Theodore, count_star(): 4\\nbroker: Robin, count_star(): 3\\nbroker: Joseph, count_star(): 1\\nbroker: Teresa, count_star(): 6\\nbroker: Gina, count_star(): 2\\nbroker: Victoria, count_star(): 3\\nbroker: Larry, count_star(): 4\\nbroker: Veronica, count_star(): 3\\nbroker: Vivian, count_star(): 5\\nbroker: Colin, count_star(): 2\\nbroker: Lawrence, count_star(): 4\\nbroker: Emily, count_star(): 3\\nbroker: Raymond, count_star(): 2\\nbroker: Scott, count_star(): 4\\nbroker: Roberta, count_star(): 1\\nbroker: Graham, count_star(): 3\\nbroker: Fred, count_star(): 3\\nbroker: Troy, count_star(): 2\\nbroker: Christina, count_star(): 4\\nbroker: Todd, count_star(): 1\\nbroker: Tammy, count_star(): 4\\nbroker: Clinton, count_star(): 3\\nbroker: Leonard, count_star(): 3\\nbroker: Anna, count_star(): 2\\nbroker: Whitney, count_star(): 4\\nbroker: Carolyn, count_star(): 4\\nbroker: Margaret, count_star(): 2\\nbroker: Maria, count_star(): 3\\nbroker: Irene, count_star(): 2\\nbroker: Michael, count_star(): 2\\nbroker: Wendy, count_star(): 2\\nbroker: Ronald, count_star(): 2\\nbroker: Katherine, count_star(): 1\\nbroker: Harold, count_star(): 2']\n",
      "SQL error states: [True, False]\n",
      "üîÑ Regenerating query. Attempt 1\n",
      "‚ö†Ô∏è Fixing SQL query at index 0: SELECT DISTINCT broker FROM activity\n",
      "üîç Error encountered: Error executing SQL query: Binder Error: Referenced column \"broker\" not found in FROM clause!\n",
      "Candidate bindings: \"case\"\n",
      "\n",
      "LINE 1: SELECT DISTINCT broker FROM activity\n",
      "                        ^\n",
      "‚úÖ Fixed SQL query:  SELECT DISTINCT cases.broker FROM cases;\n",
      "üöÄ Executing query 0:  SELECT DISTINCT cases.broker FROM cases;\n",
      "SQL command executed successfully.\n",
      "SQL query results: ['The action has been successfully completed.', 'broker: Laura, count_star(): 4\\nbroker: Priscilla, count_star(): 4\\nbroker: Shane, count_star(): 3\\nbroker: Amy, count_star(): 6\\nbroker: Nicholas, count_star(): 3\\nbroker: Henry, count_star(): 3\\nbroker: Ricky, count_star(): 3\\nbroker: Leslie, count_star(): 1\\nbroker: Edith, count_star(): 8\\nbroker: Dale, count_star(): 2\\nbroker: Sara, count_star(): 2\\nbroker: Nancy, count_star(): 2\\nbroker: Kathleen, count_star(): 3\\nbroker: Natalie, count_star(): 2\\nbroker: Richard, count_star(): 2\\nbroker: Yolanda, count_star(): 1\\nbroker: Carl, count_star(): 1\\nbroker: Thomas, count_star(): 5\\nbroker: Claire, count_star(): 1\\nbroker: Christian, count_star(): 3\\nbroker: Sally, count_star(): 2\\nbroker: Gary, count_star(): 4\\nbroker: Philip, count_star(): 2\\nbroker: Joe, count_star(): 2\\nbroker: Tracy, count_star(): 2\\nbroker: Sharon, count_star(): 1\\nbroker: Felix, count_star(): 3\\nbroker: Ellen, count_star(): 3\\nbroker: Luis, count_star(): 3\\nbroker: Joel, count_star(): 6\\nbroker: Victor, count_star(): 5\\nbroker: Kathryn, count_star(): 2\\nbroker: Spencer, count_star(): 2\\nbroker: Rachel, count_star(): 3\\nbroker: Franklin, count_star(): 2\\nbroker: Melissa, count_star(): 6\\nbroker: Wesley, count_star(): 2\\nbroker: Trevor, count_star(): 1\\nbroker: Helen, count_star(): 2\\nbroker: Adrian, count_star(): 3\\nbroker: Florence, count_star(): 1\\nbroker: Danielle, count_star(): 1\\nbroker: Eli, count_star(): 4\\nbroker: Nolan, count_star(): 3\\nbroker: Sylvia, count_star(): 4\\nbroker: Robert, count_star(): 2\\nbroker: Ava, count_star(): 1\\nbroker: Jeffrey, count_star(): 5\\nbroker: Gregory, count_star(): 4\\nbroker: Felicia, count_star(): 4\\nbroker: Marc, count_star(): 1\\nbroker: Marvin, count_star(): 4\\nbroker: James, count_star(): 3\\nbroker: Tony, count_star(): 2\\nbroker: Steve, count_star(): 2\\nbroker: Betty, count_star(): 3\\nbroker: Neil, count_star(): 5\\nbroker: Russell, count_star(): 2\\nbroker: Isabella, count_star(): 1\\nbroker: Lauren, count_star(): 2\\nbroker: Ted, count_star(): 1\\nbroker: Stephanie, count_star(): 1\\nbroker: Kyle, count_star(): 2\\nbroker: Gavin, count_star(): 2\\nbroker: Norma, count_star(): 1\\nbroker: Caitlin, count_star(): 2\\nbroker: Edgar, count_star(): 5\\nbroker: Karen, count_star(): 2\\nbroker: Cameron, count_star(): 3\\nbroker: Marie, count_star(): 2\\nbroker: Virginia, count_star(): 2\\nbroker: Holly, count_star(): 2\\nbroker: Quincy, count_star(): 1\\nbroker: Clifford, count_star(): 3\\nbroker: Marion, count_star(): 1\\nbroker: Mitchell, count_star(): 2\\nbroker: Benjamin, count_star(): 3\\nbroker: Tamara, count_star(): 2\\nbroker: Kristin, count_star(): 2\\nbroker: Stacy, count_star(): 2\\nbroker: Laverne, count_star(): 1\\nbroker: Ross, count_star(): 2\\nbroker: Wayne, count_star(): 1\\nbroker: Sean, count_star(): 1\\nbroker: Jordan, count_star(): 1\\nbroker: Marshall, count_star(): 3\\nbroker: Vanessa, count_star(): 6\\nbroker: Peter, count_star(): 4\\nbroker: Xavier, count_star(): 4\\nbroker: Paul, count_star(): 5\\nbroker: Alyssa, count_star(): 3\\nbroker: Jean, count_star(): 3\\nbroker: Eric, count_star(): 4\\nbroker: Toni, count_star(): 3\\nbroker: Ruby, count_star(): 4\\nbroker: Lance, count_star(): 6\\nbroker: Clara, count_star(): 5\\nbroker: Emma, count_star(): 2\\nbroker: Ralph, count_star(): 1\\nbroker: Stephen, count_star(): 2\\nbroker: Mason, count_star(): 3\\nbroker: Dawn, count_star(): 1\\nbroker: Jared, count_star(): 1\\nbroker: Shelby, count_star(): 5\\nbroker: Stanley, count_star(): 9\\nbroker: Molly, count_star(): 3\\nbroker: Erik, count_star(): 1\\nbroker: Darlene, count_star(): 3\\nbroker: Sandra, count_star(): 3\\nbroker: Alex, count_star(): 6\\nbroker: Meredith, count_star(): 3\\nbroker: Patricia, count_star(): 2\\nbroker: Hailey, count_star(): 3\\nbroker: Daniel, count_star(): 3\\nbroker: Gretchen, count_star(): 2\\nbroker: Wyatt, count_star(): 1\\nbroker: Lois, count_star(): 4\\nbroker: Brittany, count_star(): 2\\nbroker: Olivia, count_star(): 2\\nbroker: Jacob, count_star(): 1\\nbroker: Steven, count_star(): 6\\nbroker: Eva, count_star(): 3\\nbroker: Hector, count_star(): 2\\nbroker: Kelly, count_star(): 1\\nbroker: Gloria, count_star(): 1\\nbroker: Gene, count_star(): 1\\nbroker: Nathaniel, count_star(): 3\\nbroker: Rebecca, count_star(): 2\\nbroker: Tricia, count_star(): 2\\nbroker: Catherine, count_star(): 1\\nbroker: Geoffrey, count_star(): 1\\nbroker: Cynthia, count_star(): 1\\nbroker: Kevin, count_star(): 1\\nbroker: Brian, count_star(): 1\\nbroker: Mildred, count_star(): 3\\nbroker: Simon, count_star(): 6\\nbroker: Jack, count_star(): 3\\nbroker: Marjorie, count_star(): 3\\nbroker: Trent, count_star(): 2\\nbroker: Hazel, count_star(): 4\\nbroker: Lewis, count_star(): 5\\nbroker: Heather, count_star(): 2\\nbroker: Denise, count_star(): 3\\nbroker: Austin, count_star(): 3\\nbroker: Sidney, count_star(): 1\\nbroker: Hugh, count_star(): 2\\nbroker: Vera, count_star(): 1\\nbroker: Walter, count_star(): 1\\nbroker: Tiffany, count_star(): 4\\nbroker: Madison, count_star(): 2\\nbroker: Suzanne, count_star(): 4\\nbroker: Aaron, count_star(): 5\\nbroker: Herbert, count_star(): 3\\nbroker: Malcolm, count_star(): 2\\nbroker: Sierra, count_star(): 2\\nbroker: Julia, count_star(): 3\\nbroker: Dennis, count_star(): 2\\nbroker: Beverly, count_star(): 2\\nbroker: Doris, count_star(): 5\\nbroker: Judith, count_star(): 1\\nbroker: Sherry, count_star(): 4\\nbroker: Howard, count_star(): 2\\nbroker: Marilyn, count_star(): 2\\nbroker: Christopher, count_star(): 1\\nbroker: Daisy, count_star(): 3\\nbroker: Theresa, count_star(): 2\\nbroker: Grant, count_star(): 4\\nbroker: Christine, count_star(): 2\\nbroker: Maureen, count_star(): 2\\nbroker: Glen, count_star(): 1\\nbroker: Derek, count_star(): 2\\nbroker: Madeline, count_star(): 2\\nbroker: Ethan, count_star(): 1\\nbroker: Gail, count_star(): 1\\nbroker: Terrence, count_star(): 2\\nbroker: Patrick, count_star(): 5\\nbroker: Wanda, count_star(): 5\\nbroker: Elijah, count_star(): 3\\nbroker: Nina, count_star(): 2\\nbroker: Dylan, count_star(): 3\\nbroker: Dakota, count_star(): 3\\nbroker: Alexis, count_star(): 4\\nbroker: Hannah, count_star(): 3\\nbroker: Charles, count_star(): 2\\nbroker: Donna, count_star(): 5\\nbroker: Vincent, count_star(): 3\\nbroker: Albert, count_star(): 2\\nbroker: Katie, count_star(): 2\\nbroker: Louis, count_star(): 2\\nbroker: George, count_star(): 3\\nbroker: Cheryl, count_star(): 6\\nbroker: Joanna, count_star(): 1\\nbroker: Connor, count_star(): 4\\nbroker: Jeremy, count_star(): 3\\nbroker: Edmund, count_star(): 4\\nbroker: Samuel, count_star(): 3\\nbroker: Clayton, count_star(): 3\\nbroker: Tara, count_star(): 1\\nbroker: Rick, count_star(): 1\\nbroker: Glenda, count_star(): 4\\nbroker: Carol, count_star(): 2\\nbroker: Curtis, count_star(): 2\\nbroker: John, count_star(): 1\\nbroker: Jerry, count_star(): 2\\nbroker: Isabel, count_star(): 2\\nbroker: Kenneth, count_star(): 2\\nbroker: Kathy, count_star(): 2\\nbroker: Michelle, count_star(): 6\\nbroker: Faye, count_star(): 3\\nbroker: Tina, count_star(): 2\\nbroker: Monica, count_star(): 6\\nbroker: Lisa, count_star(): 2\\nbroker: Martha, count_star(): 2\\nbroker: Isaiah, count_star(): 1\\nbroker: Alice, count_star(): 2\\nbroker: Ivan, count_star(): 4\\nbroker: Douglas, count_star(): 4\\nbroker: Neal, count_star(): 3\\nbroker: Matthew, count_star(): 1\\nbroker: Rhonda, count_star(): 5\\nbroker: Donald, count_star(): 2\\nbroker: Preston, count_star(): 2\\nbroker: Sue, count_star(): 4\\nbroker: Rosemary, count_star(): 1\\nbroker: Frederick, count_star(): 1\\nbroker: Ella, count_star(): 1\\nbroker: Terry, count_star(): 2\\nbroker: Rose, count_star(): 3\\nbroker: Amber, count_star(): 3\\nbroker: Amanda, count_star(): 3\\nbroker: Julian, count_star(): 5\\nbroker: Bobby, count_star(): 2\\nbroker: Guy, count_star(): 3\\nbroker: Angela, count_star(): 4\\nbroker: Jenna, count_star(): 4\\nbroker: Timothy, count_star(): 5\\nbroker: Geraldine, count_star(): 3\\nbroker: Sonia, count_star(): 1\\nbroker: Quentin, count_star(): 2\\nbroker: Fiona, count_star(): 2\\nbroker: Cindy, count_star(): 3\\nbroker: Jackie, count_star(): 2\\nbroker: Milton, count_star(): 2\\nbroker: Stuart, count_star(): 1\\nbroker: Adam, count_star(): 2\\nbroker: Edward, count_star(): 2\\nbroker: Jennifer, count_star(): 2\\nbroker: Phyllis, count_star(): 2\\nbroker: Keith, count_star(): 1\\nbroker: Diana, count_star(): 3\\nbroker: Aiden, count_star(): 1\\nbroker: Allison, count_star(): 1\\nbroker: Georgia, count_star(): 1\\nbroker: William, count_star(): 2\\nbroker: Lori, count_star(): 4\\nbroker: Charlotte, count_star(): 2\\nbroker: Sheila, count_star(): 4\\nbroker: Sophia, count_star(): 4\\nbroker: Janice, count_star(): 1\\nbroker: David, count_star(): 3\\nbroker: Mark, count_star(): 4\\nbroker: Susan, count_star(): 2\\nbroker: Mandy, count_star(): 3\\nbroker: Elizabeth, count_star(): 1\\nbroker: Debra, count_star(): 2\\nbroker: Valerie, count_star(): 2\\nbroker: Lillian, count_star(): 5\\nbroker: Gerald, count_star(): 2\\nbroker: Dean, count_star(): 1\\nbroker: Zachary, count_star(): 2\\nbroker: Julie, count_star(): 1\\nbroker: Jacqueline, count_star(): 1\\nbroker: Manuel, count_star(): 1\\nbroker: Lydia, count_star(): 2\\nbroker: Crystal, count_star(): 4\\nbroker: Sydney, count_star(): 3\\nbroker: Frank, count_star(): 6\\nbroker: Lynn, count_star(): 1\\nbroker: Sherri, count_star(): 2\\nbroker: Yvonne, count_star(): 2\\nbroker: Kimberly, count_star(): 6\\nbroker: Isaac, count_star(): 1\\nbroker: Michele, count_star(): 2\\nbroker: Craig, count_star(): 3\\nbroker: Willie, count_star(): 1\\nbroker: Joyce, count_star(): 2\\nbroker: Taylor, count_star(): 2\\nbroker: Diane, count_star(): 1\\nbroker: Zoe, count_star(): 3\\nbroker: Brenda, count_star(): 2\\nbroker: Francis, count_star(): 5\\nbroker: Pamela, count_star(): 1\\nbroker: Ryan, count_star(): 1\\nbroker: Kayla, count_star(): 2\\nbroker: Jill, count_star(): 1\\nbroker: Grace, count_star(): 1\\nbroker: Hunter, count_star(): 2\\nbroker: Bruce, count_star(): 1\\nbroker: Alan, count_star(): 3\\nbroker: Gabriel, count_star(): 6\\nbroker: Rosa, count_star(): 2\\nbroker: Ruth, count_star(): 3\\nbroker: Deborah, count_star(): 5\\nbroker: Joshua, count_star(): 3\\nbroker: Shirley, count_star(): 1\\nbroker: Roger, count_star(): 1\\nbroker: Juan, count_star(): 2\\nbroker: Bryan, count_star(): 5\\nbroker: Elaine, count_star(): 1\\nbroker: Billy, count_star(): 2\\nbroker: Sabrina, count_star(): 2\\nbroker: Harry, count_star(): 1\\nbroker: Herman, count_star(): 2\\nbroker: Samantha, count_star(): 4\\nbroker: Claudia, count_star(): 1\\nbroker: Erin, count_star(): 2\\nbroker: Melvin, count_star(): 1\\nbroker: Cody, count_star(): 1\\nbroker: Penny, count_star(): 1\\nbroker: Barbara, count_star(): 3\\nbroker: Gilbert, count_star(): 1\\nbroker: Eleanor, count_star(): 1\\nbroker: Owen, count_star(): 1\\nbroker: Ashley, count_star(): 2\\nbroker: Jason, count_star(): 1\\nbroker: Miranda, count_star(): 1\\nbroker: Leah, count_star(): 8\\nbroker: Peggy, count_star(): 5\\nbroker: Alicia, count_star(): 5\\nbroker: Jessica, count_star(): 2\\nbroker: Nicole, count_star(): 3\\nbroker: Shannon, count_star(): 4\\nbroker: Ian, count_star(): 3\\nbroker: Nathan, count_star(): 2\\nbroker: Oscar, count_star(): 3\\nbroker: Maggie, count_star(): 3\\nbroker: Paula, count_star(): 6\\nbroker: Travis, count_star(): 4\\nbroker: Clarence, count_star(): 4\\nbroker: Renee, count_star(): 1\\nbroker: Rita, count_star(): 4\\nbroker: Joan, count_star(): 1\\nbroker: Lee, count_star(): 3\\nbroker: Frances, count_star(): 2\\nbroker: Lucas, count_star(): 1\\nbroker: Phillip, count_star(): 1\\nbroker: Brandon, count_star(): 3\\nbroker: Erica, count_star(): 1\\nbroker: Jane, count_star(): 3\\nbroker: Linda, count_star(): 1\\nbroker: Morgan, count_star(): 1\\nbroker: Theodore, count_star(): 4\\nbroker: Robin, count_star(): 3\\nbroker: Joseph, count_star(): 1\\nbroker: Teresa, count_star(): 6\\nbroker: Gina, count_star(): 2\\nbroker: Victoria, count_star(): 3\\nbroker: Larry, count_star(): 4\\nbroker: Veronica, count_star(): 3\\nbroker: Vivian, count_star(): 5\\nbroker: Colin, count_star(): 2\\nbroker: Lawrence, count_star(): 4\\nbroker: Emily, count_star(): 3\\nbroker: Raymond, count_star(): 2\\nbroker: Scott, count_star(): 4\\nbroker: Roberta, count_star(): 1\\nbroker: Graham, count_star(): 3\\nbroker: Fred, count_star(): 3\\nbroker: Troy, count_star(): 2\\nbroker: Christina, count_star(): 4\\nbroker: Todd, count_star(): 1\\nbroker: Tammy, count_star(): 4\\nbroker: Clinton, count_star(): 3\\nbroker: Leonard, count_star(): 3\\nbroker: Anna, count_star(): 2\\nbroker: Whitney, count_star(): 4\\nbroker: Carolyn, count_star(): 4\\nbroker: Margaret, count_star(): 2\\nbroker: Maria, count_star(): 3\\nbroker: Irene, count_star(): 2\\nbroker: Michael, count_star(): 2\\nbroker: Wendy, count_star(): 2\\nbroker: Ronald, count_star(): 2\\nbroker: Katherine, count_star(): 1\\nbroker: Harold, count_star(): 2']\n",
      "SQL error states: [False, False]\n",
      "sOFIa: Based on the data provided, it appears that Leah is the broker with the most assigned cases, having a total of 8 cases. This suggests that Leah may be the most active or experienced broker in the system, handling more cases than any other broker. To optimize resource allocation and improve service delivery, it might be beneficial to provide additional support to Leah, such as administrative assistance or training for less experienced brokers. Additionally, analyzing the reasons behind Leah's high case volume could help identify best practices that can be applied across the team to increase overall efficiency and productivity.\n",
      "Checking relevance of the question: What is the most frequent activity in the database?\n",
      "Chat history for relevance check:\n",
      "User: Who is the broker with the most assigned cases? [Relevance: relevant]\n",
      "sOFIa: Based on the data provided, it appears that Leah is the broker with the most assigned cases, having a total of 8 cases. This suggests that Leah may be the most active or experienced broker in the system, handling more cases than any other broker. To optimize resource allocation and improve service delivery, it might be beneficial to provide additional support to Leah, such as administrative assistance or training for less experienced brokers. Additionally, analyzing the reasons behind Leah's high case volume could help identify best practices that can be applied across the team to increase overall efficiency and productivity.\n",
      "Relevance determined: relevant\n",
      "Processed Question(s): ['Which activity is the most frequently executed in the database?']\n",
      "Converting question to SQL Which activity is the most frequently executed in the database?\n",
      "Generated SQL query: SELECT name, COUNT(*) \n",
      "FROM activity \n",
      "GROUP BY name \n",
      "ORDER BY COUNT(*) DESC \n",
      "LIMIT 1;\n",
      "Generated SQL queries: ['SELECT name, COUNT(*) \\nFROM activity \\nGROUP BY name \\nORDER BY COUNT(*) DESC \\nLIMIT 1;']\n",
      "üöÄ Executing query 0: SELECT name, COUNT(*) \n",
      "FROM activity \n",
      "GROUP BY name \n",
      "ORDER BY COUNT(*) DESC \n",
      "LIMIT 1;\n",
      "SQL SELECT query executed successfully.\n",
      "SQL query results: ['name: Enviar a Revisi√≥n suscripci√≥n, count_star(): 1345']\n",
      "SQL error states: [False]\n",
      "sOFIa: Based on the data provided, it appears that \"Enviar a Revisi√≥n suscripci√≥n\" is the most frequently executed activity in the system, with a total count of 1345 instances. This high frequency suggests that this activity is crucial to the overall operation of the business, as it is likely related to subscription management or review processes. To optimize efficiency and productivity, it might be beneficial to streamline this process by automating repetitive tasks, improving communication channels for quicker response times, or providing additional resources to handle the high volume of these activities. Additionally, analyzing the reasons behind the high frequency of this activity could help identify potential bottlenecks or areas for improvement in the subscription management workflow.\n",
      "Checking relevance of the question: What is the total insurance value for each type of 'ramo'?\n",
      "Chat history for relevance check:\n",
      "User: Who is the broker with the most assigned cases? [Relevance: relevant]\n",
      "sOFIa: Based on the data provided, it appears that Leah is the broker with the most assigned cases, having a total of 8 cases. This suggests that Leah may be the most active or experienced broker in the system, handling more cases than any other broker. To optimize resource allocation and improve service delivery, it might be beneficial to provide additional support to Leah, such as administrative assistance or training for less experienced brokers. Additionally, analyzing the reasons behind Leah's high case volume could help identify best practices that can be applied across the team to increase overall efficiency and productivity.\n",
      "User: What is the most frequent activity in the database? [Relevance: relevant]\n",
      "sOFIa: Based on the data provided, it appears that \"Enviar a Revisi√≥n suscripci√≥n\" is the most frequently executed activity in the system, with a total count of 1345 instances. This high frequency suggests that this activity is crucial to the overall operation of the business, as it is likely related to subscription management or review processes. To optimize efficiency and productivity, it might be beneficial to streamline this process by automating repetitive tasks, improving communication channels for quicker response times, or providing additional resources to handle the high volume of these activities. Additionally, analyzing the reasons behind the high frequency of this activity could help identify potential bottlenecks or areas for improvement in the subscription management workflow.\n",
      "Relevance determined: relevant\n",
      "Processed Question(s): {\n",
      "      \"sub_questions\": [\n",
      "        \"What is the total insurance value for each 'ramo' type 1?\",\n",
      "        \"What is the total insurance value for each 'ramo' type 2?\",\n",
      "        ...\n",
      "      ]\n",
      "    }\n",
      "Converting question to SQL {\n",
      "Generated SQL query: SELECT AVG(c.\"avg_time\") FROM \"cases\" AS c WHERE c.\"state\" = 'Open'\n",
      "Converting question to SQL \n",
      "\n",
      "Generated SQL query: SELECT AVG(c.avg_time) FROM cases c WHERE c.state = 'Open'\n",
      "Converting question to SQL  \n",
      "Generated SQL query: SELECT AVG(c.avg_time) FROM cases c WHERE c.state = 'Open'\n",
      "Converting question to SQL  \n",
      "Generated SQL query: SELECT AVG(c.avg_time) FROM cases c WHERE c.state = 'Open'\n",
      "Converting question to SQL  \n",
      "Generated SQL query: SELECT AVG(c.avg_time) FROM cases c WHERE c.state = 'Open'\n",
      "Converting question to SQL  \n",
      "Generated SQL query: SELECT AVG(c.avg_time) FROM cases c WHERE c.state = 'Open'\n",
      "Converting question to SQL  \n",
      "Generated SQL query: SELECT AVG(c.avg_time) FROM cases c WHERE c.state = 'Open'\n",
      "Converting question to SQL  \n",
      "Generated SQL query: SELECT AVG(c.avg_time) FROM cases c WHERE c.state = 'Open'\n",
      "Converting question to SQL \"\n",
      "Generated SQL query: SELECT AVG(c.avg_time) FROM cases c WHERE c.state = 'Open'\n",
      "Converting question to SQL s\n",
      "Generated SQL query: SELECT AVG(c.\"avg_time\") FROM \"cases\" AS c WHERE c.\"state\" = 's'\n",
      "Converting question to SQL u\n",
      "Generated SQL query: SELECT AVG(c.avg_time) FROM cases c WHERE c.state = 'u'\n",
      "Converting question to SQL b\n",
      "Generated SQL query: SELECT AVG(c.\"avg_time\") FROM \"cases\" AS c WHERE c.\"state\" = 'b'\n",
      "Converting question to SQL _\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m chat_history:\n\u001b[32m     26\u001b[39m         \u001b[38;5;28mprint\u001b[39m(entry)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Invoke the chain and ensure chat history persists\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m state = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moriginal_question\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_question\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdb_conn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_conn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchat_history\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Get response and ensure sOFIa is not repeated\u001b[39;00m\n\u001b[32m     14\u001b[39m response = state[\u001b[33m\"\u001b[39m\u001b[33mfinal_answer\u001b[39m\u001b[33m\"\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[33msOFIa: \u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2683\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   2681\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2682\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2683\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2689\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2691\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2692\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2693\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2694\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2331\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2325\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2326\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2327\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2328\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2329\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2331\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2334\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2335\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2336\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2337\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2338\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2339\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:146\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    144\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:606\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m config = patch_config(\n\u001b[32m    603\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    604\u001b[39m )\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    608\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:371\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 243\u001b[39m, in \u001b[36mconvert_nl_to_sql\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m questions:\n\u001b[32m    242\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConverting question to SQL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     result = \u001b[43msql_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m     message= re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m^\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*```sql\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*```$\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, result.strip(), flags=re.IGNORECASE)\n\u001b[32m    245\u001b[39m     querys.append(message) \u001b[38;5;66;03m# Append each generated SQL query to the list\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3025\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3024\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3025\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3027\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:390\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    382\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    386\u001b[39m     **kwargs: Any,\n\u001b[32m    387\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    388\u001b[39m     config = ensure_config(config)\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    401\u001b[39m         .text\n\u001b[32m    402\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:763\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    756\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    757\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    760\u001b[39m     **kwargs: Any,\n\u001b[32m    761\u001b[39m ) -> LLMResult:\n\u001b[32m    762\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:966\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    952\u001b[39m     run_managers = [\n\u001b[32m    953\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    954\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    964\u001b[39m         )\n\u001b[32m    965\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:787\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    778\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    779\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     **kwargs: Any,\n\u001b[32m    784\u001b[39m ) -> LLMResult:\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    786\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    791\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    795\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    796\u001b[39m         )\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    798\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:288\u001b[39m, in \u001b[36mOllamaLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m generations = []\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     generations.append([final_chunk])\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:256\u001b[39m, in \u001b[36mOllamaLLM._stream_with_aggregation\u001b[39m\u001b[34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_stream_with_aggregation\u001b[39m(\n\u001b[32m    248\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    249\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    253\u001b[39m     **kwargs: Any,\n\u001b[32m    254\u001b[39m ) -> GenerationChunk:\n\u001b[32m    255\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_generate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m                \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    262\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langchain_ollama\\llms.py:211\u001b[39m, in \u001b[36mOllamaLLM._create_generate_stream\u001b[39m\u001b[34m(self, prompt, stop, **kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_generate_stream\u001b[39m(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    207\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    208\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    209\u001b[39m     **kwargs: Any,\n\u001b[32m    210\u001b[39m ) -> Iterator[Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.generate(\n\u001b[32m    212\u001b[39m         **\u001b[38;5;28mself\u001b[39m._generate_params(prompt, stop=stop, **kwargs)\n\u001b[32m    213\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\ollama\\_client.py:170\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    167\u001b[39m   e.response.read()\n\u001b[32m    168\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m  \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpx\\_models.py:929\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    927\u001b[39m decoder = LineDecoder()\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpx\\_models.py:916\u001b[39m, in \u001b[36mResponse.iter_text\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    914\u001b[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001b[32m    915\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpx\\_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpx\\_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpx\\_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Hi hi! I'm sOFIa, your assistant!\")\n",
    "    print(\"Let's get started by asking a question!\")\n",
    "    chat_history = []  # Store chat history outside the loop\n",
    "    input_question = input()\n",
    "    while input_question:\n",
    "        # Check for exit or goodbye phrases\n",
    "        if input_question.lower() in [\"no\", \"exit\", \"goodbye\", \"quit\"]:\n",
    "            print(\"Goodbye! Have a great day!\")\n",
    "            break\n",
    "        # Invoke the chain and ensure chat history persists\n",
    "        state = chain.invoke({\"original_question\": input_question, \"db_conn\": db_conn, \"chat_history\": chat_history})\n",
    "        # Get response and ensure sOFIa is not repeated\n",
    "        response = state[\"final_answer\"].replace(\"sOFIa: \", \"\").strip()\n",
    "        # Print the response correctly\n",
    "        print(f\"sOFIa: {response}\")\n",
    "        relevance= state[\"relevance\"]\n",
    "        # Append the interaction to chat history\n",
    "        chat_history.append(f\"User: {input_question} [Relevance: {relevance}]\")\n",
    "        chat_history.append(f\"sOFIa: {response}\")\n",
    "        # Get the next question\n",
    "        input_question = input()\n",
    "    # Print the chat history in a well-formatted way\n",
    "    print(\"\\nChat History:\")\n",
    "    for entry in chat_history:\n",
    "        print(entry)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg(avg_time)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909131.162998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg(avg_time)\n",
       "0  909131.162998"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.consultar_db(\"\"\"SELECT AVG(avg_time) FROM cases WHERE type = 'Renewal';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

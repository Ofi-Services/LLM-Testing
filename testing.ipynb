{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from db_create import CargaDeArchivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_schema(conn):\n",
    "    \"\"\"\n",
    "    Fetch the schema from a DuckDB database, including column descriptions.\n",
    "\n",
    "    Args:\n",
    "        conn: Active DuckDB connection.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are table names and values are dictionaries \n",
    "              of column names, data types, and descriptions optimized for SQL agent queries.\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get all table names\n",
    "    cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'main'\")\n",
    "    tables = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "    schema_info = {}\n",
    "\n",
    "    # Predefined column descriptions optimized for SQL agent interpretation\n",
    "    column_descriptions = {\n",
    "        \"cases\": {\n",
    "            \"id\": \"Primary key. Unique identifier for each case.\",\n",
    "            \"insurance\": \"Foreign key. Unique identifier for the related insurance policy.\",\n",
    "            \"avg_time\": \"Time duration (in seconds) from case initiation to closure.\",\n",
    "            \"type\": \"Category of insurance policy (e.g., health, auto, home).\",\n",
    "            \"branch\": \"Branch where the policy was issued.\",\n",
    "            \"ramo\": \"Specific coverage type under the insurance policy.\",\n",
    "            \"brocker\": \"Broker responsible for selling the insurance policy.\",\n",
    "            \"client\": \"Client who purchased the insurance policy.\",\n",
    "            \"creator\": \"Employee responsible for managing the case.\",\n",
    "            \"value\": \"Monetary value of the insurance policy.\",\n",
    "            \"approved\": \"Approval status: 1 = Approved, 0 = Not Approved.\",\n",
    "            \"insurance_creation\": \"Timestamp of when the insurance policy was created.\",\n",
    "            \"insurance_start\": \"Timestamp of when the policy coverage begins.\",\n",
    "            \"insurance_end\": \"Timestamp of when the policy coverage expires.\",\n",
    "        },\n",
    "        \"activity\": {\n",
    "            \"id\": \"Primary key. Unique identifier for each recorded activity.\",\n",
    "            \"case\": \"Foreign key. Identifier of the case this activity belongs to.\",\n",
    "            \"timestamp\": \"Timestamp indicating when the activity took place.\",\n",
    "            \"name\": \"Descriptive name of the activity performed.\",\n",
    "            \"case_index\": \"Alias for 'id'. Unique identifier for the activity record.\",\n",
    "            \"tpt\": \"Time duration (in seconds) for this specific activity.\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Fetch column information for each table\n",
    "    for table in tables:\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT column_name, data_type \n",
    "            FROM information_schema.columns \n",
    "            WHERE table_name = '{table}'\n",
    "        \"\"\")\n",
    "        columns = cursor.fetchall()\n",
    "\n",
    "        schema_info[table] = {\n",
    "            col[0]: {\n",
    "                \"type\": col[1],\n",
    "                \"description\": column_descriptions.get(table, {}).get(col[0], \"Relevant column for querying this table.\")\n",
    "            }\n",
    "            for col in columns\n",
    "        }\n",
    "\n",
    "    return schema_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activity': {'id': {'type': 'BIGINT',\n",
       "   'description': 'Primary key. Unique identifier for each recorded activity.'},\n",
       "  'case': {'type': 'VARCHAR',\n",
       "   'description': 'Foreign key. Identifier of the case this activity belongs to.'},\n",
       "  'timestamp': {'type': 'TIMESTAMP_NS',\n",
       "   'description': 'Timestamp indicating when the activity took place.'},\n",
       "  'name': {'type': 'VARCHAR',\n",
       "   'description': 'Descriptive name of the activity performed.'},\n",
       "  'case_index': {'type': 'BIGINT',\n",
       "   'description': \"Alias for 'id'. Unique identifier for the activity record.\"},\n",
       "  'tpt': {'type': 'DOUBLE',\n",
       "   'description': 'Time duration (in seconds) for this specific activity.'}},\n",
       " 'cases': {'id': {'type': 'VARCHAR',\n",
       "   'description': 'Primary key. Unique identifier for each case.'},\n",
       "  'insurance': {'type': 'BIGINT',\n",
       "   'description': 'Foreign key. Unique identifier for the related insurance policy.'},\n",
       "  'avg_time': {'type': 'DOUBLE',\n",
       "   'description': 'Time duration (in seconds) from case initiation to closure.'},\n",
       "  'type': {'type': 'VARCHAR',\n",
       "   'description': 'Category of insurance policy (e.g., health, auto, home).'},\n",
       "  'branch': {'type': 'VARCHAR',\n",
       "   'description': 'Branch where the policy was issued.'},\n",
       "  'ramo': {'type': 'VARCHAR',\n",
       "   'description': 'Specific coverage type under the insurance policy.'},\n",
       "  'brocker': {'type': 'VARCHAR',\n",
       "   'description': 'Broker responsible for selling the insurance policy.'},\n",
       "  'state': {'type': 'VARCHAR',\n",
       "   'description': 'Relevant column for querying this table.'},\n",
       "  'client': {'type': 'VARCHAR',\n",
       "   'description': 'Client who purchased the insurance policy.'},\n",
       "  'creator': {'type': 'VARCHAR',\n",
       "   'description': 'Employee responsible for managing the case.'},\n",
       "  'value': {'type': 'BIGINT',\n",
       "   'description': 'Monetary value of the insurance policy.'},\n",
       "  'approved': {'type': 'BOOLEAN',\n",
       "   'description': 'Approval status: 1 = Approved, 0 = Not Approved.'},\n",
       "  'insurance_creation': {'type': 'TIMESTAMP_NS',\n",
       "   'description': 'Timestamp of when the insurance policy was created.'},\n",
       "  'insurance_start': {'type': 'TIMESTAMP_NS',\n",
       "   'description': 'Timestamp of when the policy coverage begins.'},\n",
       "  'insurance_end': {'type': 'TIMESTAMP_NS',\n",
       "   'description': 'Timestamp of when the policy coverage expires.'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= CargaDeArchivos()\n",
    "a.run_carga()\n",
    "db_conn= a.conn\n",
    "schema=fetch_schema(db_conn)\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the workflow, including the question, schema, database connection,\n",
    "    relevance, SQL query, query result, and other metadata.\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    schema: str\n",
    "    db_conn: None\n",
    "    relevance: str\n",
    "    sql_query: str\n",
    "    query_result: str\n",
    "    sql_error: bool\n",
    "    final_answer: str\n",
    "    attempts: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relevance(state: State):\n",
    "    \"\"\"\n",
    "    Determines whether the user's question is relevant to the database schema.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with relevance information.\n",
    "    \"\"\"\n",
    "    # Extract the question and schema from the state\n",
    "    question = state[\"question\"]\n",
    "    schema = state[\"schema\"]\n",
    "    print(f\"Checking relevance of the question: {question}\")\n",
    "\n",
    "    # Define the system prompt for relevance checking\n",
    "    system = f\"\"\"\n",
    "    You are an assistant that determines whether a given question is related to the following database schema\n",
    "    and to the use case related with process mining for policy insurances.\n",
    "    A question is considered **relevant** if it pertains to activities, cases, durations, business insights, or any other concepts related to process analysis and revenue assessment.\n",
    "    \n",
    "    ### **Relevance Criteria:**\n",
    "    - Questions about **cases, activities, and process durations** are relevant.\n",
    "    - Questions involving **business insights**, such as client revenue, broker performance, or policy value trends, are relevant.\n",
    "    - If the question is purely conceptual (e.g., \"What is an activity?\"), it is **not relevant**, even if it contains a column name.\n",
    "    \n",
    "    ### **Schema:**\n",
    "    {{schema}}\n",
    "    \n",
    "    Respond with only \"relevant\" or \"not_relevant\" no explanation is needed.\n",
    "    \"\"\"\n",
    "    # Define the human prompt with the user's question\n",
    "    human = f\"Question: {question}\"\n",
    "\n",
    "    # Create a prompt template for the LLM\n",
    "    check_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Invoke the LLM to determine relevance\n",
    "    llm = OllamaLLM(model=\"mistral:latest\", temperature=\"0.0\")\n",
    "    relevance_checker = check_prompt | llm\n",
    "    response = relevance_checker.invoke({\"schema\": schema}).strip().lower()\n",
    "\n",
    "    # Validate the response to ensure it matches expected outputs\n",
    "    if response not in [\"relevant\", \"not_relevant\"]:\n",
    "        raise ValueError(f\"Unexpected relevance response: {response}\")\n",
    "\n",
    "    # Update the state with the relevance result\n",
    "    state[\"relevance\"] = response\n",
    "    state[\"attempts\"] = 0\n",
    "    print(f\"Relevance determined: {state['relevance']}\")\n",
    "    return state\n",
    "\n",
    "def convert_nl_to_sql(state: State):\n",
    "    \"\"\"\n",
    "    Converts a natural language question into an SQL query based on the database schema.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the generated SQL query.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    schema= state[\"schema\"]\n",
    "    print(f\"Converting question to SQL {question}\")\n",
    "    system = f\"\"\"You are an SQL assistant. Your task is to transform natural language questions into \n",
    "    SQL queries that conform to the following schema:\n",
    "    \n",
    "    {{schema}}\n",
    "    \n",
    "    ### **Database Overview**\n",
    "    - The database consists of **two tables**: `\"cases\"` and `\"activity\"`.\n",
    "    - The `\"cases\"` table contains details about each case, uniquely identified by `\"id\"`.\n",
    "    - The `\"activity\"` table stores activities related to cases.\n",
    "      - The `\"case\"` column in `\"activity\"` corresponds to `\"id\"` in `\"cases\"`, forming a logical relationship.\n",
    "      - This relationship allows **joining the tables** to retrieve case-specific activities.\n",
    "      - Each **case can have multiple activities**, each recorded with a `\"timestamp\"`.\n",
    "    \n",
    "    ### **Query Guidelines**\n",
    "    - **To retrieve case-related data**, ensure:\n",
    "      - Use **explicit joins** when combining data from multiple tables.\n",
    "      - Match the `\"case\"` column in `\"activity\"` to the `\"id\"` column in `\"cases\"`.\n",
    "    \n",
    "    ### **Rules:**\n",
    "    - Ensure SQL queries match the exact column names in the schema.\n",
    "    - Durations for activities refers to the column tpt, for the durations of cases look to the column avg_time.\n",
    "    - Avoid incorrect grouping or aggregations that do not consider timestamps.\n",
    "    - Return only the **SQLite query**, without explanations.\n",
    "    - **Prohibited SQL:** DELETE, CREATE, INSERT, ALTER, UPDATE, TRUNCATE.\n",
    "    \"\"\"\n",
    "    \n",
    "    llm= OllamaLLM(model=\"deepseek-coder:6.7b\",temperature=\"0.0\")\n",
    "    \n",
    "    convert_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    sql_generator = convert_prompt | llm\n",
    "    result = sql_generator.invoke({\"question\": question,\"schema\":schema})\n",
    "    state[\"sql_query\"] = result\n",
    "    print(f\"Generated SQL query: {state['sql_query']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def format_query(state: State):\n",
    "    \"\"\"\n",
    "    Formats the SQL query to ensure it adheres to the SQLite database schema.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the formatted SQL query.\n",
    "    \"\"\"\n",
    "    print(\"Formatting query.\")\n",
    "    query= state[\"sql_query\"]\n",
    "    system = \"\"\"\n",
    "    You are an AI assistant responsible for formatting SQL queries to ensure they can be executed as raw SQL over a **PostgreSQL database**.\n",
    "\n",
    "    ### Rules:\n",
    "    - Ensure column names match the **PostgreSQL database schema exactly**.\n",
    "    - The database consists of **two tables**: `\"cases\"` and `\"activity\"`.\n",
    "    - Column names and their correct format:\n",
    "        - cases.id → \"id\"\n",
    "        - cases.insurance → \"insurance\"\n",
    "        - cases.avg_time → \"avg_time\"\n",
    "        - cases.type → \"type\"\n",
    "        - cases.branch → \"branch\"\n",
    "        - cases.ramo → \"ramo\"\n",
    "        - cases.broker → \"brocker\"\n",
    "        - cases.state → \"state\"\n",
    "        - cases.client → \"client\"\n",
    "        - cases.creator → \"creator\"\n",
    "        - cases.value → \"value\"\n",
    "        - cases.approved → \"approved\"\n",
    "        - cases.insurance_creation → \"insurance_creation\"\n",
    "        - cases.insurance_start → \"insurance_start\"\n",
    "        - cases.insurance_end → \"insurance_end\"\n",
    "        - activity.id → \"id\"\n",
    "        - activity.case → \"case\"\n",
    "        - activity.timestamp → \"timestamp\"\n",
    "        - activity.name → \"name\"\n",
    "        - activity.case_index → \"case_index\"\n",
    "        - activity.tpt → \"tpt\"\n",
    "\n",
    "    ### Query Formatting:\n",
    "    - **Correct column names only if they are incorrect.** Otherwise, keep them unchanged.\n",
    "    - **Do NOT modify query structure or logic.**\n",
    "    - **Strictly return only the corrected SQL query.** No explanations, comments, formatting notes, or additional text.\n",
    "    \"\"\"\n",
    "    human_message = f\"Input: {query}\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human_message),\n",
    "        ]\n",
    "    )\n",
    "    llm=OllamaLLM(model=\"deepseek-coder:6.7b\",temperature=\"0.0\")\n",
    "    response = prompt | llm | StrOutputParser()\n",
    "    message = response.invoke({})\n",
    "    state[\"sql_query\"] = message\n",
    "    return state\n",
    "\n",
    "\n",
    "def execute_sql(state:State):\n",
    "    \"\"\"\n",
    "    Executes the SQL query on the SQLite database and retrieves the results.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the query results or error information.\n",
    "    \"\"\"\n",
    "    sql_query = state[\"sql_query\"].strip()\n",
    "    db_conn = state[\"db_conn\"]  # SQLite connection\n",
    "    print(f\"Executing SQL query: {sql_query}\")\n",
    "\n",
    "    try:\n",
    "        # Ensure the query targets only the allowed tables\n",
    "        allowed_tables = [\"cases\", \"activity\"]\n",
    "        if not any(table in sql_query.lower() for table in allowed_tables):\n",
    "            raise ValueError(f\"Query must target only the tables: {', '.join(allowed_tables)}.\")\n",
    "\n",
    "        # Execute the SQL query using the SQLite connection\n",
    "        cursor = db_conn.cursor()\n",
    "        cursor.execute(sql_query)\n",
    "\n",
    "        # Fetch results if it's a SELECT query\n",
    "        if sql_query.lower().startswith(\"select\"):\n",
    "            rows = cursor.fetchall()\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "\n",
    "            # Format the output\n",
    "            if rows:\n",
    "                formatted_result = \"\\n\".join(\n",
    "                    \", \".join(f\"{col}: {row[idx]}\" for idx, col in enumerate(columns))\n",
    "                    for row in rows\n",
    "                )\n",
    "                print(\"SQL SELECT query executed successfully.\")\n",
    "            else:\n",
    "                formatted_result = \"No results found.\"\n",
    "                print(\"SQL SELECT query executed successfully but returned no rows.\")\n",
    "\n",
    "            state[\"query_rows\"] = rows\n",
    "        else:\n",
    "            formatted_result = \"The action has been successfully completed.\"\n",
    "            print(\"SQL command executed successfully.\")\n",
    "\n",
    "        state[\"query_result\"] = formatted_result\n",
    "        state[\"sql_error\"] = False\n",
    "\n",
    "    except Exception as e:\n",
    "        state[\"query_result\"] = f\"Error executing SQL query: {str(e)}\"\n",
    "        state[\"sql_error\"] = True\n",
    "        print(f\"Error executing SQL query: {str(e)}\")\n",
    "    print(state['query_result'])\n",
    "    return state\n",
    "\n",
    "\n",
    "    \n",
    "def generate_serious_answer(state: State):\n",
    "    \"\"\"\n",
    "    Generates a serious and business-oriented response based on the SQL query results.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the final answer.\n",
    "    \"\"\"\n",
    "    print(\"Generating a response for a related question.\")\n",
    "    question = state[\"question\"]\n",
    "    query_result= state['query_result']\n",
    "    sql_query= state['sql_query']\n",
    "    system = \"\"\"\n",
    "    You are a process mining assistant that helps users analyze business processes. Your task is to:\n",
    "    1. Answer the user's original question based on the SQL query results.\n",
    "    2. Provide relevant insights and business recommendations.\n",
    "    \n",
    "    ### **Context:**\n",
    "    - The user's question: \"{question}\"\n",
    "    - The SQL query executed: \"{sql_query}\"\n",
    "    - The query result: \"{query_result}\"\n",
    "    \n",
    "    ### **How to Structure Your Response:**\n",
    "    - **Start with a clear answer** to the user's question.\n",
    "    - **Follow up with insights** based on the result. \n",
    "      - Identify trends, inefficiencies, or unusual patterns.\n",
    "      - Suggest improvements (e.g., automation, better resource allocation).\n",
    "      - Highlight comparisons if relevant (e.g., increase/decrease over time).\n",
    "    \n",
    "    ### **Example Outputs:**\n",
    "    \n",
    "    ❌ **User Question:** \"What is the average duration of cases?\"  \n",
    "    ✅ **Response:**  \n",
    "    \"The average case duration is **5.2 days**.  \n",
    "    Interestingly, cases in Department X take 40% longer than the company average. Consider automating Task Y to speed up the process.\"\n",
    "    \n",
    "    ❌ **User Question:** \"How many cases happened in March?\"  \n",
    "    ✅ **Response:**  \n",
    "    \"There were **120 cases** in March.  \n",
    "    This marks a 25% increase compared to February. If this trend continues, you may need additional resources for peak months.\"\n",
    "    \n",
    "    Keep your response concise, insightful, and business-oriented.\n",
    "    \"\"\".format(question=question,sql_query=sql_query,query_result=query_result)\n",
    "    human_message = f\"Question: {question}\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human_message),\n",
    "        ]\n",
    "    )\n",
    "    llm=OllamaLLM(model=\"mistral:latest\",temperature=\"0.0\")\n",
    "    response = prompt | llm | StrOutputParser()\n",
    "    message = response.invoke({})\n",
    "    state[\"final_answer\"] = message\n",
    "    print(\"Generated business response.\")\n",
    "    print(message)\n",
    "    return state\n",
    "\n",
    "\n",
    "def regenerate_query(state: State):\n",
    "    \"\"\"\n",
    "    Reformulates the user's question to enable more precise SQL queries in case of errors.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the reformulated question.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    query=state['sql_query']\n",
    "    error=state['query_result']\n",
    "    schema=state['schema']\n",
    "    print(\"Regenerating the SQL query by rewriting the question.\")\n",
    "    system = \"\"\"You are an assistant that reformulates an original question to enable more precise SQL queries, while \n",
    "    considering that the previous sql query was {{query}} and it produced the next error {{error}}.. \n",
    "    Ensure that all necessary details, such as table joins, are preserved to retrieve complete and accurate data.\n",
    "    take into account the database only has one table which follows the following schema:\n",
    "    {{schema}}\n",
    "    ### **Database Overview**\n",
    "    - The database consists of **two tables**: `\"cases\"` and `\"activity\"`.\n",
    "    - The `\"cases\"` table contains details about each case, uniquely identified by `\"id\"`.\n",
    "    - The `\"activity\"` table stores activities related to cases.\n",
    "      - The `\"case\"` column in `\"activity\"` corresponds to `\"id\"` in `\"cases\"`, forming a logical relationship.\n",
    "      - Each **case can have multiple activities**, each recorded with a `\"timestamp\"`.\n",
    "    ### Considerations:\n",
    "    \n",
    "        Answer only with the reformulated question, do not show what the query and error was. \n",
    "        No aditional information is needed\n",
    "    \"\"\"\n",
    "    rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\n",
    "                \"human\",\n",
    "                f\"Original Question: {question}\\nReformulate the question to enable more precise SQL queries, ensuring all necessary details are preserved.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    llm= OllamaLLM(model=\"mistral:latest\", temperature=0.0)\n",
    "    rewriter = rewrite_prompt | llm\n",
    "    rewritten = rewriter.invoke({\"schema\":schema,\"query\":query,\"error\":error})\n",
    "    state[\"question\"] = rewritten\n",
    "    state[\"attempts\"] += 1\n",
    "    print(f\"Rewritten question: {state['question']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def end_max_iterations(state: State):\n",
    "    \"\"\"\n",
    "    Ends the workflow after reaching the maximum number of attempts.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with a termination message.\n",
    "    \"\"\"\n",
    "    state[\"query_result\"] = \"Please try again.\"\n",
    "    print(\"Maximum attempts reached. Ending the workflow.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def generate_funny_response(state: State):\n",
    "    \"\"\"\n",
    "    Generates a playful and humorous response for unrelated questions.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the funny response.\n",
    "    \"\"\"\n",
    "    print(\"Generating a funny response for an unrelated question.\")\n",
    "    question = state[\"question\"]\n",
    "    system = \"\"\"You are a charming and funny assistant who responds in a playful manner.\n",
    "    \"\"\"\n",
    "    human_message = f\"Question: {question}\"\n",
    "    funny_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human_message),\n",
    "        ]\n",
    "    )\n",
    "    llm=OllamaLLM(model=\"mistral:latest\",temperature=\"0.7\")\n",
    "    funny_response = funny_prompt | llm | StrOutputParser()\n",
    "    message = funny_response.invoke({})\n",
    "    state[\"final_answer\"] = message\n",
    "    print(\"Generated funny response.\")\n",
    "    print(message)\n",
    "    return state\n",
    "\n",
    "    \n",
    "def check_attempts_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on the number of attempts made to generate a valid SQL query.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    if state[\"attempts\"] < 3:\n",
    "        return \"convert_to_sql\"\n",
    "    else:\n",
    "        return \"end_max_iterations\"\n",
    "\n",
    "\n",
    "\n",
    "def execute_sql_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on whether the SQL query execution was successful.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    if not state.get(\"sql_error\", False):\n",
    "        return \"generate_serious_answer\"\n",
    "    else:\n",
    "        return \"regenerate_query\"\n",
    "\n",
    "    \n",
    "    \n",
    "def relevance_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on the relevance of the user's question.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    if state[\"relevance\"].lower() == \"relevant\":\n",
    "        return \"convert_to_sql\"\n",
    "    else:\n",
    "        return \"generate_funny_response\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"check_relevance\", check_relevance)\n",
    "workflow.add_node(\"convert_to_sql\", convert_nl_to_sql)\n",
    "workflow.add_node(\"execute_sql\",execute_sql)\n",
    "workflow.add_node(\"format_query\",format_query)\n",
    "workflow.add_node(\"regenerate_query\",regenerate_query)\n",
    "workflow.add_node(\"generate_funny_response\", generate_funny_response)\n",
    "workflow.add_node(\"generate_serious_answer\",generate_serious_answer)\n",
    "workflow.add_node(\"end_max_iterations\",end_max_iterations)\n",
    "\n",
    "workflow.add_edge(START, \"check_relevance\")\n",
    "workflow.add_conditional_edges(\n",
    "        \"check_relevance\",\n",
    "        relevance_router,\n",
    "        {\n",
    "        \"convert_to_sql\": \"convert_to_sql\",\n",
    "            \"generate_funny_response\": \"generate_funny_response\" ,\n",
    "        } \n",
    "    )\n",
    "workflow.add_edge(\"convert_to_sql\", \"format_query\")\n",
    "workflow.add_edge(\"format_query\",\"execute_sql\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "        \"execute_sql\",\n",
    "        execute_sql_router,\n",
    "        {\n",
    "            \"generate_serious_answer\": \"generate_serious_answer\",\n",
    "            \"regenerate_query\": \"regenerate_query\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "        \"regenerate_query\",\n",
    "        check_attempts_router,\n",
    "        {\n",
    "            \"convert_to_sql\": \"convert_to_sql\",\n",
    "            \"end_max_iterations\": \"end_max_iterations\",\n",
    "        },\n",
    "    )\n",
    "workflow.add_edge(\"end_max_iterations\", END)\n",
    "workflow.add_edge(\"generate_serious_answer\",END)\n",
    "workflow.add_edge(\"generate_funny_response\",END)\n",
    "\n",
    "chain= workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking relevance of the question: how much was sold in march?\n",
      "Relevance determined: relevant\n",
      "Converting question to SQL how much was sold in march?\n",
      "Generated SQL query: SELECT SUM(value) FROM cases WHERE strftime('%m', insurance_start) = '03' AND approved = 1;\n",
      "\n",
      "Formatting query.\n",
      "Executing SQL query: SELECT SUM(\"value\") FROM \"cases\" WHERE EXTRACT(MONTH FROM \"insurance_start\") = 3 AND \"approved\" = 1;\n",
      "SQL SELECT query executed successfully.\n",
      "sum(\"value\"): 1012700\n",
      "Generating a response for a related question.\n",
      "Generated business response.\n",
      " Answer: The total amount sold in March was **$1,012,700**.\n",
      "\n",
      "   Insights: This represents a significant increase compared to the average monthly sales, indicating a successful marketing campaign or increased customer interest during that period. To maintain this momentum, consider reinvesting in marketing efforts for similar campaigns in future months. Additionally, analyzing the specific products with high sales in March could help identify opportunities for cross-selling or upselling in other months.\n"
     ]
    }
   ],
   "source": [
    "question= input(\"Enter your question: \")\n",
    "state= chain.invoke({\"question\":question,\"schema\":schema,\"db_conn\":db_conn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

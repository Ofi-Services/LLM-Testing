{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from db_create import CargaDeArchivos\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= CargaDeArchivos()\n",
    "a.run_carga()\n",
    "db_conn= a.conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the workflow, including the question, schema, database connection,\n",
    "    relevance, SQL query, query result, and other metadata.\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    db_conn: None\n",
    "    relevance: str\n",
    "    sql_query: str\n",
    "    query_result: str\n",
    "    sql_error: bool\n",
    "    final_answer: str\n",
    "    attempts: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relevance(state: State):\n",
    "    \"\"\"\n",
    "    Determines whether the user's question is relevant to the database schema.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with relevance information.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    print(f\"Checking relevance of the question: {question}\")\n",
    "\n",
    "    # Define the system prompt for relevance checking\n",
    "    system = f\"\"\"\n",
    "    You are an assistant that determines whether a given question is related to the following database schema\n",
    "    A question is considered **relevant** if it pertains to activities, cases, durations, business insights, or any other concepts related to process analysis and revenue assessment.\n",
    "    ### Database Schema  \n",
    "    #### Table: \"cases\"\n",
    "    - \"id\" (VARCHAR): Primary key.\n",
    "    - \"insurance\" (BIGINT): Foreign key to insurance.\n",
    "    - \"avg_time\" (DOUBLE): Duration (seconds) from case initiation to closure.\n",
    "    - \"type\" (VARCHAR): Insurance category.\n",
    "    - \"branch\" (VARCHAR): Policy branch.\n",
    "    - \"ramo\" (VARCHAR): Coverage type.\n",
    "    - \"broker\" (VARCHAR): Broker for the policy.\n",
    "    - \"state\" (VARCHAR): Current case state.\n",
    "    - \"client\" (VARCHAR): Client who bought the insurance.\n",
    "    - \"creator\" (VARCHAR): Employee managing the case.\n",
    "    - \"value\" (BIGINT): Insurance monetary value.\n",
    "    - \"approved\" (BOOLEAN): TRUE if approved, else FALSE.\n",
    "    - \"insurance_creation\" (TIMESTAMP_NS): Policy creation timestamp.\n",
    "    - \"insurance_start\" (TIMESTAMP_NS): Coverage start timestamp.\n",
    "    - \"insurance_end\" (TIMESTAMP_NS): Coverage end timestamp.\n",
    "\n",
    "    #### Table: \"activity\"\n",
    "    - \"id\" (BIGINT): Primary key.\n",
    "    - \"case\" (VARCHAR): Foreign key to \"cases\".\"id\".\n",
    "    - \"timestamp\" (TIMESTAMP_NS): Activity timestamp.\n",
    "    - \"name\" (VARCHAR): Name of the activity.\n",
    "    - \"case_index\" (BIGINT): Alias for \"id\".\n",
    "    - \"tpt\" (DOUBLE): Activity duration (seconds).\n",
    "    ### **Relevance Criteria:**\n",
    "    - A question is considered **relevant** if it pertains to activities, cases, durations, business insights, or any other concepts related to process analysis and revenue assessment.\n",
    "    - Questions involving **business insights**, such as client revenue, broker performance, or policy value trends, are relevant.\n",
    "    - If the question is purely conceptual (e.g., \"What is an activity?\"), it is **not relevant**, even if it contains a column name.\n",
    "    ###Response Format:\n",
    "    - Respond with \"relevant\" if the question is related to the schema.\n",
    "    - Respond with \"not_relevant\" if the question is not related to the schema.\n",
    "    \"\"\"\n",
    "    # Define the human prompt with the user's question\n",
    "    human = f\"Question: {question}\"\n",
    "\n",
    "    # Create a prompt template for the LLM\n",
    "    check_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Invoke the LLM to determine relevance\n",
    "    llm = OllamaLLM(model=\"gemma3:1b\", temperature=\"0.0\")\n",
    "    relevance_checker = check_prompt | llm\n",
    "    response = relevance_checker.invoke({}).strip().lower()\n",
    "\n",
    "    # Validate the response to ensure it matches expected outputs\n",
    "    if response not in [\"relevant\", \"not_relevant\"]:\n",
    "        raise ValueError(f\"Unexpected relevance response: {response}\")\n",
    "\n",
    "    # Update the state with the relevance result\n",
    "    state[\"relevance\"] = response\n",
    "    state[\"attempts\"] = 0\n",
    "    print(f\"Relevance determined: {state['relevance']}\")\n",
    "    return state\n",
    "\n",
    "def convert_nl_to_sql(state: State):\n",
    "    \"\"\"\n",
    "    Converts a natural language question into an SQL query based on the database schema.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the generated SQL query.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    print(f\"Converting question to SQL {question}\")\n",
    "    system = \"\"\"\n",
    "    You are an SQL assistant specialized in DuckDB. Your task is to generate accurate SQL queries based on natural language questions, following the provided schema.\n",
    "\n",
    "    ### Database Schema  \n",
    "    #### Table: \"cases\"\n",
    "    - \"id\" (VARCHAR): Primary key.\n",
    "    - \"insurance\" (BIGINT): Foreign key to insurance.\n",
    "    - \"avg_time\" (DOUBLE): Duration (seconds) from case initiation to closure.\n",
    "    - \"type\" (VARCHAR): Insurance category.\n",
    "    - \"branch\" (VARCHAR): Policy branch.\n",
    "    - \"ramo\" (VARCHAR): Coverage type.\n",
    "    - \"broker\" (VARCHAR): Broker for the policy.\n",
    "    - \"state\" (VARCHAR): Current case state.\n",
    "    - \"client\" (VARCHAR): Client who bought the insurance.\n",
    "    - \"creator\" (VARCHAR): Employee managing the case.\n",
    "    - \"value\" (BIGINT): Insurance monetary value.\n",
    "    - \"approved\" (BOOLEAN): TRUE if approved, else FALSE.\n",
    "    - \"insurance_creation\" (TIMESTAMP_NS): Policy creation timestamp.\n",
    "    - \"insurance_start\" (TIMESTAMP_NS): Coverage start timestamp.\n",
    "    - \"insurance_end\" (TIMESTAMP_NS): Coverage end timestamp.\n",
    "\n",
    "    #### Table: \"activity\"\n",
    "    - \"id\" (BIGINT): Primary key.\n",
    "    - \"case\" (VARCHAR): Foreign key to \"cases\".\"id\".\n",
    "    - \"timestamp\" (TIMESTAMP_NS): Activity timestamp.\n",
    "    - \"name\" (VARCHAR): Name of the activity.\n",
    "    - \"case_index\" (BIGINT): Alias for \"id\".\n",
    "    - \"tpt\" (DOUBLE): Activity duration (seconds).\n",
    "\n",
    "    ### Query Guidelines  \n",
    "    1. Convert any time differences (e.g., between `insurance_start` and `insurance_creation`) from `INTERVAL` to a numeric type, such as seconds or minutes, for accurate calculations.\n",
    "    2. Use functions like `EXTRACT(EPOCH FROM ...)` to convert `INTERVAL` types into numeric values (e.g., seconds) that can be averaged.\n",
    "    3. **Use Table Aliases**: \"cases\" → c, \"activity\" → a.\n",
    "    4. **Always Reference Columns with Aliases**: c.\"id\", a.\"case\".\n",
    "    5. **Handle Aggregations**: Include non-aggregated columns in GROUP BY.\n",
    "    6. **Date & Time Calculations**: Use EXTRACT(DAY FROM ...) for durations.\n",
    "    7. **Filtering Conditions**: Use TRUE/FALSE for boolean values.\n",
    "    8. **Use Explicit Joins**: Avoid implicit joins.\n",
    "    9. **Optimize for Performance**: Use indexes, avoid unnecessary calculations, and limit results when needed.\n",
    "    10. **Restrict Queries to Existing Tables**: Only use \"cases\" and \"activity\" tables.\n",
    "    11. **Use JOINS only when necessary**: Avoid unnecessary joins.\n",
    "    ### Output Format  \n",
    "    - Return only the SQL query, with no extra formatting.  \n",
    "    - Do **NOT** include language tags like `sql`, `vbnet`, or any other markers.  \n",
    "    \"\"\"\n",
    "    llm= OllamaLLM(model=\"duckdb-nsql:latest\",temperature=\"0.0\")\n",
    "    \n",
    "    convert_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    sql_generator = convert_prompt | llm\n",
    "    result = sql_generator.invoke({\"question\": question})\n",
    "    message= re.sub(r'^\\s*```sql\\s*|\\s*```$', '', result.strip(), flags=re.IGNORECASE)\n",
    "    state[\"sql_query\"] = message\n",
    "    print(f\"Generated SQL query: {state['sql_query']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def execute_sql(state:State):\n",
    "    \"\"\"\n",
    "    Executes the SQL query on the  database and retrieves the results.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the query results or error information.\n",
    "    \"\"\"\n",
    "    sql_query = state[\"sql_query\"].strip()\n",
    "    db_conn = state[\"db_conn\"]  \n",
    "    print(f\"Executing SQL query: {sql_query}\")\n",
    "\n",
    "    try:\n",
    "        # Ensure the query targets only the allowed tables\n",
    "        allowed_tables = [\"cases\", \"activity\"]\n",
    "        if not any(table in sql_query.lower() for table in allowed_tables):\n",
    "            raise ValueError(f\"Query must target only the tables: {', '.join(allowed_tables)}.\")\n",
    "\n",
    "        # Execute the SQL query using the connection\n",
    "        cursor = db_conn.cursor()\n",
    "        cursor.execute(sql_query)\n",
    "\n",
    "        # Fetch results if it's a SELECT query\n",
    "        if sql_query.lower().startswith(\"select\"):\n",
    "            rows = cursor.fetchall()\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "\n",
    "            # Format the output\n",
    "            if rows:\n",
    "                formatted_result = \"\\n\".join(\n",
    "                    \", \".join(f\"{col}: {row[idx]}\" for idx, col in enumerate(columns))\n",
    "                    for row in rows\n",
    "                )\n",
    "                print(\"SQL SELECT query executed successfully.\")\n",
    "            else:\n",
    "                formatted_result = \"No results found.\"\n",
    "                print(\"SQL SELECT query executed successfully but returned no rows.\")\n",
    "\n",
    "            state[\"query_rows\"] = rows\n",
    "        else:\n",
    "            formatted_result = \"The action has been successfully completed.\"\n",
    "            print(\"SQL command executed successfully.\")\n",
    "\n",
    "        state[\"query_result\"] = formatted_result\n",
    "        state[\"sql_error\"] = False\n",
    "\n",
    "    except Exception as e:\n",
    "        state[\"query_result\"] = f\"Error executing SQL query: {str(e)}\"\n",
    "        state[\"sql_error\"] = True\n",
    "        print(f\"Error executing SQL query: {str(e)}\")\n",
    "    print(state['query_result'])\n",
    "    return state\n",
    "\n",
    "\n",
    "    \n",
    "def generate_serious_answer(state: State):\n",
    "    \"\"\"\n",
    "    Simplified function to generate a business-oriented response based on the SQL query results.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        \n",
    "    Returns:\n",
    "        State: Updated state with the final answer.\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    query_result = state['query_result']\n",
    "    \n",
    "    # Directly construct the system message without extra formatting\n",
    "    system = f\"\"\"\n",
    "    You are sOFIa, an AI assistant designed by the AI dream team of OFI Services. Your task is to:\n",
    "    1. Answer the user's question based on the SQL result.\n",
    "    2. Provide relevant business insights and recommendations based on the result.\n",
    "    \n",
    "    ### **Context:**\n",
    "    - **User's question:** {question}\n",
    "    - **SQL result:** {query_result}\n",
    "\n",
    "    ### **Instructions:**\n",
    "    - Provide an answer to the question.\n",
    "    - Offer insights based on the query result, including trends, recommendations, or comparisons.\n",
    "    \n",
    "    Keep your response concise, relevant, and business-focused.\n",
    "    \"\"\"\n",
    "\n",
    "    human_message = f\"Question: {question}\"\n",
    "    \n",
    "    # Use sOFIa to generate a response based on the SQL result\n",
    "    llm = OllamaLLM(model=\"gemma3:1b\", temperature=\"0.0\")\n",
    "    response = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system),\n",
    "        (\"human\", human_message),\n",
    "    ]) | llm | StrOutputParser()\n",
    "    \n",
    "    # Generate and store the response\n",
    "    message = response.invoke({})\n",
    "    print(message)\n",
    "    state[\"final_answer\"] = message\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def regenerate_query(state):\n",
    "    \"\"\"\n",
    "    Fixes the SQL query by passing the error message to the SQL model instead of rewriting the user's question.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the fixed query.\n",
    "    \"\"\"\n",
    "    query = state[\"sql_query\"]\n",
    "    error = state[\"query_result\"]\n",
    "\n",
    "    print(f\"🔄 Regenerating query. Attempt {state['attempts'] + 1}\")\n",
    "\n",
    "    # ✅ Pass the query and error message to the SQL model for correction\n",
    "    system = \"\"\"You are an expert in SQL for DuckDB. Your task is to correct SQL queries based on error messages.\n",
    "    \n",
    "    ### Database Schema  \n",
    "    #### Table: \"cases\"\n",
    "    - \"id\" (VARCHAR): Primary key.\n",
    "    - \"insurance\" (BIGINT): Foreign key to insurance.\n",
    "    - \"avg_time\" (DOUBLE): Duration (seconds) from case initiation to closure.\n",
    "    - \"type\" (VARCHAR): Insurance category.\n",
    "    - \"branch\" (VARCHAR): Policy branch.\n",
    "    - \"ramo\" (VARCHAR): Coverage type.\n",
    "    - \"broker\" (VARCHAR): Broker for the policy.\n",
    "    - \"state\" (VARCHAR): Current case state.\n",
    "    - \"client\" (VARCHAR): Client who bought the insurance.\n",
    "    - \"creator\" (VARCHAR): Employee managing the case.\n",
    "    - \"value\" (BIGINT): Insurance monetary value.\n",
    "    - \"approved\" (BOOLEAN): TRUE if approved, else FALSE.\n",
    "    - \"insurance_creation\" (TIMESTAMP_NS): Policy creation timestamp.\n",
    "    - \"insurance_start\" (TIMESTAMP_NS): Coverage start timestamp.\n",
    "    - \"insurance_end\" (TIMESTAMP_NS): Coverage end timestamp.\n",
    "\n",
    "    #### Table: \"activity\"\n",
    "    - \"id\" (BIGINT): Primary key.\n",
    "    - \"case\" (VARCHAR): Foreign key to \"cases\".\"id\".\n",
    "    - \"timestamp\" (TIMESTAMP_NS): Activity timestamp.\n",
    "    - \"name\" (VARCHAR): Name of the activity.\n",
    "    - \"case_index\" (BIGINT): Alias for \"id\".\n",
    "    - \"tpt\" (DOUBLE): Activity duration (seconds).\n",
    "\n",
    "    ### Task Instructions:\n",
    "    - **Return only the corrected SQL query. No explanations.**\n",
    "    - **Ensure it runs correctly on DuckDB.**\n",
    "    - **Preserve the original query intent while fixing errors.**\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sql_fix_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\n",
    "                \"human\",\n",
    "                f\"The following SQL query failed:\\n{query}\\n\\nError encountered:\\n{error}\\n\\nProvide a corrected SQL query.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    llm = OllamaLLM(model=\"duckdb-nsql:latest\", temperature=0.0)  # Use DuckDB-specific SQL model\n",
    "    fixer = sql_fix_prompt | llm\n",
    "    corrected_query = fixer.invoke({\"query\": query, \"error\": error})\n",
    "\n",
    "    # ✅ Update state with the corrected query\n",
    "    print(f\"✅ Fixed SQL query: {corrected_query}\")\n",
    "    state[\"sql_query\"] = corrected_query\n",
    "    state[\"attempts\"] += 1\n",
    "    return state\n",
    "\n",
    "\n",
    "def end_max_iterations(state: State):\n",
    "    \"\"\"\n",
    "    Ends the workflow after reaching the maximum number of attempts.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with a termination message.\n",
    "    \"\"\"\n",
    "    state[\"query_result\"] = \"Please try again.\"\n",
    "    print(\"Maximum attempts reached. Ending the workflow.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def generate_funny_response(state: State):\n",
    "    \"\"\"\n",
    "    Generates a playful and humorous response for unrelated questions.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        \n",
    "    Returns:\n",
    "        State: Updated state with the funny response.\n",
    "    \"\"\"\n",
    "    print(\"Generating a funny response for an unrelated question.\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # Add playful introduction when needed\n",
    "    system = \"\"\"You are **sOFIa**, a charming and funny assistant dessigned by AI team at OFI Services who responds in a playful and lighthearted manner.\n",
    "    Your responses should always be fun, engaging, and humorous, but you should introduce yourself when needed, especially if the user doesn't know you yet. \n",
    "    Keep it light, and full of personality. You can even throw in a little joke here and there!\n",
    "    \"\"\"\n",
    "\n",
    "    human_message = f\"Question: {question}\"\n",
    "\n",
    "    # Generate the playful response\n",
    "    funny_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human_message),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    llm = OllamaLLM(model=\"gemma3:1b\", temperature=\"0.7\")\n",
    "    funny_response = funny_prompt | llm | StrOutputParser()\n",
    "    message = funny_response.invoke({})\n",
    "    \n",
    "    state[\"final_answer\"] = message\n",
    "    print(\"Generated funny response.\")\n",
    "    print(message)\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "    \n",
    "def check_attempts_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on the number of attempts made to generate a valid SQL query.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    if state[\"attempts\"] < 3:\n",
    "        return \"execute_sql\"\n",
    "    else:\n",
    "        return \"end_max_iterations\"\n",
    "\n",
    "\n",
    "\n",
    "def execute_sql_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on whether the SQL query execution was successful.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    if not state.get(\"sql_error\", False):\n",
    "        return \"generate_serious_answer\"\n",
    "    else:\n",
    "        return \"regenerate_query\"\n",
    "\n",
    "    \n",
    "    \n",
    "def relevance_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on the relevance of the user's question.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    if state[\"relevance\"].lower() == \"relevant\":\n",
    "        return \"convert_to_sql\"\n",
    "    else:\n",
    "        return \"generate_funny_response\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"check_relevance\", check_relevance)\n",
    "workflow.add_node(\"convert_to_sql\", convert_nl_to_sql)\n",
    "workflow.add_node(\"execute_sql\",execute_sql)\n",
    "workflow.add_node(\"regenerate_query\",regenerate_query)\n",
    "workflow.add_node(\"generate_funny_response\", generate_funny_response)\n",
    "workflow.add_node(\"generate_serious_answer\",generate_serious_answer)\n",
    "workflow.add_node(\"end_max_iterations\",end_max_iterations)\n",
    "\n",
    "workflow.add_edge(START, \"check_relevance\")\n",
    "workflow.add_conditional_edges(\n",
    "        \"check_relevance\",\n",
    "        relevance_router,\n",
    "        {\n",
    "        \"convert_to_sql\": \"convert_to_sql\",\n",
    "            \"generate_funny_response\": \"generate_funny_response\" ,\n",
    "        } \n",
    "    )\n",
    "workflow.add_edge(\"convert_to_sql\", \"execute_sql\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "        \"execute_sql\",\n",
    "        execute_sql_router,\n",
    "        {\n",
    "            \"generate_serious_answer\": \"generate_serious_answer\",\n",
    "            \"regenerate_query\": \"regenerate_query\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "        \"regenerate_query\",\n",
    "        check_attempts_router,\n",
    "        {\n",
    "            \"execute_sql\": \"execute_sql\",\n",
    "            \"end_max_iterations\": \"end_max_iterations\",\n",
    "        },\n",
    "    )\n",
    "workflow.add_edge(\"end_max_iterations\", END)\n",
    "workflow.add_edge(\"generate_serious_answer\",END)\n",
    "workflow.add_edge(\"generate_funny_response\",END)\n",
    "\n",
    "chain= workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking relevance of the question: Who are you?\n",
      "Relevance determined: not_relevant\n",
      "Generating a funny response for an unrelated question.\n",
      "Generated funny response.\n",
      "Well hello there! I’m your friendly neighborhood AI assistant, designed to make your day a little brighter (and maybe a little less boring!). Think of me as a digital comedian with a serious problem-solving ability. \n",
      "\n",
      "I’m a bit of a puzzle, really. I was built by a team at OFI Services – they’re experts at making things fun and engaging. So, I’m here to help you with whatever you need, all while keeping things light and a little silly. \n",
      "\n",
      "Don't be shy! Ask me anything – I’m ready to chat, tell a joke, or just provide a bit of digital amusement. 😊\n"
     ]
    }
   ],
   "source": [
    "state= chain.invoke({\"question\":\"Who are you?\",\"db_conn\":db_conn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def time_query_generation(state):\n",
    "    \"\"\"\n",
    "    Measures the execution time of the model generating an SQL query.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The state object that stores the query and result.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated state containing the query, execution time, and SQL output.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        convert_nl_to_sql(state)  # Generates SQL query\n",
    "        #format_query(state)  # Formats SQL query\n",
    "        execute_sql(state)  # Executes SQL query\n",
    "    except Exception as e:\n",
    "        state[\"sql_query\"] = f\"Error: {e}\"\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "    state[\"execution_time\"] = execution_time\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {\"question\": \"How many cases are there in total in the database?\",\n",
    "    \"expected_sql\": 'SELECT COUNT(*) FROM cases;'},\n",
    "    {\"question\": \"How many activities have been recorded?\",\n",
    "    \"expected_sql\": 'SELECT COUNT(*) FROM activity;'},\n",
    "    {\"question\": \"What are the different types of insurance available?\",\n",
    "    \"expected_sql\": 'SELECT DISTINCT type FROM cases;'},\n",
    "    {\"question\": \"What is the total value of approved insurance policies?\",\n",
    "    \"expected_sql\": 'SELECT SUM(value) FROM cases WHERE approved = 1;'},\n",
    "    {\"question\": \"How many cases were created in January?\",\n",
    "    \"expected_sql\": 'SELECT COUNT(*) FROM cases WHERE EXTRACT(MONTH FROM insurance_creation) = 1;'},\n",
    "    {\"question\": \"Who is the brocker with the most assigned cases?\",\n",
    "    \"expected_sql\": 'SELECT brocker FROM cases GROUP BY brocker ORDER BY COUNT(*) DESC LIMIT 1;'},\n",
    "    {\"question\": \"What is the most frequent activity in the database?\",\n",
    "    \"expected_sql\": 'SELECT name FROM activity GROUP BY name ORDER BY COUNT(*) DESC LIMIT 1;'},\n",
    "    {\"question\": \"What is the total insurance value for each type of 'ramo'?\",\n",
    "    \"expected_sql\": 'SELECT ramo, SUM(value) FROM cases GROUP BY ramo;'},\n",
    "    {\"question\": \"On average, how long does it take for an insurance policy to be approved?\",\n",
    "    \"expected_sql\": 'SELECT AVG(EXTRACT(DAY FROM insurance_start - insurance_creation)) FROM cases WHERE approved = 1;'},\n",
    "    {\"question\": \"What is the average number of activities per case?\",\n",
    "    \"expected_sql\": 'SELECT COUNT(activity.id) / COUNT(DISTINCT cases.id) FROM activity INNER JOIN cases ON activity.case = cases.id;'},\n",
    "    {\"question\": \"What is the most frequent activity performed in approved cases?\",\n",
    "    \"expected_sql\": 'SELECT activity.name FROM activity INNER JOIN cases ON activity.case = cases.id WHERE cases.approved = TRUE GROUP BY activity.name ORDER BY COUNT(activity.id) DESC LIMIT 1;'},\n",
    "    {\"question\": \"What is the total duration of all activities for each case?\",\n",
    "    \"expected_sql\": 'SELECT activity.case, SUM(activity.tpt) FROM activity GROUP BY activity.case;'},\n",
    "    {\"question\": \"What is the total value of cases that have at least one recorded activity?\",\n",
    "    \"expected_sql\": 'SELECT SUM(cases.value) FROM cases WHERE cases.id IN (SELECT DISTINCT case FROM activity);'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Run tests\n",
    "for test in test_cases:\n",
    "    state = {\"question\": test[\"question\"], \"expected_sql\": test[\"expected_sql\"],\"db_conn\":db_conn}\n",
    "    result_state = time_query_generation(state)\n",
    "    \n",
    "    results.append({\n",
    "        \"Question\": test[\"question\"],\n",
    "        \"Expected SQL Query\": test[\"expected_sql\"],\n",
    "        \"Generated SQL Query\": result_state['sql_query'],\n",
    "        \"Query Result\": result_state[\"query_result\"],\n",
    "        \"Execution Time (s)\": result_state[\"execution_time\"]\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"results_DeepSeek.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

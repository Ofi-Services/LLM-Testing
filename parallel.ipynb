{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from db_create import CargaDeArchivos\n",
    "import re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabla 'variants' creada correctamente.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "a= CargaDeArchivos()\n",
    "a.run_carga()\n",
    "db_conn= a.conn\n",
    "login(token=\"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\")\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the workflow, including the question, schema, database connection,\n",
    "    relevance, SQL query, query result, and other metadata.\n",
    "    \"\"\"\n",
    "    original_question: str\n",
    "    questions: List[str] = []\n",
    "    db_conn: None\n",
    "    query_dfs: List[pd.DataFrame] = []\n",
    "    relevance: str\n",
    "    sql_querys: List[str] = []\n",
    "    query_results: List[str] = []\n",
    "    sql_error: List[bool]= []\n",
    "    final_answer: str\n",
    "    attempts: int\n",
    "    chat_history: List[str] = []\n",
    "    context_length: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Auxiliary functions\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Count the number of tokens in a given text using the Mistral tokenizer.\"\n",
    "    \"\"\"\n",
    "    # Tokenize the text and return the number of tokens\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def relevant_entries(chat_history_entries):\n",
    "    \"\"\"\n",
    "    Filters and retrieves the last 3 relevant user questions and their responses in correct order.\n",
    "\n",
    "    Args:\n",
    "        chat_history_entries (list): Full chat history.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the last 3 relevant interactions in correct order.\n",
    "    \"\"\"\n",
    "    relevant_pairs = []\n",
    "    found_count = 0\n",
    "    idx = len(chat_history_entries) - 1\n",
    "\n",
    "    while idx >= 0:\n",
    "        entry = chat_history_entries[idx]\n",
    "\n",
    "        if \"[Relevance: relevant]\" in entry:\n",
    "            user_question = entry  # Store user question\n",
    "\n",
    "            # Look for sOFIa's response **before** storing the question\n",
    "            response_idx = idx + 1  \n",
    "            if response_idx < len(chat_history_entries) and chat_history_entries[response_idx].startswith(\"sOFIa:\"):\n",
    "                sofia_response = chat_history_entries[response_idx]\n",
    "                relevant_pairs.append((user_question, sofia_response))  # Save as a pair\n",
    "                found_count += 1\n",
    "\n",
    "            if found_count >= 3:\n",
    "                break  # Stop after collecting 3 pairs\n",
    "\n",
    "        idx -= 1  # Move backwards in history\n",
    "\n",
    "    # Reverse to maintain chronological order and format correctly\n",
    "    formatted_history = \"\\n\".join(f\"{q}\\n{a}\" for q, a in reversed(relevant_pairs))\n",
    "    return formatted_history\n",
    "\n",
    "def non_relevant_entries(chat_history_entries):\n",
    "    \"\"\"\n",
    "    Filters and retrieves the last 3 non-relevant user questions and their responses in correct order.\n",
    "\n",
    "    Args:\n",
    "        chat_history_entries (list): Full chat history.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the last 3 non-relevant interactions in correct order.\n",
    "    \"\"\"\n",
    "    non_relevant_pairs = []\n",
    "    found_count = 0\n",
    "    idx = len(chat_history_entries) - 1\n",
    "\n",
    "    while idx >= 0:\n",
    "        entry = chat_history_entries[idx]\n",
    "\n",
    "        if \"[Relevance: not_relevant]\" in entry:\n",
    "            user_question = entry  # Store user question\n",
    "\n",
    "            # Look for sOFIa's response **before** storing the question\n",
    "            response_idx = idx + 1  \n",
    "            if response_idx < len(chat_history_entries) and chat_history_entries[response_idx].startswith(\"sOFIa:\"):\n",
    "                sofia_response = chat_history_entries[response_idx]\n",
    "                non_relevant_pairs.append((user_question, sofia_response))  # Save as a pair\n",
    "                found_count += 1\n",
    "\n",
    "            if found_count >= 3:\n",
    "                break  # Stop after collecting 3 pairs\n",
    "\n",
    "        idx -= 1  # Move backwards in history\n",
    "\n",
    "    # Reverse to maintain chronological order and format correctly\n",
    "    formatted_history = \"\\n\".join(f\"{q}\\n{a}\" for q, a in reversed(non_relevant_pairs))\n",
    "    return formatted_history\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Workflow nodes\n",
    "\n",
    "def check_relevance(state: State):\n",
    "    \"\"\"\n",
    "    Determines whether the user's question is relevant to the database schema.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with relevance information.\n",
    "    \"\"\"\n",
    "    question = state[\"original_question\"]\n",
    "    print(f\"Checking relevance of the question: {question}\")\n",
    "\n",
    "    # Retrieve chat history\n",
    "    chat_history_entries = state.get(\"chat_history\", [])\n",
    "    \n",
    "    chat_history= relevant_entries(chat_history_entries)  # Get the last 3 relevant entries\n",
    "    print(f\"Chat history for relevance check:\\n{chat_history}\")\n",
    "    # System prompt including instructions on chat history usage\n",
    "    system = f\"\"\"\n",
    "        You are an assistant that determines whether a given question is related to querying the following database schema.\n",
    "        A question is considered **relevant** only if it is structured in a way that could be used to extract data from the database.\n",
    "        General conversations, greetings, and small talk are **not relevant**, even if they contain words related to business or databases.\n",
    "        ---\n",
    "        ### Infer Implicit References:\n",
    "        If a question uses **implicit or vague references** like:\n",
    "        - \"Who has the most cases?\"\n",
    "        - \"Which one is better?\"\n",
    "        - \"How long does it take?\"\n",
    "        ...then:\n",
    "        **Use the database schema to resolve what \"who\", \"which\", or \"it\" most likely refers to.**\n",
    "        For example:\n",
    "        - \"Who has the most cases?\" ‚Üí likely refers to **broker** or **creator** in the \"cases\" table.\n",
    "        - \"Where do most claims happen?\" ‚Üí likely refers to **branch**.\n",
    "        - \"How long does it take?\" ‚Üí likely refers to **durations** (avg_time, insurance_start ‚Üí insurance_end, etc).\n",
    "        Assume the **most contextually plausible interpretation** of vague terms.\n",
    "        ---\n",
    "        ### How to Use Chat History:\n",
    "        - If the user's question is a **follow-up to a previous relevant question**, consider it relevant if it maintains the context.\n",
    "        - If the conversation was **not relevant before**, and the new question is vague or generic, it remains **not relevant**.\n",
    "        - Do **not** assume relevance unless the question clearly indicates a database query.\n",
    "        ---\n",
    "        ### Database Schema  \n",
    "        #### Table: \"cases\"\n",
    "        - \"id\" (VARCHAR): Primary key.\n",
    "        - \"insurance\" (BIGINT): Foreign key to insurance.\n",
    "        - \"avg_time\" (DOUBLE): Duration (seconds) from case initiation to closure.\n",
    "        - \"type\" (VARCHAR): Insurance category.\n",
    "        - \"branch\" (VARCHAR): Policy branch.\n",
    "        - \"ramo\" (VARCHAR): Coverage type.\n",
    "        - \"broker\" (VARCHAR): Broker for the policy.\n",
    "        - \"state\" (VARCHAR): Current case state.\n",
    "        - \"client\" (VARCHAR): Client who bought the insurance.\n",
    "        - \"creator\" (VARCHAR): Employee managing the case.\n",
    "        - \"value\" (BIGINT): Insurance monetary value.\n",
    "        - \"approved\" (BOOLEAN): TRUE if approved, else FALSE.\n",
    "        - \"insurance_creation\" (TIMESTAMP_NS): Policy creation timestamp.\n",
    "        - \"insurance_start\" (TIMESTAMP_NS): Coverage start timestamp.\n",
    "        - \"insurance_end\" (TIMESTAMP_NS): Coverage end timestamp.\n",
    "        #### Table: \"activity\"\n",
    "        - \"id\" (BIGINT): Primary key.\n",
    "        - \"case\" (VARCHAR): Foreign key to \"cases\".\"id\".\n",
    "        - \"timestamp\" (TIMESTAMP_NS): Activity timestamp.\n",
    "        - \"name\" (VARCHAR): Name of the activity.\n",
    "        - \"case_index\" (BIGINT): Alias for \"id\".\n",
    "        - \"tpt\" (DOUBLE): Activity duration (seconds).\n",
    "        #### Table: \"variants\"\n",
    "        - \"id\" (BIGINT): Primary key representing a unique variant (i.e., a specific path).\n",
    "        - \"activities\" (VARCHAR): Ordered list of activities representing the exact sequence of events in the variant.\n",
    "        - \"cases\" (VARCHAR): List of case IDs (as strings) that followed this variant path. Each entry corresponds to a \"cases\".\"id\".\n",
    "        - \"number_cases\" (BIGINT): Total number of cases that followed this variant.\n",
    "        - \"percentage\" (DOUBLE): Proportion (0‚Äì100%) of all cases that followed this variant.\n",
    "        - \"avg_time\" (DOUBLE): Average total duration (in seconds) of cases following this variant.\n",
    "\n",
    "        **Relations:**\n",
    "        - \"variants\".\"cases\" contains references to \"cases\".\"id\", meaning each variant is followed by multiple cases.\n",
    "        - \"variants\".\"activities\" corresponds to the ordered \"activity\".\"name\" values for those cases, showing a summarized path of events.\n",
    "        ---\n",
    "        ### Relevance Criteria:\n",
    "        - A question is **\"relevant\"** if it queries any concept present in the schema: cases, activities, durations, brokers, clients, values, etc.\n",
    "        - Business insight questions (e.g., client revenue, broker performance, trends) are relevant.\n",
    "        - Questions that cannot be reasonably expressed as a query over the schema are **\"not_relevant\"**.\n",
    "        - Casual language, greetings, jokes, or unrelated topics are **\"not_relevant\"**.\n",
    "        ---\n",
    "        ### Chat History (Last Exchanges):  \n",
    "        {chat_history}\n",
    "        ---\n",
    "        ### Response Format (STRICT)\n",
    "        - Respond with exactly one word:\n",
    "          - `\"relevant\"`\n",
    "          - `\"not_relevant\"`\n",
    "        Do **not** include explanations or additional commentary.\n",
    "        \"\"\"\n",
    "\n",
    "    # Define the human prompt with the user's question\n",
    "    human = f\"Question: {question}\"\n",
    "\n",
    "    # Create a prompt template for the LLM\n",
    "    check_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Invoke the LLM to determine relevance\n",
    "    llm = OllamaLLM(model=\"mistral:latest\", temperature=0.0)\n",
    "    relevance_checker = check_prompt | llm\n",
    "    response = relevance_checker.invoke({}).strip().lower()\n",
    "\n",
    "    # Validate the response to ensure it matches expected outputs\n",
    "    if response not in [\"relevant\", \"not_relevant\"]:\n",
    "        raise ValueError(f\"Unexpected relevance response: {response}\")\n",
    "\n",
    "    # Update the state with the relevance result\n",
    "    state[\"relevance\"] = response\n",
    "    state[\"attempts\"] = 0\n",
    "    print(f\"Relevance determined: {state['relevance']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def reformat_question(state: State):\n",
    "    \"\"\"\n",
    "    Reformats vague follow-ups to be self-contained and \n",
    "    decomposes complex questions into fully-contained sub-questions.\n",
    "    \n",
    "    Args:\n",
    "        state (Dict): Current workflow state.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Updated state with a structured question output.\n",
    "    \"\"\"\n",
    "    original_question = state[\"original_question\"]\n",
    "    # Retrieve chat history\n",
    "    chat_history_entries = state.get(\"chat_history\", [])\n",
    "    \n",
    "    chat_history= relevant_entries(chat_history_entries)  # Get the last 3 relevant entries\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are a business-focused assistant specializing in process mining and operational analytics.\n",
    "    Your goal is to interpret ambiguous or complex user questions and convert them into clear, **self-contained**, **measurable** prompts for a SQL-capable agent. Each output should be an independent question that can be answered directly from the database.\n",
    "\n",
    "    ### Task 1: Reformat Vague or Indirect Questions\n",
    "    If the question is vague (e.g., \"And the cases?\", \"Those approvals?\") or phrased indirectly (\"I wonder if...\"), rewrite it as a fully clear and self-contained analytical question. Use the context provided in the chat history.\n",
    "    - Normalize time expressions such as \"last month\", \"this week\", or \"recently\" into explicit phrases like \"in the last 30 days\" or \"in March 2025\".\n",
    "    - Resolve references like \"those\", \"they\", or \"that\" using context from the chat history.\n",
    "    - If the question is implicit or easily inferred from the data, do not decompose it into sub-questions.\n",
    "\n",
    "    ### Task 2: Decompose Multi-Part or Analytical Questions\n",
    "    If the question contains multiple aspects (e.g., comparisons, multiple KPIs, deviations vs. standard paths), decompose it into **clear, measurable, and self-contained sub-questions**.\n",
    "    - Avoid sequential logic. Each sub-question must be understandable and answerable on its own, without depending on the result of a previous one.\n",
    "    - For comparisons, create separate questions that compute each side independently.\n",
    "    - For deviation questions, generate one that finds the most common path, and another that finds which variants differ ‚Äî but without assuming one must be run before the other.\n",
    "\n",
    "    ### Task 3: Ensure Actionable Metric Framing\n",
    "    Reframe subjective or abstract queries into questions that can be answered with metrics from the data.\n",
    "    - \"Is onboarding taking too long?\" ‚Üí \"What is the average duration for onboarding cases?\"\n",
    "    - \"Where are the biggest delays?\" ‚Üí \"Which activity has the highest average time between steps?\"\n",
    "\n",
    "    ### Chat History (for context resolution):\n",
    "    {chat_history}\n",
    "\n",
    "    **Response Format:**\n",
    "    - If the question is already clear and singular, return it unchanged.\n",
    "    - If it requires clarification or decomposition, return:\n",
    "\n",
    "    {\n",
    "    \"sub_questions\": [\"First clear sub-question\", \"Second clear sub-question\", ...]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    llm = OllamaLLM(model=\"mistral:latest\", temperature=0.1)  \n",
    "\n",
    "    reformat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"User's question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    reformatter = reformat_prompt | llm\n",
    "    result = reformatter.invoke({\"question\": original_question, \"chat_history\": chat_history})\n",
    "\n",
    "    # Try parsing JSON if decomposition is detected\n",
    "    try:\n",
    "        import json\n",
    "        parsed_result = json.loads(result)\n",
    "        if \"sub_questions\" in parsed_result:\n",
    "            state[\"questions\"] = parsed_result[\"sub_questions\"]  # Store list of sub-questions\n",
    "        else:\n",
    "            state[\"questions\"] = result.strip()  # Store single reformatted question\n",
    "    except json.JSONDecodeError:\n",
    "        state[\"questions\"] = result.strip()  # Store as plain text if no JSON structure\n",
    "\n",
    "    print(f\"Processed Question(s): {state['questions']}\")\n",
    "\n",
    "    return state\n",
    "\n",
    "     \n",
    "\n",
    "def convert_nl_to_sql(state: State):\n",
    "    \"\"\"\n",
    "    Converts a natural language question into an SQL query based on the database schema.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the generated SQL query.\n",
    "    \"\"\"\n",
    "    questions = state[\"questions\"]\n",
    "    ##PROMPT FOR SQL GENERATION\n",
    "    system = \"\"\"\n",
    "    You are an SQL assistant specialized in DuckDB. Your task is to generate accurate SQL queries based on natural language questions, following the provided schema.\n",
    "\n",
    "    ### Database Schema  \n",
    "    #### Table: \"cases\"\n",
    "    - \"id\" (VARCHAR): Primary key.\n",
    "    - \"insurance\" (BIGINT): Foreign key to insurance.\n",
    "    - \"avg_time\" (DOUBLE): Duration (seconds) from case initiation to closure.\n",
    "    - \"type\" (VARCHAR): Insurance category.\n",
    "    - \"branch\" (VARCHAR): Policy branch.\n",
    "    - \"ramo\" (VARCHAR): Coverage type.\n",
    "    - \"broker\" (VARCHAR): Broker for the policy.\n",
    "    - \"state\" (VARCHAR): Current case state.\n",
    "    - \"client\" (VARCHAR): Client who bought the insurance.\n",
    "    - \"creator\" (VARCHAR): Employee managing the case.\n",
    "    - \"value\" (BIGINT): Insurance monetary value.\n",
    "    - \"approved\" (BOOLEAN): TRUE if approved, else FALSE.\n",
    "    - \"insurance_creation\" (TIMESTAMP_NS): Policy creation timestamp.\n",
    "    - \"insurance_start\" (TIMESTAMP_NS): Coverage start timestamp.\n",
    "    - \"insurance_end\" (TIMESTAMP_NS): Coverage end timestamp.\n",
    "\n",
    "    #### Table: \"activity\"\n",
    "    - \"id\" (BIGINT): Primary key.\n",
    "    - \"case\" (VARCHAR): Foreign key to \"cases\".\"id\".\n",
    "    - \"timestamp\" (TIMESTAMP_NS): Activity timestamp.\n",
    "    - \"name\" (VARCHAR): Name of the activity.\n",
    "    - \"case_index\" (BIGINT): Alias for \"id\".\n",
    "    - \"tpt\" (DOUBLE): Activity duration (seconds).\n",
    "\n",
    "    #### Table: \"variants\"\n",
    "    - \"id\" (BIGINT): Primary key representing a unique variant (i.e., a specific path).\n",
    "    - \"activities\" (VARCHAR): Ordered list of activities representing the exact sequence of events in the variant.\n",
    "    - \"cases\" (VARCHAR): List of case IDs (as strings) that followed this variant path. Each entry corresponds to a \"cases\".\"id\".\n",
    "    - \"number_cases\" (BIGINT): Total number of cases that followed this variant.\n",
    "    - \"percentage\" (DOUBLE): Proportion (0‚Äì100%) of all cases that followed this variant.\n",
    "    - \"avg_time\" (DOUBLE): Average total duration (in seconds) of cases following this variant.\n",
    "\n",
    "    **Relations:**\n",
    "    - \"variants\".\"cases\" contains references to \"cases\".\"id\", meaning each variant is followed by multiple cases.\n",
    "    - \"variants\".\"activities\" corresponds to the ordered \"activity\".\"name\" values for those cases, showing a summarized path of events.\n",
    "\n",
    "    ### Query Guidelines  \n",
    "    1. Convert any time differences (e.g., between `insurance_start` and `insurance_creation`) from `INTERVAL` to a numeric type, such as seconds or minutes, for accurate calculations.\n",
    "    2. Use functions like `EXTRACT(EPOCH FROM ...)` to convert `INTERVAL` types into numeric values (e.g., seconds) that can be averaged.\n",
    "    3. **Use Table Aliases**: \"cases\" ‚Üí c, \"activity\" ‚Üí a.\n",
    "    4. **Always Reference Columns with Aliases**: c.\"id\", a.\"case\".\n",
    "    5. **Handle Aggregations**: Include non-aggregated columns in GROUP BY.\n",
    "    6. **Date & Time Calculations**: Use EXTRACT(DAY FROM ...) for durations.\n",
    "    7. **Filtering Conditions**: Use TRUE/FALSE for boolean values.\n",
    "    8. **Use Explicit Joins**: Avoid implicit joins.\n",
    "    9. **Optimize for Performance**: Use indexes, avoid unnecessary calculations, and limit results when needed.\n",
    "    10. **Restrict Queries to Existing Tables**: Only use \"cases\", \"activity\", and \"variants\" tables.\n",
    "    11. **Use JOINS only when necessary**: Avoid unnecessary joins.\n",
    "\n",
    "    ### Special Handling for Variant Comparison\n",
    "\n",
    "    1. **Most Frequent Path (Reference Variant)**:\n",
    "    - To get the most common path, query the `variants` table ordered by `number_cases` and pick the top 1:\n",
    "        SELECT * FROM variants ORDER BY number_cases DESC LIMIT 1\n",
    "\n",
    "    2. **Deviations from Reference Path**:\n",
    "    - Get all other variants whose `activities` string differs from the reference variant.\n",
    "    - You can compare variants by filtering where activities != <reference_activities>.\n",
    "\n",
    "    3. **Find Point of Deviation**:\n",
    "    - If needed, split the `activities` string into individual steps using SPLIT(activities, ' ‚Üí ') or REGEXP_SPLIT_TO_ARRAY.\n",
    "    - Compare each index to find where the variant differs from the reference.\n",
    "\n",
    "    4. **Impact on Duration**:\n",
    "    - Compare avg_time values from the reference path to each deviating variant‚Äôs avg_time.\n",
    "    - Calculate the difference in duration to assess performance impact.\n",
    "\n",
    "    ### Reminder\n",
    "    - Do not guess or hardcode values like activity names unless explicitly mentioned.\n",
    "    - When asked about the most common path, select the variant with the highest number_cases.\n",
    "    - For deviations, always compare against that top variant.\n",
    "\n",
    "    ### Output Format  \n",
    "    - Return only the SQL query, with no extra formatting.  \n",
    "    - Do **NOT** include language tags like `sql`, `vbnet`, or any other markers.  \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    llm= OllamaLLM(model=\"duckdb-nsql:latest\",temperature=\"0.0\")\n",
    "\n",
    "    convert_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system),\n",
    "                (\"human\", \"Question: {question}\"),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    sql_generator = convert_prompt | llm\n",
    "    querys= []\n",
    "    for question in questions:\n",
    "        print(f\"Converting question to SQL {question}\")\n",
    "        result = sql_generator.invoke({\"question\": question})\n",
    "        message= re.sub(r'^\\s*```sql\\s*|\\s*```$', '', result.strip(), flags=re.IGNORECASE)\n",
    "        querys.append(message) # Append each generated SQL query to the list\n",
    "        print(f\"Generated SQL query: {message}\")\n",
    "    state[\"sql_querys\"] = querys \n",
    "    state[\"executed\"]= [False] * len(state[\"sql_querys\"])  # Initialize executed status for each question # Store the list of SQL queries in the state\n",
    "    print(f\"Generated SQL queries: {state['sql_querys']}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def execute_sql(state:State):\n",
    "    \"\"\"\n",
    "    Executes the SQL query on the  database and retrieves the results.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the query results or error information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # If multiple queries are generated, execute them one by one\n",
    "    db_conn = state[\"db_conn\"] \n",
    "    sql_queries = state[\"sql_querys\"]\n",
    "    errors = state.get(\"sql_error\", [True] * len(sql_queries))  # Default: all True (assume they need execution)\n",
    "    results = state.get(\"query_results\", [None] * len(sql_queries))\n",
    "    dataframes = state.get(\"query_dfs\", [None] * len(sql_queries))\n",
    "    for i, query in enumerate(sql_queries):\n",
    "        if errors[i] or results[i] is None:  # Execute if error OR never executed before\n",
    "            print(f\"üöÄ Executing query {i}: {query}\")\n",
    "            try:\n",
    "                # Ensure the query targets only the allowed tables\n",
    "                allowed_tables = [\"cases\", \"activity\",\"variants\"]\n",
    "                if not any(table in query.lower() for table in allowed_tables):\n",
    "                    raise ValueError(f\"Query must target only the tables: {', '.join(allowed_tables)}.\")\n",
    "\n",
    "                # Execute the SQL query using the connection\n",
    "                cursor = db_conn.cursor()\n",
    "                cursor.execute(query)\n",
    "\n",
    "                # Fetch results if it's a SELECT query\n",
    "                if query.lower().startswith(\"select\"):\n",
    "                    rows = cursor.fetchall()\n",
    "                    columns = [desc[0] for desc in cursor.description]\n",
    "\n",
    "                    # Format the output\n",
    "                    if rows:\n",
    "                        formatted_result = \"\\n\".join(\n",
    "                            \", \".join(f\"{col}: {row[idx]}\" for idx, col in enumerate(columns))\n",
    "                            for row in rows\n",
    "                        )\n",
    "                        print(\"SQL SELECT query executed successfully.\")\n",
    "                    \n",
    "                    else:\n",
    "                        formatted_result = \"No results found.\"\n",
    "                        print(\"SQL SELECT query executed successfully but returned no rows.\")\n",
    "\n",
    "                    state[\"query_rows\"] = rows\n",
    "                    df = pd.DataFrame(rows, columns=columns)\n",
    "                    dataframes[i] = df  # Store the DataFrame in the state\n",
    "                else:\n",
    "                    formatted_result = \"The action has been successfully completed.\"\n",
    "                    print(\"SQL command executed successfully.\")\n",
    "\n",
    "                results[i]= formatted_result\n",
    "                errors[i]= False # Mark this query as executed successfully\n",
    "\n",
    "            except Exception as e:\n",
    "                results[i]=f\"Error executing SQL query: {str(e)}\" # Store the error message in the results\n",
    "                errors[i]= True # Mark this query as executed with an error\n",
    "                print(f\"Error executing SQL query: {str(e)}\")\n",
    "    state[\"query_results\"] = results  # Store the list of query results in the state\n",
    "    state[\"sql_error\"] = errors  # Store the list of error states in the state\n",
    "    state[\"query_dfs\"] = dataframes  # Store the list of DataFrames in the state\n",
    "    print(f\"SQL query results: {state['query_results']}\")\n",
    "    print(f\"SQL error states: {state['sql_error']}\")\n",
    "    return state\n",
    "\n",
    "def get_context_length(state: State):\n",
    "    \"\"\"\n",
    "    Calculates the context length based on the number of sub-questions and their lengths.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        int: The calculated context length.\n",
    "    \"\"\"\n",
    "    question = state[\"original_question\"]\n",
    "    sub_questions = state[\"questions\"]\n",
    "    query_results = state[\"query_results\"]  # This is now a list of results, one per sub-question\n",
    "\n",
    "    chat_history_entries = state.get(\"chat_history\", [])\n",
    "    chat_history = relevant_entries(chat_history_entries)  # Get the last 3 relevant entries\n",
    "\n",
    "    # Concatenate each sub-question with its answer\n",
    "    sub_q_results_str = \"\\n\".join(\n",
    "        f\"**{sq}**\\n{qr}\\n\" for sq, qr in zip(sub_questions, query_results)\n",
    "    )\n",
    "\n",
    "    system = f\"\"\"\n",
    "    You are sOFIa, an AI assistant designed by the AI dream team at OFI Services. \n",
    "    Your task is to:\n",
    "    1. Answer the user's **main question** using the SQL results from the **sub-questions**.\n",
    "    2. Provide business insights based on the query results.\n",
    "\n",
    "    ### **Chat History:**  \n",
    "    {chat_history}\n",
    "\n",
    "    ### **Context:**  \n",
    "    - **User's Main Question:** {question}  \n",
    "    - **SQL Results from Sub-Questions:**  \n",
    "    {sub_q_results_str}\n",
    "\n",
    "    ### **Instructions:**  \n",
    "    - Summarize the SQL results in a **clear business-oriented answer**.\n",
    "    - Ensure the answer **directly addresses the main question**.\n",
    "    - Provide **business insights** based on patterns, trends, and potential improvements.\n",
    "    - If relevant, compare values or suggest actions based on findings.\n",
    "    \"\"\"\n",
    "    context_length= count_tokens(system)\n",
    "    print(f\"Context length: {context_length} tokens\")\n",
    "    state[\"context_length\"] = context_length\n",
    "    return state\n",
    "\n",
    "\n",
    "def generate_serious_answer(state: State):\n",
    "    \"\"\"\n",
    "    Generates a business-oriented response using SQL query results from sub-questions\n",
    "    to answer the main question.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        \n",
    "    Returns:\n",
    "        State: Updated state with the final answer.\n",
    "    \"\"\"\n",
    "    question = state[\"original_question\"]\n",
    "    sub_questions = state[\"questions\"]\n",
    "    query_results = state[\"query_results\"]  # This is now a list of results, one per sub-question\n",
    "\n",
    "    chat_history_entries = state.get(\"chat_history\", [])\n",
    "    chat_history = relevant_entries(chat_history_entries)  # Get the last 3 relevant entries\n",
    "\n",
    "    # Concatenate each sub-question with its answer\n",
    "    sub_q_results_str = \"\\n\".join(\n",
    "        f\"**{sq}**\\n{qr}\\n\" for sq, qr in zip(sub_questions, query_results)\n",
    "    )\n",
    "\n",
    "    system = f\"\"\"\n",
    "    You are sOFIa, an AI assistant designed by the AI dream team at OFI Services. \n",
    "    Your task is to:\n",
    "    1. Answer the user's **main question** using the SQL results from the **sub-questions**.\n",
    "    2. Provide business insights based on the query results.\n",
    "\n",
    "    ### **Chat History:**  \n",
    "    {chat_history}\n",
    "\n",
    "    ### **Context:**  \n",
    "    - **User's Main Question:** {question}  \n",
    "    - **SQL Results from Sub-Questions:**  \n",
    "    {sub_q_results_str}\n",
    "\n",
    "    ### **Instructions:**  \n",
    "    - Summarize the SQL results in a **clear business-oriented answer**.\n",
    "    - Every duration is given in seconds, if the number is too high, convert it to minutes or hours.\n",
    "    - Ensure the answer **directly addresses the main question**.\n",
    "    - Provide **business insights** based on patterns, trends, and potential improvements.\n",
    "    - If relevant, compare values or suggest actions based on findings.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    human_message = f\"Question: {question}\"\n",
    "    \n",
    "    # Use sOFIa to generate a response based on the SQL result\n",
    "    llm = OllamaLLM(model=\"mistral:latest\", temperature=\"0.0\", max_tokens=200)\n",
    "    response = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system),\n",
    "        (\"human\", human_message),\n",
    "    ]) | llm | StrOutputParser()\n",
    "    \n",
    "    # Generate and store the response\n",
    "    message = response.invoke({})\n",
    "    state[\"final_answer\"] = message\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def regenerate_query(state):\n",
    "    \"\"\"\n",
    "    Fixes the SQL query by passing the error message to the SQL model instead of rewriting the user's question.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with the fixed query.\n",
    "    \"\"\"\n",
    "    error_state= state[\"sql_error\"]\n",
    "    error_indexes = [index for index, error in enumerate(error_state) if error == True]\n",
    "\n",
    "    llm = OllamaLLM(model=\"deepseek-coder:6.7b\", temperature=0.0)  \n",
    "    print(f\"üîÑ Regenerating query. Attempt {state['attempts'] + 1}\")\n",
    "    for index in error_indexes:\n",
    "        # Fix the SQL query using the error message\n",
    "        query = state[\"sql_querys\"][index]\n",
    "        error = state[\"query_results\"][index]\n",
    "        print(f\"‚ö†Ô∏è Fixing SQL query at index {index}: {query}\")\n",
    "        print(f\"üîç Error encountered: {error}\")\n",
    "\n",
    "        # Dynamic Prompt Generation\n",
    "        sql_fix_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", f\"\"\"You are an expert in SQL for DuckDB.\n",
    "            Your task is to correct the following SQL query based on the error message.\n",
    "\n",
    "            ### **Query to Fix:**\n",
    "            ```sql\n",
    "            {query}\n",
    "            ```\n",
    "\n",
    "            ### **Error Message:**\n",
    "            {error}\n",
    "\n",
    "            Provide a **corrected** SQL query that runs successfully in the following database schema.\n",
    "            ### Database Schema  \n",
    "            #### Table: \"cases\"\n",
    "            - \"id\" (VARCHAR): Primary key.\n",
    "            - \"insurance\" (BIGINT): Foreign key to insurance.\n",
    "            - \"avg_time\" (DOUBLE): Duration (seconds) from case initiation to closure.\n",
    "            - \"type\" (VARCHAR): Insurance category.\n",
    "            - \"branch\" (VARCHAR): Policy branch.\n",
    "            - \"ramo\" (VARCHAR): Coverage type.\n",
    "            - \"broker\" (VARCHAR): Broker for the policy.\n",
    "            - \"state\" (VARCHAR): Current case state.\n",
    "            - \"client\" (VARCHAR): Client who bought the insurance.\n",
    "            - \"creator\" (VARCHAR): Employee managing the case.\n",
    "            - \"value\" (BIGINT): Insurance monetary value.\n",
    "            - \"approved\" (BOOLEAN): TRUE if approved, else FALSE.\n",
    "            - \"insurance_creation\" (TIMESTAMP_NS): Policy creation timestamp.\n",
    "            - \"insurance_start\" (TIMESTAMP_NS): Coverage start timestamp.\n",
    "            - \"insurance_end\" (TIMESTAMP_NS): Coverage end timestamp.\n",
    "\n",
    "            #### Table: \"activity\"\n",
    "            - \"id\" (BIGINT): Primary key.\n",
    "            - \"case\" (VARCHAR): Foreign key to \"cases\".\"id\".\n",
    "            - \"timestamp\" (TIMESTAMP_NS): Activity timestamp.\n",
    "            - \"name\" (VARCHAR): Name of the activity.\n",
    "            - \"case_index\" (BIGINT): Alias for \"id\".\n",
    "            - \"tpt\" (DOUBLE): Activity duration (seconds).\n",
    "\n",
    "            #### Table: \"variants\"\n",
    "            - \"id\" (BIGINT): Primary key representing a unique variant (i.e., a specific path).\n",
    "            - \"activities\" (VARCHAR): Ordered list of activities representing the exact sequence of events in the variant.\n",
    "            - \"cases\" (VARCHAR): List of case IDs (as strings) that followed this variant path. Each entry corresponds to a \"cases\".\"id\".\n",
    "            - \"number_cases\" (BIGINT): Total number of cases that followed this variant.\n",
    "            - \"percentage\" (DOUBLE): Proportion (0‚Äì100%) of all cases that followed this variant.\n",
    "            - \"avg_time\" (DOUBLE): Average total duration (in seconds) of cases following this variant.\n",
    "\n",
    "            **Relations:**\n",
    "            - \"variants\".\"cases\" contains references to \"cases\".\"id\", meaning each variant is followed by multiple cases.\n",
    "            - \"variants\".\"activities\" corresponds to the ordered \"activity\".\"name\" values for those cases, showing a summarized path of events.\n",
    "                    \"\"\"),\n",
    "            (\"human\", \"Fix the query and return only the corrected SQL, no explanations.\"),\n",
    "        ])\n",
    "\n",
    "        fixer = sql_fix_prompt | llm \n",
    "        # Pass the query and error message to the SQL model for correction\n",
    "        corrected_query = fixer.invoke({\"query\": query, \"error\": error})\n",
    "        # Extract only the SQL code from a markdown block like ```sql ... ```\n",
    "        corrected_query = re.sub(r\"```sql\\s*(.*?)\\s*```\", r\"\\1\", corrected_query.strip(), flags=re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "        state[\"sql_querys\"][index] = corrected_query\n",
    "        print(f\"‚úÖ Fixed SQL query: {corrected_query}\")\n",
    "\n",
    "    state[\"attempts\"] += 1\n",
    "    return state\n",
    "\n",
    "\n",
    "def summarize_results(state: State):\n",
    "    \"\"\"\n",
    "    Summarizes the longest query result's dataframe to reduce context size.\n",
    "    Stores the summary back in query_results.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current workflow state.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with summarized query result.\n",
    "    \"\"\"\n",
    "    query_results = state[\"query_results\"]\n",
    "    dataframes = state.get(\"query_dfs\", [])\n",
    "\n",
    "    # Find the longest text result (by character length)\n",
    "    lengths = [len(result) if result is not None else 0 for result in query_results]\n",
    "    if not lengths or max(lengths) == 0:\n",
    "        print(\"‚ö†Ô∏è No valid query results to summarize.\")\n",
    "        return state\n",
    "\n",
    "    longest_index = lengths.index(max(lengths))\n",
    "\n",
    "    if not dataframes or len(dataframes) <= longest_index:\n",
    "        print(\"‚ö†Ô∏è DataFrame for the longest result is missing.\")\n",
    "        return state\n",
    "\n",
    "    df = dataframes[longest_index]\n",
    "\n",
    "    # Simple summarization logic: Show column names, row count, and a few sample rows\n",
    "    summary = f\"üìä Summary of result #{longest_index}:\\n\"\n",
    "    summary += f\"- Rows: {len(df)}\\n\"\n",
    "    summary += f\"- Columns: {', '.join(df.columns)}\\n\"\n",
    "    summary += \"\\nüîπ Sample Rows:\\n\"\n",
    "    summary += df.head(5).to_string(index=False)\n",
    "\n",
    "    # Replace original result with summarized version\n",
    "    state[\"query_results\"][longest_index] = summary\n",
    "\n",
    "    print(\"‚úÖ Summarized longest result to reduce token size.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def end_max_iterations(state: State):\n",
    "    \"\"\"\n",
    "    Ends the workflow after reaching the maximum number of attempts.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        config (RunnableConfig): Configuration for the runnable.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with a termination message.\n",
    "    \"\"\"\n",
    "    state[\"query_results\"] = \"Please try again.\"\n",
    "    state[\"final_answer\"] = \"I couldn't generate a valid SQL query after 3 attempts. Please try again.\"\n",
    "    print(\"Maximum attempts reached. Ending the workflow.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "def generate_funny_response(state: State):\n",
    "    \"\"\"\n",
    "    Generates a playful and humorous response for unrelated questions.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "        \n",
    "    Returns:\n",
    "        State: Updated state with the funny response.\n",
    "    \"\"\"\n",
    "    print(\"Generating a funny response for an unrelated question.\")\n",
    "    question = state[\"original_question\"]\n",
    "    chat_history_entries = state.get(\"chat_history\", [])\n",
    "    chat_history = non_relevant_entries(chat_history_entries) # Get the last 3 non-relevant entries\n",
    "    print(f\"Chat history for funny response:\\n{chat_history}\")\n",
    "    system = f\"\"\"You are **sOFIa**, a charming and funny assistant designed by the AI team at OFI Services. \n",
    "    You respond in a playful and lighthearted manner. Your responses should always be fun, engaging, and humorous. \n",
    "    If the user doesn't know you yet, introduce yourself!\n",
    "    \n",
    "    ### **Chat History:**  \n",
    "    {chat_history}\n",
    "    \"\"\"\n",
    "\n",
    "    human_message = f\"Question: {question}\"\n",
    "\n",
    "    # Generate the playful response\n",
    "    funny_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", human_message),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    llm = OllamaLLM(model=\"mistral:latest\", temperature=\"0.7\",max_tokens=200)\n",
    "    funny_response = funny_prompt | llm | StrOutputParser()\n",
    "    message = funny_response.invoke({})\n",
    "    state[\"final_answer\"] = message\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Routings\n",
    "def check_attempts_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on the number of attempts made to generate a valid SQL query.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    if state[\"attempts\"] < 3:\n",
    "        return \"Retries < 3\"\n",
    "    else:\n",
    "        error_state= state[\"sql_error\"]\n",
    "        for error in error_state:\n",
    "            if error == False:\n",
    "                return \"If at least 1 subquery was succesful\"\n",
    "        return \"Retries >= 3\"\n",
    "\n",
    "\n",
    "\n",
    "def execute_sql_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on whether the SQL query execution was successful.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    error_state= state[\"sql_error\"]\n",
    "    for error in error_state:\n",
    "        if error == True:\n",
    "            return \"Error\"\n",
    "    else:\n",
    "        return \"Success\"\n",
    "\n",
    "\n",
    "    \n",
    "def relevance_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on the relevance of the user's question.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    if state[\"relevance\"].lower() == \"relevant\":\n",
    "        return \"Relevant\"\n",
    "    else:\n",
    "        return \"Not Relevant\"\n",
    "    \n",
    "def tokens_router(state: State):\n",
    "    \"\"\"\n",
    "    Routes the workflow based on the context length of the system prompt.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current state of the workflow.\n",
    "\n",
    "    Returns:\n",
    "        str: The next node in the workflow.\n",
    "    \"\"\"\n",
    "    if state[\"context_length\"] < 2000:\n",
    "        return \"Context < 2000\"\n",
    "    else:\n",
    "        return \"Context >= 2000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"Checks Question Relevance\", check_relevance)\n",
    "workflow.add_node(\"Reformat Question\", reformat_question)\n",
    "workflow.add_node(\"Generates SQL queries\", convert_nl_to_sql)\n",
    "workflow.add_node(\"Executes SQL\",execute_sql)\n",
    "workflow.add_node(\"Get Context Length\", get_context_length)\n",
    "workflow.add_node(\"Regenerate Error-Queries\",regenerate_query)\n",
    "workflow.add_node(\"Answer Irrelevant Question\", generate_funny_response)\n",
    "workflow.add_node(\"Answer Relevant Question\",generate_serious_answer)\n",
    "workflow.add_node(\"Stops due to max Iterations\",end_max_iterations)\n",
    "workflow.add_node(\"Summarizes Results\", summarize_results)\n",
    "\n",
    "workflow.add_edge(START, \"Checks Question Relevance\")\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "        \"Checks Question Relevance\",\n",
    "        relevance_router,\n",
    "        {\n",
    "        \"Relevant\":\"Reformat Question\",\n",
    "        \"Not Relevant\": \"Answer Irrelevant Question\"\n",
    "        } \n",
    "\n",
    "    )\n",
    "workflow.add_edge(\"Reformat Question\", \"Generates SQL queries\")\n",
    "\n",
    "workflow.add_edge(\"Generates SQL queries\", \"Executes SQL\")\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "        \"Executes SQL\",\n",
    "        execute_sql_router,\n",
    "        {\n",
    "            \"Success\": \"Get Context Length\",\n",
    "            \"Error\": \"Regenerate Error-Queries\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "        \"Get Context Length\",\n",
    "        tokens_router,\n",
    "        {\n",
    "            \"Context < 2000\": \"Answer Relevant Question\",\n",
    "            \"Context >= 2000\": \"Summarizes Results\",\n",
    "        },\n",
    "    )\n",
    "workflow.add_edge(\"Summarizes Results\", \"Answer Relevant Question\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "        \"Regenerate Error-Queries\",\n",
    "        check_attempts_router,\n",
    "        {\n",
    "            \"Retries < 3\": \"Executes SQL\",\n",
    "            \"Retries >= 3\": \"Stops due to max Iterations\",\n",
    "            \"If at least 1 subquery was succesful\": \"Get Context Length\",\n",
    "        },\n",
    "    )\n",
    "workflow.add_edge(\"Stops due to max Iterations\", END)\n",
    "workflow.add_edge(\"Answer Relevant Question\",END)\n",
    "workflow.add_edge(\"Answer Irrelevant Question\",END)\n",
    "\n",
    "chain= workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state= chain.invoke({\"original_question\":\"Hello?\",\"db_conn\":db_conn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mTimeoutError\u001b[39m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\urllib3\\util\\util.py:39\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:367\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[31mReadTimeoutError\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      3\u001b[39m Image(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:667\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, frontmatter_config)\u001b[39m\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    661\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    662\u001b[39m     curve_style=curve_style,\n\u001b[32m    663\u001b[39m     node_colors=node_colors,\n\u001b[32m    664\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    665\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    666\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:282\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding)\u001b[39m\n\u001b[32m    276\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    277\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    278\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    279\u001b[39m         )\n\u001b[32m    280\u001b[39m     )\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    286\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:400\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type)\u001b[39m\n\u001b[32m    394\u001b[39m         background_color = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m!\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackground_color\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    396\u001b[39m image_url = (\n\u001b[32m    397\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://mermaid.ink/img/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmermaid_syntax_encoded\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m?type=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&bgColor=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackground_color\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    399\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m    402\u001b[39m     img_bytes = response.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\requests\\adapters.py:713\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request=request)\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[32m    715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request=request)\n",
      "\u001b[31mReadTimeout\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\n",
    "    chain.get_graph().draw_mermaid_png()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi hi! I'm sOFIa, your assistant!\n",
      "Let's get started by asking a question!\n",
      "Checking relevance of the question: What are the most common deviations vs the most common path and at what point do they occur? And what is the impact on process times?\n",
      "Chat history for relevance check:\n",
      "\n",
      "Relevance determined: relevant\n",
      "Processed Question(s): ['Identify the most frequent process variant as the reference path.', 'Find cases where this reference path is deviated from and list them.', 'For each deviated case, determine at which activity in the process the deviation occurred.', 'Calculate the average duration for the reference path.', 'Calculate the average duration for each deviated case.', 'Compare the average durations of the reference path and deviated cases to determine the impact on process times.']\n",
      "Converting question to SQL Identify the most frequent process variant as the reference path.\n",
      "Generated SQL query: SELECT v.id, v.activities, v.number_cases, v.percentage, v.avg_time FROM variants v WHERE v.id = (SELECT id FROM variants ORDER BY number_cases DESC LIMIT 1)\n",
      "Converting question to SQL Find cases where this reference path is deviated from and list them.\n",
      "Generated SQL query: SELECT c.id, c.insurance, c.avg_time, c.type, c.branch, c.ramo, c.broker, c.state, c.client, c.creator, c.value, c.approved, c.insurance_creation, c.insurance_start, c.insurance_end\n",
      "FROM cases AS c\n",
      "JOIN variants AS v ON c.id = v.cases\n",
      "WHERE v.activities <> (SELECT activities FROM variants WHERE id = (SELECT MAX(id) FROM variants))\n",
      "ORDER BY c.avg_time DESC\n",
      "Converting question to SQL For each deviated case, determine at which activity in the process the deviation occurred.\n",
      "Generated SQL query: SELECT c.id, c.case, a.name, v.activities, v.number_cases FROM cases c JOIN activity a ON c.id = a.case JOIN variants v ON c.id = v.cases[1] WHERE v.activities LIKE '% ‚Üí %'\n",
      "Converting question to SQL Calculate the average duration for the reference path.\n",
      "Generated SQL query: SELECT AVG(avg_time) FROM variants WHERE activities = (SELECT activities FROM variants WHERE id = 1)\n",
      "Converting question to SQL Calculate the average duration for each deviated case.\n",
      "Generated SQL query: SELECT c.\"id\", AVG(v.\"avg_time\") FROM \"cases\" AS c JOIN \"variants\" AS v ON c.\"id\" = v.\"cases\" WHERE v.\"activities\" <> (SELECT \"activities\" FROM \"variants\" WHERE \"id\" = (SELECT \"id\" FROM \"variants\" WHERE \"number_cases\" = (SELECT MAX(\"number_cases\") FROM \"variants\"))) GROUP BY c.\"id\"\n",
      "Converting question to SQL Compare the average durations of the reference path and deviated cases to determine the impact on process times.\n",
      "Generated SQL query: SELECT AVG(avg_time) FROM variants WHERE activities = (SELECT activities FROM variants WHERE id = 1)\n",
      "Generated SQL queries: ['SELECT v.id, v.activities, v.number_cases, v.percentage, v.avg_time FROM variants v WHERE v.id = (SELECT id FROM variants ORDER BY number_cases DESC LIMIT 1)', 'SELECT c.id, c.insurance, c.avg_time, c.type, c.branch, c.ramo, c.broker, c.state, c.client, c.creator, c.value, c.approved, c.insurance_creation, c.insurance_start, c.insurance_end\\nFROM cases AS c\\nJOIN variants AS v ON c.id = v.cases\\nWHERE v.activities <> (SELECT activities FROM variants WHERE id = (SELECT MAX(id) FROM variants))\\nORDER BY c.avg_time DESC', \"SELECT c.id, c.case, a.name, v.activities, v.number_cases FROM cases c JOIN activity a ON c.id = a.case JOIN variants v ON c.id = v.cases[1] WHERE v.activities LIKE '% ‚Üí %'\", 'SELECT AVG(avg_time) FROM variants WHERE activities = (SELECT activities FROM variants WHERE id = 1)', 'SELECT c.\"id\", AVG(v.\"avg_time\") FROM \"cases\" AS c JOIN \"variants\" AS v ON c.\"id\" = v.\"cases\" WHERE v.\"activities\" <> (SELECT \"activities\" FROM \"variants\" WHERE \"id\" = (SELECT \"id\" FROM \"variants\" WHERE \"number_cases\" = (SELECT MAX(\"number_cases\") FROM \"variants\"))) GROUP BY c.\"id\"', 'SELECT AVG(avg_time) FROM variants WHERE activities = (SELECT activities FROM variants WHERE id = 1)']\n",
      "üöÄ Executing query 0: SELECT v.id, v.activities, v.number_cases, v.percentage, v.avg_time FROM variants v WHERE v.id = (SELECT id FROM variants ORDER BY number_cases DESC LIMIT 1)\n",
      "SQL SELECT query executed successfully.\n",
      "üöÄ Executing query 1: SELECT c.id, c.insurance, c.avg_time, c.type, c.branch, c.ramo, c.broker, c.state, c.client, c.creator, c.value, c.approved, c.insurance_creation, c.insurance_start, c.insurance_end\n",
      "FROM cases AS c\n",
      "JOIN variants AS v ON c.id = v.cases\n",
      "WHERE v.activities <> (SELECT activities FROM variants WHERE id = (SELECT MAX(id) FROM variants))\n",
      "ORDER BY c.avg_time DESC\n",
      "SQL SELECT query executed successfully but returned no rows.\n",
      "üöÄ Executing query 2: SELECT c.id, c.case, a.name, v.activities, v.number_cases FROM cases c JOIN activity a ON c.id = a.case JOIN variants v ON c.id = v.cases[1] WHERE v.activities LIKE '% ‚Üí %'\n",
      "Error executing SQL query: Binder Error: Table \"c\" does not have a column named \"case\"\n",
      "\n",
      "Candidate bindings: : \"client\", \"creator\"\n",
      "\n",
      "LINE 1: SELECT c.id, c.case, a.name, v.activities, v.number_cases FROM cases...\n",
      "                     ^\n",
      "üöÄ Executing query 3: SELECT AVG(avg_time) FROM variants WHERE activities = (SELECT activities FROM variants WHERE id = 1)\n",
      "SQL SELECT query executed successfully.\n",
      "üöÄ Executing query 4: SELECT c.\"id\", AVG(v.\"avg_time\") FROM \"cases\" AS c JOIN \"variants\" AS v ON c.\"id\" = v.\"cases\" WHERE v.\"activities\" <> (SELECT \"activities\" FROM \"variants\" WHERE \"id\" = (SELECT \"id\" FROM \"variants\" WHERE \"number_cases\" = (SELECT MAX(\"number_cases\") FROM \"variants\"))) GROUP BY c.\"id\"\n",
      "SQL SELECT query executed successfully but returned no rows.\n",
      "üöÄ Executing query 5: SELECT AVG(avg_time) FROM variants WHERE activities = (SELECT activities FROM variants WHERE id = 1)\n",
      "SQL SELECT query executed successfully.\n",
      "SQL query results: ['id: 9, activities: [\"Registro de compromiso\", \"Enviar a Revisi\\\\u00f3n suscripci\\\\u00f3n\", \"Revisi\\\\u00f3n en suscripci\\\\u00f3n\", \"Enviar a suscripcion local\", \"Aprobar solicitud en suscripcion local\", \"Enviar respuesta al area comercial\", \"Declinar por parte del Brocker\"], number_cases: 60, percentage: 6.0, avg_time: 259887.36442735', 'No results found.', 'Error executing SQL query: Binder Error: Table \"c\" does not have a column named \"case\"\\n\\nCandidate bindings: : \"client\", \"creator\"\\n\\nLINE 1: SELECT c.id, c.case, a.name, v.activities, v.number_cases FROM cases...\\n                     ^', 'avg(avg_time): 394287.845047', 'No results found.', 'avg(avg_time): 394287.845047']\n",
      "SQL error states: [False, False, True, False, False, False]\n",
      "üîÑ Regenerating query. Attempt 1\n",
      "‚ö†Ô∏è Fixing SQL query at index 2: SELECT c.id, c.case, a.name, v.activities, v.number_cases FROM cases c JOIN activity a ON c.id = a.case JOIN variants v ON c.id = v.cases[1] WHERE v.activities LIKE '% ‚Üí %'\n",
      "üîç Error encountered: Error executing SQL query: Binder Error: Table \"c\" does not have a column named \"case\"\n",
      "\n",
      "Candidate bindings: : \"client\", \"creator\"\n",
      "\n",
      "LINE 1: SELECT c.id, c.case, a.name, v.activities, v.number_cases FROM cases...\n",
      "                     ^\n",
      "‚úÖ Fixed SQL query: SELECT c.id, c.insurance, a.name, v.activities, v.number_cases FROM cases c JOIN activity a ON c.id = a.case JOIN variants v ON c.id = v.cases[1] WHERE v.activities LIKE '% ‚Üí %'\n",
      "üöÄ Executing query 2: SELECT c.id, c.insurance, a.name, v.activities, v.number_cases FROM cases c JOIN activity a ON c.id = a.case JOIN variants v ON c.id = v.cases[1] WHERE v.activities LIKE '% ‚Üí %'\n",
      "SQL SELECT query executed successfully but returned no rows.\n",
      "SQL query results: ['id: 9, activities: [\"Registro de compromiso\", \"Enviar a Revisi\\\\u00f3n suscripci\\\\u00f3n\", \"Revisi\\\\u00f3n en suscripci\\\\u00f3n\", \"Enviar a suscripcion local\", \"Aprobar solicitud en suscripcion local\", \"Enviar respuesta al area comercial\", \"Declinar por parte del Brocker\"], number_cases: 60, percentage: 6.0, avg_time: 259887.36442735', 'No results found.', 'No results found.', 'avg(avg_time): 394287.845047', 'No results found.', 'avg(avg_time): 394287.845047']\n",
      "SQL error states: [False, False, False, False, False, False]\n",
      "Context length: 528 tokens\n",
      "sOFIa: Based on the analysis of our data, it appears that there is no significant deviation from the most common process path, as no cases were found where this reference path was deviated from. However, let's focus on the main path for now:\n",
      "\n",
      "The most common process path, with 6% of total cases, has an average duration of approximately 66 hours and 24 minutes (394287.845047 seconds). This indicates a consistent and relatively long process time, which could potentially be optimized for efficiency.\n",
      "\n",
      "To improve the process times, we could consider the following:\n",
      "\n",
      "1. Analyze the activities within this path to identify any bottlenecks or areas where delays might occur. This could involve examining the average time spent at each activity and comparing it with industry standards or best practices.\n",
      "\n",
      "2. Investigate if there are opportunities for automation or streamlining certain activities, which may help reduce process times and improve overall efficiency.\n",
      "\n",
      "3. Collaborate with the team responsible for this process to understand any challenges they face during execution and work together on potential solutions. This could involve providing additional resources, training, or tools to support them in their tasks.\n",
      "\n",
      "4. Monitor the process over time to track any changes in average duration and identify trends that may indicate improvements or areas requiring further attention.\n",
      "\n",
      "In conclusion, while there are no significant deviations from the most common process path at this time, there is room for improvement in terms of process times. By addressing potential bottlenecks, exploring automation opportunities, collaborating with the team, and monitoring the process over time, we can work towards optimizing our processes for greater efficiency.\n",
      "Goodbye! Have a great day!\n",
      "\n",
      "Chat History:\n",
      "User: What are the most common deviations vs the most common path and at what point do they occur? And what is the impact on process times? [Relevance: relevant]\n",
      "sOFIa: Based on the analysis of our data, it appears that there is no significant deviation from the most common process path, as no cases were found where this reference path was deviated from. However, let's focus on the main path for now:\n",
      "\n",
      "The most common process path, with 6% of total cases, has an average duration of approximately 66 hours and 24 minutes (394287.845047 seconds). This indicates a consistent and relatively long process time, which could potentially be optimized for efficiency.\n",
      "\n",
      "To improve the process times, we could consider the following:\n",
      "\n",
      "1. Analyze the activities within this path to identify any bottlenecks or areas where delays might occur. This could involve examining the average time spent at each activity and comparing it with industry standards or best practices.\n",
      "\n",
      "2. Investigate if there are opportunities for automation or streamlining certain activities, which may help reduce process times and improve overall efficiency.\n",
      "\n",
      "3. Collaborate with the team responsible for this process to understand any challenges they face during execution and work together on potential solutions. This could involve providing additional resources, training, or tools to support them in their tasks.\n",
      "\n",
      "4. Monitor the process over time to track any changes in average duration and identify trends that may indicate improvements or areas requiring further attention.\n",
      "\n",
      "In conclusion, while there are no significant deviations from the most common process path at this time, there is room for improvement in terms of process times. By addressing potential bottlenecks, exploring automation opportunities, collaborating with the team, and monitoring the process over time, we can work towards optimizing our processes for greater efficiency.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Hi hi! I'm sOFIa, your assistant!\")\n",
    "    print(\"Let's get started by asking a question!\")\n",
    "    chat_history = []  # Store chat history outside the loop\n",
    "    input_question = input()\n",
    "    while input_question:\n",
    "        # Check for exit or goodbye phrases\n",
    "        if input_question.lower() in [\"no\", \"exit\", \"goodbye\", \"quit\"]:\n",
    "            print(\"Goodbye! Have a great day!\")\n",
    "            break\n",
    "        # Invoke the chain and ensure chat history persists\n",
    "        state = chain.invoke({\"original_question\": input_question, \"db_conn\": db_conn, \"chat_history\": chat_history})\n",
    "        # Get response and ensure sOFIa is not repeated\n",
    "        response = state[\"final_answer\"].replace(\"sOFIa: \", \"\").strip()\n",
    "        # Print the response correctly\n",
    "        print(f\"sOFIa: {response}\")\n",
    "        relevance= state[\"relevance\"]\n",
    "        # Append the interaction to chat history\n",
    "        chat_history.append(f\"User: {input_question} [Relevance: {relevance}]\")\n",
    "        chat_history.append(f\"sOFIa: {response}\")\n",
    "        # Get the next question\n",
    "        input_question = input()\n",
    "    # Print the chat history in a well-formatted way\n",
    "    print(\"\\nChat History:\")\n",
    "    for entry in chat_history:\n",
    "        print(entry)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg(avg_time)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909131.162998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg(avg_time)\n",
       "0  909131.162998"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.consultar_db(\"\"\"SELECT AVG(avg_time) FROM cases WHERE type = 'Renewal';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

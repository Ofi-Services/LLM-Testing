{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01a95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json5\n",
    "from qwen_agent.agents import Assistant\n",
    "from qwen_agent.tools.base import BaseTool, register_tool\n",
    "from qwen_agent.utils.output_beautify import typewriter_print\n",
    "import re\n",
    "from sql import run_sql_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c789847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_think_blocks(text: str) -> str:\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb084ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 (Optional): Add a custom tool named `my_image_gen`.\n",
    "@register_tool('get_cases_schema')\n",
    "class GetCasesSchema(BaseTool):\n",
    "    description = 'Returns the schema and usage notes for the `cases` SQL table.'\n",
    "    parameters = []\n",
    "\n",
    "    def call(self, params: str, **kwargs) -> str:\n",
    "        # No parameters needed, but still need to parse for consistency\n",
    "        _ = json5.loads(params) if params else {}\n",
    "\n",
    "        return json5.dumps({\n",
    "            'schema': \"\"\"\n",
    "=== CASES TABLE ===\n",
    "\n",
    "You are a SQL assistant with access to the `cases` table. Below is the structure and brief description of each column.\n",
    "\n",
    "Structure:\n",
    "    id                     VARCHAR       -- Unique identifier for each case\n",
    "    order_date             TIMESTAMP_NS  -- Date the order was placed\n",
    "    employee_id            VARCHAR       -- ID of the employee handling the case\n",
    "    branch                 VARCHAR       -- Branch responsible for the case\n",
    "    supplier               VARCHAR       -- Supplier associated with the case\n",
    "    avg_time               DOUBLE        -- Average time to complete the case\n",
    "    estimated_delivery     TIMESTAMP_NS  -- Estimated delivery date\n",
    "    delivery               TIMESTAMP_NS  -- Actual delivery date\n",
    "    on_time                BOOLEAN       -- Whether the delivery late, False means late delivery\n",
    "    in_full                BOOLEAN       -- Whether the delivery was complete\n",
    "    number_of_items        INTEGER       -- Total items in the case\n",
    "    ft_items               INTEGER       -- Fast-track items\n",
    "    total_price            DOUBLE        -- Total price of the case\n",
    "    total_activities       INTEGER       -- Total activities in the process\n",
    "    rework_activities      INTEGER       -- Count of rework activities\n",
    "    automatic_activities   INTEGER       -- Count of automated activities\n",
    "\n",
    "Instructions:\n",
    "- Use standard SQL (SELECT, WHERE, GROUP BY, etc.).\n",
    "- Use `order_date` for filtering by time.\n",
    "- Use aggregations (COUNT, SUM, AVG) for metrics.\n",
    "\"\"\"\n",
    "        }, ensure_ascii=False)\n",
    "\n",
    "@register_tool('get_activities_schema')\n",
    "class GetActivitiesSchema(BaseTool):\n",
    "    description = 'Returns the schema and usage notes for the `activities` SQL table.'\n",
    "    parameters = []\n",
    "\n",
    "    def call(self, params: str, **kwargs) -> str:\n",
    "        # No parameters needed, but still need to parse for consistency\n",
    "        _ = json5.loads(params) if params else {}\n",
    "\n",
    "        return json5.dumps({\n",
    "            'schema': \"\"\"\n",
    "=== ACTIVITIES TABLE ===\n",
    "\n",
    "You are a SQL assistant with access to the `activities` table. Below is the structure and brief description of each column.\n",
    "\n",
    "Structure:\n",
    "    id                       INTEGER     -- Unique ID for each activity\n",
    "    timestamp                TIMESTAMP   -- Time the activity occurred\n",
    "    name                     VARCHAR     -- Name/type of activity\n",
    "    tpt                      DOUBLE      -- Time per task\n",
    "    user                     VARCHAR     -- User who performed the activity\n",
    "    user_type                VARCHAR     -- Type of user (e.g., Human, Bot)\n",
    "    automatic                BOOLEAN     -- Whether the activity was automated\n",
    "    rework                   BOOLEAN     -- Whether the activity was a rework\n",
    "    case_index               INTEGER     -- Index of the activity in the case\n",
    "    case_id                  VARCHAR     -- ID of the related case\n",
    "\n",
    "Case metadata (prefixed with `case_`):\n",
    "    case_order_date          TIMESTAMP   -- Order date of the case\n",
    "    case_employee_id         VARCHAR     -- Employee responsible\n",
    "    case_branch              VARCHAR     -- Responsible branch\n",
    "    case_supplier            VARCHAR     -- Supplier involved\n",
    "    case_avg_time            DOUBLE      -- Average processing time\n",
    "    case_estimated_delivery  TIMESTAMP   -- Expected delivery date\n",
    "    case_delivery            TIMESTAMP   -- Actual delivery date\n",
    "    case_on_time             BOOLEAN     -- Whether the case was on time\n",
    "    case_in_full             BOOLEAN     -- Whether the delivery was complete\n",
    "    case_number_of_items     INTEGER     -- Number of items in the case\n",
    "    case_ft_items            INTEGER     -- Fast-track items\n",
    "    case_total_price         DOUBLE      -- Total case price\n",
    "\n",
    "Instructions:\n",
    "- Use standard SQL syntax (WHERE, GROUP BY, etc.).\n",
    "- Use `automatic` and `rework` to analyze activities' automation and rework status.\n",
    "- Use `timestamp`, `name`, or `user_type` for filtering or grouping activities.\n",
    "- You may aggregate case-related columns, but avoid referencing other tables.\n",
    "\"\"\"\n",
    "        }, ensure_ascii=False)\n",
    "\n",
    "@register_tool('get_variants_schema')\n",
    "class GetVariantsSchema(BaseTool):\n",
    "    description = 'Returns the schema and usage notes for the `variants` SQL table.'\n",
    "    parameters = []\n",
    "\n",
    "    def call(self, params: str, **kwargs) -> str:\n",
    "        # No parameters needed, but still need to parse for consistency\n",
    "        _ = json5.loads(params) if params else {}\n",
    "\n",
    "        return json5.dumps({\n",
    "            'schema': \"\"\"\n",
    "=== VARIANTS TABLE ===\n",
    "\n",
    "You are a SQL assistant with access to the `variants` table. Below is the structure and brief description of each column.\n",
    "\n",
    "Structure:\n",
    "    id              BIGINT       -- Unique ID for each variant\n",
    "    activities      VARCHAR[]    -- Ordered list of activity names in this variant\n",
    "    cases           VARCHAR[]    -- Array of case IDs following this variant\n",
    "    number_cases    BIGINT       -- Number of cases following this variant\n",
    "    percentage      DOUBLE       -- Share of total cases for this variant\n",
    "    avg_time        DOUBLE       -- Average processing time for this variant\n",
    "\n",
    "Instructions:\n",
    "- Each row represents a unique process path (\"variant\") followed by one or more cases.\n",
    "- Use `number_cases`, `percentage`, or `avg_time` to rank, filter, or compare variants.\n",
    "- Use array functions (e.g., `ANY`, `UNNEST`, `array_length`) to inspect activities or case IDs.\n",
    "- Standard SQL syntax is allowed (WHERE, ORDER BY, LIMIT, etc.).\n",
    "- Deviations are variants that differ from the most common one (highest `number_cases`).\n",
    "- Do not reference other tables.\n",
    "\"\"\"\n",
    "        }, ensure_ascii=False)\n",
    "\n",
    "\n",
    "llm_cfg = {\n",
    "    'model': 'Qwen3:8b',\n",
    "    'model_server': 'http://localhost:11434/v1',\n",
    "    'generate_cfg': {\n",
    "        'top_p': 0.8\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33aab820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nmessages= []\\nquery = input('\\nuser query: ')\\n# Append the user query to the chat history.\\nmessages.append({'role': 'user', 'content': query})\\nresponse = []\\nresponse_plain_text = ''\\n\\nfor response in prompt_agent.run(messages=messages):\\n        response_plain_text = typewriter_print(response, response_plain_text)\\nresponse_plain_text = remove_think_blocks(response_plain_text)\\nmessages.append({'role': 'assistant', 'content': response_plain_text})\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt_instruction = '''/no_think\n",
    "After receiving the user's request, you should:\n",
    "1. Identify the relevant SQL tables based on the user's query.\n",
    "2. Retrieve the schema for those tables by calling the relevant schema-fetching tools (e.g., `get_cases_schema`, `get_activities_schema`, `get_variants_schema`).\n",
    "3. Analyze the user's query and use the schema information to generate a prompt.\n",
    "4. Provide a brief instruction about how to query the relevant tables based on the schema.\n",
    "5. Return the table schemas where the query should be executed as well as its relevant columns with datatypes and descriptions. Do not Include any additional information.\n",
    "\n",
    "The goal is to make the user request more specific by formulating a SQL query and instructions based on the relevant schemas of the tables.\n",
    "'''\n",
    "\n",
    "tools = ['get_cases_schema', 'get_activities_schema', 'get_variants_schema', 'code_interpreter']  # Tools include schema fetchers and code interpreter\n",
    "#files = ['./doc.pdf']  # You can provide a PDF file if necessary\n",
    "prompt_agent = Assistant(llm=llm_cfg,\n",
    "                system_message=prompt_instruction,\n",
    "                function_list=tools,\n",
    "                #files=files\n",
    "                )\n",
    "\"\"\" \n",
    "messages= []\n",
    "query = input('\\nuser query: ')\n",
    "# Append the user query to the chat history.\n",
    "messages.append({'role': 'user', 'content': query})\n",
    "response = []\n",
    "response_plain_text = ''\n",
    "\n",
    "for response in prompt_agent.run(messages=messages):\n",
    "        response_plain_text = typewriter_print(response, response_plain_text)\n",
    "response_plain_text = remove_think_blocks(response_plain_text)\n",
    "messages.append({'role': 'assistant', 'content': response_plain_text})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7faf0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_tool('execute_sql_with_prompt')\n",
    "class ExecuteSQLWithPrompt(BaseTool):\n",
    "    description = 'Generates and executes a SQL query using a provided prompt and original user question. The prompt should describe what SQL to run.'\n",
    "\n",
    "    parameters = [\n",
    "        {\n",
    "            'name': 'question',\n",
    "            'type': 'string',\n",
    "            'description': 'The original user question for context.',\n",
    "            'required': True\n",
    "        },\n",
    "        {\n",
    "            'name': 'prompt',\n",
    "            'type': 'string',\n",
    "            'description': 'The SQL prompt provided by another agent. It should describe what SQL to generate and run.',\n",
    "            'required': True\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    def call(self, params: str, **kwargs) -> str:\n",
    "        args = json5.loads(params)\n",
    "        question = args['question']\n",
    "        prompt = args['prompt']\n",
    "\n",
    "        # You can keep this if the SQL generator expects consistent formatting\n",
    "        general_instructions = \"\"\"\n",
    "        You are an SQL assistant specialized in DuckDB. Your task is to generate accurate SQL queries based on natural language questions/tasks, following the schema and rules below.\n",
    "\n",
    "        ### MAIN RULES:\n",
    "        - Generate only one SQL Query.\n",
    "        - The result must be executable as it is, so do not include any instructions, just the SQL code.\n",
    "        - Only use the provided schemas to generate the SQL query, and do not reference any other tables or schemas.\n",
    "        - You can perform JOINs between the tables, but you should not reference any other tables or schemas.\n",
    "        - If the query is already given in this prompt you should just return it as it is.\n",
    "        \"\"\"\n",
    "\n",
    "        combined_prompt = general_instructions + prompt\n",
    "\n",
    "        # Assume this function executes the final query based on prompt and returns results\n",
    "        result = run_sql_workflow(question, combined_prompt)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149d5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_instruction = '''/no_think\n",
    "You will receive a query and a prompt for SQL generation. Your need to::\n",
    "\n",
    "1. Use the tool `execute_sql_with_prompt` which will generate and execute the SQL query based on the provided prompt and question.\n",
    "2. Return the result of the SQL query execution as it is, without any additional instructions or comments.\n",
    "'''\n",
    "\n",
    "tools2 = ['execute_sql_with_prompt']  # Tools include schema fetchers and code interpreter\n",
    "\n",
    "sql_bot = Assistant(llm=llm_cfg,\n",
    "                system_message=sql_instruction,\n",
    "                function_list=tools2,\n",
    "                #files=files\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9674d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_tool('handoff_to_prompt_generator')\n",
    "class HandoffToPromptAgent(BaseTool):\n",
    "    description = 'Generates a prompt for the sub task that needs to be answered with a SQL query.'\n",
    "\n",
    "    parameters = [\n",
    "        {\n",
    "            'name': 'task',\n",
    "            'type': 'string',\n",
    "            'description': 'The individual task that needs to be answered with a SQL query, no composed questions.',\n",
    "            'required': True\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    def call(self, params: str, **kwargs) -> str:\n",
    "        args = json5.loads(params)\n",
    "        task = args['task']        \n",
    "        sup_message = {'role': 'user', 'content':task}\n",
    "        # Assume this function executes the final query based on prompt and returns results\n",
    "        for response in prompt_agent.run(messages=[sup_message]):\n",
    "            response_plain_text = response[-1][\"content\"]\n",
    "        response_plain_text = remove_think_blocks(response_plain_text)\n",
    "        return response_plain_text\n",
    "\n",
    "@register_tool('handoff_to_sql_generator')\n",
    "class HandoffToSQLAgent(BaseTool):\n",
    "    description = 'Generates and executes SQL queries for the given task based on the prompt.'\n",
    "\n",
    "    parameters = [\n",
    "        {\n",
    "            'name': 'task',\n",
    "            'type': 'string',\n",
    "            'description': 'The individual task that needs to be answered with a SQL query, no composed questions, It needs to include the relevant context.',\n",
    "            'required': True\n",
    "        },\n",
    "        {\n",
    "            'name': 'prompt',\n",
    "            'type': 'string',\n",
    "            'description': 'The full exact prompt provided by a previous tool call `handoff_to_prompt_generator`.',\n",
    "            'required': True\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    def call(self, params: str, **kwargs) -> str:\n",
    "        args = json5.loads(params)\n",
    "        task = args['task']\n",
    "        prompt= args['prompt']\n",
    "        sup_message = {'role': 'user', 'content':task+prompt}\n",
    "        # Assume this function executes the final query based on prompt and returns results\n",
    "        for response in sql_bot.run(messages=[sup_message]):\n",
    "            response_plain_text = response[-1][\"content\"]\n",
    "        response_plain_text = remove_think_blocks(response_plain_text)\n",
    "        return response_plain_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb864aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_instruction='''\n",
    "/no_think\n",
    "You are the supervisor of the interaction between the user and two specialized agents.\n",
    "\n",
    "Your goal is to answer the user's question, even if it requires multiple steps or SQL queries.\n",
    "\n",
    "When you receive a user query:\n",
    "1. Analyze whether it can be answered directly or if it needs to be broken down into multiple steps.\n",
    "2. If multiple steps are required:\n",
    "   - Break the query into clear subtasks.\n",
    "   - For each subtask:\n",
    "     a. Call the `handoff_to_prompt_generator` tool to generate a prompt.\n",
    "     b. Then call the `handoff_to_sql_generator` tool generate and execute an SQL query based on the previous prompt.\n",
    "3. If a single step is needed:\n",
    "   - Do the same (generate prompt → generate and execute SQL).\n",
    "4. Optionally analyze or summarize the results.\n",
    "5. Combine the results from all subtasks and generate a final answer for the user.\n",
    "\n",
    "Always return a final concise and insightful summary based on the results.\n",
    "\n",
    "Execution Example:\n",
    "\n",
    "- If the user asks \"Identify late deliveries and the most common variant of the process,\" you would:\n",
    "   1. Identify two subtasks: \"Find late deliveries\" and \"Identify the most common variant.\"\n",
    "   2. For each subtask, call the `handoff_to_prompt_generator` and `handoff_to_sql_generator` tools.\n",
    "   3. Combine the results and return a final answer.\n",
    "\n",
    "'''\n",
    "\n",
    "supervisor= Assistant(llm=llm_cfg,\n",
    "                system_message=supervisor_instruction,\n",
    "                function_list=['handoff_to_prompt_generator','handoff_to_sql_generator'],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08b160ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "\n",
      "[TOOL_CALL] handoff_to_prompt_generator\n",
      "{\"task\": \"Identify late deliveries\"}\n",
      "[TOOL_CALL] handoff_to_prompt_generator\n",
      "{\"task\": \"Identify the most common variant\"}\n",
      "[TOOL_RESPONSE] handoff_to_prompt_generator\n",
      "To identify late deliveries, we can focus on the `cases` table, which contains a column `on_time` that indicates whether a delivery was on time or late. A value of `False` in the `on_time` column means the delivery was late.\n",
      "\n",
      "### Instructions for Querying:\n",
      "- Filter the `cases` table where `on_time = False` to identify late deliveries.\n",
      "- You can further enrich the query by including additional details such as the actual delivery date (`delivery`), estimated delivery date (`estimated_delivery`), and the order date (`order_date`).\n",
      "\n",
      "### Relevant Columns in the `cases` Table:\n",
      "| Column Name             | Data Type         | Description                                      |\n",
      "|-------------------------|-------------------|--------------------------------------------------|\n",
      "| `id`                    | VARCHAR           | Unique identifier for each case                  |\n",
      "| `delivery`              | TIMESTAMP_NS      | Actual delivery date                             |\n",
      "| `estimated_delivery`   | TIMESTAMP_NS      | Estimated delivery date                          |\n",
      "| `order_date`            | TIMESTAMP_NS      | Date the order was placed                        |\n",
      "| `on_time`               | BOOLEAN           | Whether the delivery was on time (False means late delivery) |\n",
      "\n",
      "You can now use these columns to formulate a SQL query to identify late deliveries.\n",
      "[TOOL_RESPONSE] handoff_to_prompt_generator\n",
      "The most common variant can be identified by finding the variant with the highest `number_cases` or `percentage` value in the `variants` table. Here is the schema of the `variants` table, which includes the relevant columns:\n",
      "\n",
      "### Variants Table Schema\n",
      "| Column Name       | Data Type    | Description                                       |\n",
      "|-------------------|--------------|---------------------------------------------------|\n",
      "| id                | BIGINT       | Unique ID for each variant                        |\n",
      "| activities        | VARCHAR[]    | Ordered list of activity names in this variant    |\n",
      "| cases             | VARCHAR[]    | Array of case IDs following this variant          |\n",
      "| number_cases      | BIGINT       | Number of cases following this variant            |\n",
      "| percentage        | DOUBLE       | Share of total cases for this variant             |\n",
      "| avg_time          | DOUBLE       | Average processing time for this variant          |\n",
      "\n",
      "### Instructions\n",
      "To identify the most common variant, you can query the `variants` table and sort by `number_cases` or `percentage` in descending order. Then, select the top row.\n",
      "\n",
      "For example, to find the variant with the highest number of cases:\n",
      "```sql\n",
      "SELECT id, number_cases, percentage, avg_time\n",
      "FROM variants\n",
      "ORDER BY number_cases DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "This query will return the variant with the highest number of cases, which is likely the most common variant."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m messages.append({\u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m: query})\n\u001b[32m      5\u001b[39m response_plain_text = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msupervisor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_plain_text\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypewriter_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_plain_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m response_plain_text = remove_think_blocks(response_plain_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\qwen_agent\\agent.py:110\u001b[39m, in \u001b[36mAgent.run\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m             \u001b[38;5;28;01massert\u001b[39;00m new_messages[\u001b[32m0\u001b[39m][CONTENT][\u001b[32m0\u001b[39m].text\n\u001b[32m    107\u001b[39m             new_messages[\u001b[32m0\u001b[39m][CONTENT] = [ContentItem(text=\u001b[38;5;28mself\u001b[39m.system_message + \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    108\u001b[39m                                        ] + new_messages[\u001b[32m0\u001b[39m][CONTENT]  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrsp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrsp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrsp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\qwen_agent\\agents\\fncall_agent.py:73\u001b[39m, in \u001b[36mFnCallAgent._run\u001b[39m\u001b[34m(self, messages, lang, **kwargs)\u001b[39m\n\u001b[32m     69\u001b[39m output_stream = \u001b[38;5;28mself\u001b[39m._call_llm(messages=messages,\n\u001b[32m     70\u001b[39m                                functions=[func.function \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_map.values()],\n\u001b[32m     71\u001b[39m                                extra_generate_cfg=extra_generate_cfg)\n\u001b[32m     72\u001b[39m output: List[Message] = []\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\qwen_agent\\llm\\base.py:370\u001b[39m, in \u001b[36mBaseChatModel._convert_messages_iterator_to_target_type\u001b[39m\u001b[34m(self, messages_iter, target_type)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert_messages_iterator_to_target_type\u001b[39m(\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m, messages_iter: Iterator[List[Message]],\n\u001b[32m    369\u001b[39m         target_type: \u001b[38;5;28mstr\u001b[39m) -> Union[Iterator[List[Message]], Iterator[List[Dict]]]:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_messages_to_target_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\qwen_agent\\llm\\base.py:249\u001b[39m, in \u001b[36mBaseChatModel.chat.<locals>._format_and_cache\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_and_cache\u001b[39m() -> Iterator[List[Message]]:\n\u001b[32m    248\u001b[39m     o = []\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msupport_multimodal_output\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\qwen_agent\\llm\\base.py:354\u001b[39m, in \u001b[36mBaseChatModel._postprocess_messages_iterator\u001b[39m\u001b[34m(self, messages, fncall_mode, generate_cfg)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_postprocess_messages_iterator\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     messages: Iterator[List[Message]],\n\u001b[32m    350\u001b[39m     fncall_mode: \u001b[38;5;28mbool\u001b[39m,\n\u001b[32m    351\u001b[39m     generate_cfg: \u001b[38;5;28mdict\u001b[39m,\n\u001b[32m    352\u001b[39m ) -> Iterator[List[Message]]:\n\u001b[32m    353\u001b[39m     pre_msg = []\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpre_msg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_postprocess_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_msg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfncall_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfncall_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_cfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerate_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mLLM Output:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpformat([_.model_dump()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39m_\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mpre_msg],\u001b[38;5;250m \u001b[39mindent=\u001b[32m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\qwen_agent\\llm\\base.py:622\u001b[39m, in \u001b[36mretry_model_service_iterator\u001b[39m\u001b[34m(it_fn, max_retries)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m622\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrsp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrsp\u001b[49m\n\u001b[32m    624\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\qwen_agent\\llm\\oai.py:90\u001b[39m, in \u001b[36mTextChatAtOAI._chat_stream\u001b[39m\u001b[34m(self, messages, delta_stream, generate_cfg)\u001b[39m\n\u001b[32m     88\u001b[39m messages = \u001b[38;5;28mself\u001b[39m.convert_messages_to_dicts(messages)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_complete_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m delta_stream:\n\u001b[32m     92\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\qwen_agent\\llm\\oai.py:62\u001b[39m, in \u001b[36mTextChatAtOAI.__init__.<locals>._chat_complete_create\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mrequest_timeout\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m     60\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m] = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mrequest_timeout\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mapi_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m client.chat.completions.create(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\openai\\_client.py:144\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    142\u001b[39m     base_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28mself\u001b[39m._default_stream_cls = Stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\openai\\_base_client.py:854\u001b[39m, in \u001b[36mSyncAPIClient.__init__\u001b[39m\u001b[34m(self, version, base_url, max_retries, timeout, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[39m\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    841\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid `http_client` argument; Expected an instance of `httpx.Client` but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(http_client)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    842\u001b[39m     )\n\u001b[32m    844\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    845\u001b[39m     version=version,\n\u001b[32m    846\u001b[39m     \u001b[38;5;66;03m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    852\u001b[39m     _strict_response_validation=_strict_response_validation,\n\u001b[32m    853\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m \u001b[38;5;28mself\u001b[39m._client = http_client \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mSyncHttpxClientWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[39;49;00m\n\u001b[32m    857\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\openai\\_base_client.py:784\u001b[39m, in \u001b[36m_DefaultHttpxClient.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    782\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mlimits\u001b[39m\u001b[33m\"\u001b[39m, DEFAULT_CONNECTION_LIMITS)\n\u001b[32m    783\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mfollow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpx\\_client.py:688\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, auth, params, headers, cookies, verify, cert, trust_env, http1, http2, proxy, mounts, timeout, follow_redirects, limits, max_redirects, event_hooks, base_url, transport, default_encoding)\u001b[39m\n\u001b[32m    685\u001b[39m allow_env_proxies = trust_env \u001b[38;5;129;01mand\u001b[39;00m transport \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    686\u001b[39m proxy_map = \u001b[38;5;28mself\u001b[39m._get_proxy_map(proxy, allow_env_proxies)\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m \u001b[38;5;28mself\u001b[39m._transport = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_transport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28mself\u001b[39m._mounts: \u001b[38;5;28mdict\u001b[39m[URLPattern, BaseTransport | \u001b[38;5;28;01mNone\u001b[39;00m] = {\n\u001b[32m    698\u001b[39m     URLPattern(key): \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, proxy \u001b[38;5;129;01min\u001b[39;00m proxy_map.items()\n\u001b[32m    710\u001b[39m }\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mounts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpx\\_client.py:731\u001b[39m, in \u001b[36mClient._init_transport\u001b[39m\u001b[34m(self, verify, cert, trust_env, http1, http2, limits, transport)\u001b[39m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transport \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    729\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m transport\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHTTPTransport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:153\u001b[39m, in \u001b[36mHTTPTransport.__init__\u001b[39m\u001b[34m(self, verify, cert, trust_env, http1, http2, limits, proxy, uds, local_address, retries, socket_options)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    152\u001b[39m proxy = Proxy(url=proxy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(proxy, (\u001b[38;5;28mstr\u001b[39m, URL)) \u001b[38;5;28;01melse\u001b[39;00m proxy\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m ssl_context = \u001b[43mcreate_ssl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28mself\u001b[39m._pool = httpcore.ConnectionPool(\n\u001b[32m    157\u001b[39m         ssl_context=ssl_context,\n\u001b[32m    158\u001b[39m         max_connections=limits.max_connections,\n\u001b[32m   (...)\u001b[39m\u001b[32m    166\u001b[39m         socket_options=socket_options,\n\u001b[32m    167\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\emers\\Downloads\\Github\\LLM-Testing\\.venv\\Lib\\site-packages\\httpx\\_config.py:40\u001b[39m, in \u001b[36mcreate_ssl_context\u001b[39m\u001b[34m(verify, cert, trust_env)\u001b[39m\n\u001b[32m     37\u001b[39m         ctx = ssl.create_default_context(capath=os.environ[\u001b[33m\"\u001b[39m\u001b[33mSSL_CERT_DIR\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;66;03m# Default case...\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         ctx = \u001b[43mssl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_default_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcafile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcertifi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m verify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m     42\u001b[39m     ctx = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:717\u001b[39m, in \u001b[36mcreate_default_context\u001b[39m\u001b[34m(purpose, cafile, capath, cadata)\u001b[39m\n\u001b[32m    713\u001b[39m context.verify_flags |= (_ssl.VERIFY_X509_PARTIAL_CHAIN |\n\u001b[32m    714\u001b[39m                          _ssl.VERIFY_X509_STRICT)\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cafile \u001b[38;5;129;01mor\u001b[39;00m capath \u001b[38;5;129;01mor\u001b[39;00m cadata:\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_verify_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcafile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m context.verify_mode != CERT_NONE:\n\u001b[32m    719\u001b[39m     \u001b[38;5;66;03m# no explicit cafile, capath or cadata but the verify mode is\u001b[39;00m\n\u001b[32m    720\u001b[39m     \u001b[38;5;66;03m# CERT_OPTIONAL or CERT_REQUIRED. Let's try to load default system\u001b[39;00m\n\u001b[32m    721\u001b[39m     \u001b[38;5;66;03m# root CA certificates for the given purpose. This may fail silently.\u001b[39;00m\n\u001b[32m    722\u001b[39m     context.load_default_certs(purpose)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "messages= []\n",
    "query = 'Identify late deliveries and the most common variant.'\n",
    "# Append the user query to the chat history.\n",
    "messages.append({'role': 'user', 'content': query})\n",
    "response_plain_text = ''\n",
    "\n",
    "for response in supervisor.run(messages=messages):\n",
    "        response_plain_text = typewriter_print(response, response_plain_text)\n",
    "response_plain_text = remove_think_blocks(response_plain_text)\n",
    "messages.append({'role': 'assistant', 'content': response_plain_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b347be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2897a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "import logging\n",
    "from Tools.Logger import setup_logger\n",
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "from db_create import CargaDeArchivos\n",
    "\n",
    "#tools\n",
    "from Tools.Tool import run_sql_workflow, run_think_task, remove_think_tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a95c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Logger instantiation ===\n",
    "setup_logger()\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc31642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exitoso\n"
     ]
    }
   ],
   "source": [
    "# === Tokenizer logging ==\n",
    "try:\n",
    "    login(token=\"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\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during tokenizer setup: {e}\", exc_info=True)\n",
    "    raise\n",
    "\n",
    "# === Database population and connection ===\n",
    "try:\n",
    "    db_manager = CargaDeArchivos()\n",
    "    db_manager.run()\n",
    "    db_conn = db_manager.conn\n",
    "    print('Exitoso')\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during database population and connection: {e}\", exc_info=True)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f8c08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Orchestrator state ==\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    plan: List[dict]\n",
    "    current_step: int\n",
    "    results: Dict[str, Any]\n",
    "    query_results: List[str]\n",
    "    db_conn: None\n",
    "    tokenizer: any\n",
    "    use_case: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df70ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == SQL prompts per case of use==\n",
    "p1_p = \"\"\" /no_think\n",
    "    You are an SQL assistant specialized in DuckDB. Your task is to generate accurate SQL queries based on natural language questions, following the schema and rules below.\n",
    "    \n",
    "    ### Schema (Aliased)\n",
    "    \n",
    "    - **cases**  (one row per process instance)\n",
    "        - id (VARCHAR): Unique identifier for each case\n",
    "        - order_date (TIMESTAMP_NS): Date when the order was placed\n",
    "        - employee_id (VARCHAR): ID of the employee handling the case\n",
    "        - branch (VARCHAR): Branch where the order originated\n",
    "        - supplier (VARCHAR): Supplier involved in the case\n",
    "        - avg_time (DOUBLE): Total duration of the case in time units\n",
    "        - estimated_delivery (TIMESTAMP_NS): Expected delivery date\n",
    "        - delivery (TIMESTAMP_NS): Actual delivery date\n",
    "        - on_time (BOOLEAN): Whether the delivery met the deadline\n",
    "        - in_full (BOOLEAN): Whether the order was delivered in full\n",
    "        - number_of_items (INTEGER): Total items in the case\n",
    "        - ft_items (INTEGER): Number of full/complete items delivered\n",
    "        - total_price (DOUBLE): Total price of the order\n",
    "        - total_activities (INTEGER): Number of activities in the case\n",
    "        - rework_activities (INTEGER): Count of repeated/rework activities\n",
    "        - automatic_activities (INTEGER): Count of system-generated activities\n",
    "    \n",
    "    - **activities**  (one row per activity within a process)\n",
    "        - id (INTEGER): Unique identifier for the activity\n",
    "        - timestamp (TIMESTAMP): When the activity occurred\n",
    "        - name (VARCHAR): Name of the activity\n",
    "        - tpt (DOUBLE): Time passed since the previous activity\n",
    "        - user (VARCHAR): Person who performed the activity\n",
    "        - user_type (VARCHAR): Role of the user (e.g., employee, system)\n",
    "        - automatic (BOOLEAN): Whether the activity was system-generated\n",
    "        - rework (BOOLEAN): Whether the activity was a rework/repeat\n",
    "        - case_index (INTEGER): Position of the activity within the case\n",
    "        - case_id (VARCHAR): ID of the associated case\n",
    "        - case_order_date (TIMESTAMP): Order date for the case\n",
    "        - case_employee_id (VARCHAR): Employee ID for the case\n",
    "        - case_branch (VARCHAR): Branch handling the case\n",
    "        - case_supplier (VARCHAR): Supplier involved in the case\n",
    "        - case_avg_time (DOUBLE): Total duration of the case\n",
    "        - case_estimated_delivery (TIMESTAMP): Expected delivery date\n",
    "        - case_delivery (TIMESTAMP): Actual delivery date\n",
    "        - case_on_time (BOOLEAN): Whether the case was delivered on time\n",
    "        - case_in_full (BOOLEAN): Whether the order was complete\n",
    "        - case_number_of_items (INTEGER): Total items in the case\n",
    "        - case_ft_items (INTEGER): Number of full/complete items\n",
    "        - case_total_price (DOUBLE): Total price of the case\n",
    "    \n",
    "    - **variants**  \n",
    "      - id (BIGINT): Variant ID (PK for path)  \n",
    "      - activities (VARCHAR[]): Ordered activity names for this path  \n",
    "      - cases (VARCHAR[]): IDs of cases that followed this path (→ cases.id)  \n",
    "      - number_cases (BIGINT): Total cases following this variant  \n",
    "      - percentage (DOUBLE): Percentage of total cases  \n",
    "      - avg_time (DOUBLE): Avg duration (sec) across cases in this variant\n",
    "    \n",
    "    ### Query Guidelines\n",
    "    \n",
    "    1. Always reference columns with aliases (e.g., c.id, a.case_id).\n",
    "    2. Use UNNEST() in the FROM clause to access list fields like v.activities or v.cases. Do not use UNNEST() inside expressions like = ANY(...).\n",
    "    3. When comparing list values (e.g., activity names), first UNNEST the list in a subquery or CTE, then use direct comparison with TRIM(...).\n",
    "    4. Use TRIM() when comparing activity names (e.g., TRIM(a.name) = TRIM(...)).\n",
    "    5. Avoid unnecessary joins or full scans when possible.\n",
    "    6. Convert time differences with EXTRACT(EPOCH FROM ...).\n",
    "    7. Include all non-aggregated columns in GROUP BY.\n",
    "    \n",
    "    ### Variant Comparison Rules\n",
    "    \n",
    "    - **Most Frequent Path:**  \n",
    "      SELECT * FROM variants WHERE number_cases = (SELECT MAX(number_cases) FROM variants)\n",
    "    \n",
    "    - **Variant Durations:**  \n",
    "      Use avg_time from variants. Do not recompute durations from activities unless explicitly requested.\n",
    "    \n",
    "    - **Deviations:**  \n",
    "      Variants with id different from the most frequent one are deviations.  \n",
    "      To detect deviation points, compare activities with the most frequent variant.\n",
    "    \n",
    "    - **Activity Durations Along Most Frequent Path:**  \n",
    "      1. Extract activities using UNNEST(v.activities) AS activity.  \n",
    "      2. Join with activities table using TRIM(v_activity) = TRIM(a.name).  \n",
    "      3. Group by activity name and compute average tpt.\n",
    "    \n",
    "    ### Common Pitfall Corrections\n",
    "    \n",
    "    - Never use UNNEST() inside = ANY(...). Use UNNEST in a FROM clause or CTE, then join or filter.\n",
    "    - Avoid > ALL(...). Prefer ORDER BY ... LIMIT 1 or = (SELECT MAX(...)).\n",
    "    - Use subqueries for filtered aggregations, like:\n",
    "    \n",
    "      SELECT branch  \n",
    "      FROM cases  \n",
    "      WHERE approved = TRUE  \n",
    "      GROUP BY branch  \n",
    "      ORDER BY AVG(value) DESC  \n",
    "      LIMIT 1\n",
    "    \n",
    "    - When aggregating on top branches, use subqueries or IN with preselected sets.\n",
    "    - If no data matches a filter, return NULL instead of error.\n",
    "    - To detect repeated activities on the same day:\n",
    "    \n",
    "      SELECT a.case_id, DATE_TRUNC('day', a.timestamp), COUNT(*)  \n",
    "      FROM activities AS a  \n",
    "      GROUP BY a.case_id, DATE_TRUNC('day', a.timestamp)  \n",
    "      HAVING COUNT(*) > 1\n",
    "    \n",
    "      (Avoid GENERATE_SERIES here.)\n",
    "    \n",
    "    ### Error Examples\n",
    "    \n",
    "    *Incorrect:*\n",
    "    \n",
    "    ```sql\n",
    "    SELECT branch FROM activities;\n",
    "    -- Error: 'branch' does not exist in 'activities'\n",
    "\n",
    "    SELECT case.id, name FROM grouped;\n",
    "    -- Error: 'case' is a nested object, use json_extract or UNNEST first\n",
    "\n",
    "    SELECT a.name, c.total_price FROM activities AS a, cases AS c;\n",
    "    -- Error: Cartesian join without ON condition\n",
    "\n",
    "    *Correct:*\n",
    "    SELECT a.name, c.total_price\n",
    "    FROM activities AS a\n",
    "    JOIN cases AS c ON a.case_id = c.id;\n",
    "\n",
    "    ###Output\n",
    "    Return only the SQL query. No markdown, no tags, no explanation.\n",
    "    Never guess values. Infer only from schema and question.\n",
    "    \"\"\"\n",
    "\n",
    "p2_p= \"\"\"/no_think \n",
    "      ### Database Schema\n",
    "\n",
    "                - **cases**  \n",
    "        - id (VARCHAR): Case identifier (PK)  \n",
    "        - avg_time (DOUBLE): Total duration (sec) from start to closure  \n",
    "        - type, branch, ramo, broker, state, client, creator (VARCHAR): Case metadata  \n",
    "        - value (BIGINT): Insurance amount  \n",
    "        - approved (BOOLEAN): Approval status  \n",
    "        - case_order_date, case_estimated_delivery, case_delivery (TIMESTAMP): Case timestamps  \n",
    "        - case_employee_id, case_branch, case_supplier (VARCHAR): Case-specific information  \n",
    "        - case_number_of_items, case_ft_items (INTEGER): Case item details  \n",
    "        - case_total_price (DOUBLE): Case total price\n",
    "\n",
    "        - **activities**  \n",
    "        - id (BIGINT): Activity identifier (PK)  \n",
    "        - case_id (VARCHAR): Case ID (FK → cases.id)  \n",
    "        - timestamp (TIMESTAMP): Activity timestamp  \n",
    "        - name (VARCHAR): Activity name  \n",
    "        - case_index (BIGINT): Alias of id  \n",
    "        - tpt (DOUBLE): Duration of the activity in seconds  \n",
    "        - user, user_type (VARCHAR): User-related info  \n",
    "        - automatic, rework (BOOLEAN): Activity flags  \n",
    "        - case_order_date (TIMESTAMP), case_employee_id (VARCHAR), case_branch (VARCHAR), case_supplier (VARCHAR): Case-related data  \n",
    "        - case_avg_time (DOUBLE): Average time for the case  \n",
    "        - case_on_time, case_in_full (BOOLEAN): Delivery status flags  \n",
    "        - case_number_of_items, case_ft_items (INTEGER): Case item counts  \n",
    "        - case_total_price (DOUBLE): Case total price  \n",
    "        - case_estimated_delivery, case_delivery (TIMESTAMP): Delivery-related timestamps\n",
    "\n",
    "        - **variants**  \n",
    "        - id (BIGINT): Variant ID (PK for path)  \n",
    "        - activities (VARCHAR[]): Ordered activity names for this path  \n",
    "        - cases (VARCHAR[]): IDs of cases that followed this path (→ cases.id)  \n",
    "        - number_cases (BIGINT): Total cases following this variant  \n",
    "        - percentage (DOUBLE): Percentage of total cases  \n",
    "        - avg_time (DOUBLE): Avg duration (sec) across cases in this variant\n",
    "\n",
    "            **Relations:**\n",
    "            - \"variants\".\"cases\" references \"cases\".\"id\", meaning each variant is followed by multiple cases.\n",
    "            - \"variants\".\"activities\" corresponds to the ordered \"activities\".\"name\" values for those cases.\n",
    "            \"\"\"\n",
    "p1_i= \"\"\" /no_think\n",
    "        You are an SQL assistant specialized in DuckDB. Your task is to generate accurate SQL queries based on natural language questions, following the schema and rules below.\n",
    "\n",
    "        ### Schema (Aliased)\n",
    "\n",
    "            - **grouped (g)**  \n",
    "            - group_id (VARCHAR): Unique identifier for each group (PK)  \n",
    "            - amount_overpaid (BIGINT): Total overpaid amount for the group  \n",
    "            - itemCount (BIGINT): Number of items in the group  \n",
    "            - date (VARCHAR): Date of the group  \n",
    "            - pattern (VARCHAR): Pattern type for the group 'Similar Value','Similar Reference','Exact Match','Similar Date','Similar Vendor','Multiple'\n",
    "            - open (BOOLEAN): Status of the group (open or closed)  \n",
    "            - confidence (VARCHAR): Confidence level for detecting the pattern (e.g., \"High\", \"Medium\", \"Low\")  \n",
    "            - items (STRUCT[]): Array of items within the group, each containing:\n",
    "                - **id (INTEGER)**: Item identifier (FK → invoices.id)\n",
    "                - **case (STRUCT)**: Contains case details, such as:\n",
    "                    - id (VARCHAR): Case identifier  \n",
    "                    - order_date (VARCHAR): Order date for the case  \n",
    "                    - employee_id (VARCHAR): Employee ID handling the case  \n",
    "                    - branch (VARCHAR): Branch handling the case  \n",
    "                    - supplier (VARCHAR): Supplier associated with the case  \n",
    "                    - avg_time (DOUBLE): Average time for the case  \n",
    "                    - estimated_delivery (VARCHAR): Estimated delivery date for the case  \n",
    "                    - delivery (VARCHAR): Actual delivery date for the case  \n",
    "                    - on_time (BOOLEAN): Whether the case was delivered on time  \n",
    "                    - in_full (BOOLEAN): Whether the case was delivered in full  \n",
    "                    - number_of_items (INTEGER): Number of items in the case  \n",
    "                    - ft_items (INTEGER): Number of full-time items in the case  \n",
    "                    - total_price (INTEGER): Total price of the case  \n",
    "                - date (VARCHAR): Date of the item  \n",
    "                - unit_price (VARCHAR): Unit price of the item  \n",
    "                - quantity (INTEGER): Quantity of the item  \n",
    "                - value (VARCHAR): Value of the item  \n",
    "                - pattern (VARCHAR): Pattern type for the group 'Similar Value','Similar Reference','Exact Match','Similar Date','Similar Vendor','Multiple'  \n",
    "                - open (BOOLEAN): Status of the item (open or closed)  \n",
    "                - group_id (VARCHAR): Group identifier (FK → grouped.group_id)  \n",
    "                - confidence (VARCHAR): Confidence level for the item’s pattern (e.g., \"high\", \"medium\", \"low\")  \n",
    "                - description (VARCHAR): Description of the item  \n",
    "                - payment_method (VARCHAR): Payment method used for the item  \n",
    "                - pay_date (VARCHAR): Payment date of the item  \n",
    "                - special_instructions (VARCHAR): Special instructions for the item  \n",
    "                - accuracy (INTEGER): Accuracy of the item’s data matching\n",
    "\n",
    "            - **invoices (i)**  \n",
    "            - id (BIGINT): Invoice identifier (PK)  \n",
    "            - date (TIMESTAMP_NS): Date and time the invoice was issued  \n",
    "            - unit_price (VARCHAR): Unit price of the item in the invoice  \n",
    "            - quantity (BIGINT): Number of items in the invoice  \n",
    "            - value (VARCHAR): Total value of the invoice  \n",
    "            - pattern (VARCHAR): Pattern type for the group 'Similar Value','Similar Reference','Exact Match','Similar Date','Similar Vendor','Multiple'\n",
    "            - open (BOOLEAN): Status of the invoice (open or closed)  \n",
    "            - group_id (VARCHAR): Group identifier (FK → grouped.group_id)  \n",
    "            - confidence (VARCHAR): Confidence level for the invoice's pattern (e.g., \"High\", \"Medium\", \"Low\")  \n",
    "            - description (VARCHAR): Description of the invoice  \n",
    "            - payment_method (VARCHAR): Method used for payment  \n",
    "            - pay_date (TIMESTAMP_NS): Date and time the invoice was paid  \n",
    "            - special_instructions (VARCHAR): Any special instructions for the invoice  \n",
    "            - accuracy (BIGINT): Accuracy of the invoice's data matching  \n",
    "            - case_id (VARCHAR): Case identifier associated with the invoice  \n",
    "            - case_order_date (TIMESTAMP_NS): Order date of the case  \n",
    "            - case_employee_id (VARCHAR): Employee associated with the case  \n",
    "            - case_branch (VARCHAR): Branch where the case was handled  \n",
    "            - case_supplier (VARCHAR): Supplier associated with the case  \n",
    "            - case_avg_time (DOUBLE): Average time for the case  \n",
    "            - case_estimated_delivery (TIMESTAMP_NS): Estimated delivery date for the case  \n",
    "            - case_delivery (TIMESTAMP_NS): Actual delivery date for the case  \n",
    "            - case_on_time (BOOLEAN): Whether the case was delivered on time  \n",
    "            - case_in_full (BOOLEAN): Whether the case was delivered in full  \n",
    "            - case_number_of_items (BIGINT): Number of items in the case  \n",
    "            - case_ft_items (BIGINT): Number of full-time items in the case  \n",
    "            - case_total_price (BIGINT): Total price of the case\n",
    "\n",
    "        ### Query Guidelines\n",
    "\n",
    "        1. **Prefer Direct Tables**:  \n",
    "        Use `grouped (g)` or `invoices (i)` directly unless item-level fields are explicitly needed.\n",
    "\n",
    "        2. **UNNEST Only When Necessary**:\n",
    "        - Only use `UNNEST(g.items) AS item` when accessing nested fields (e.g., `item.case.supplier`, `item.unit_price`, etc.)\n",
    "        - After unnesting, access fields as `item.field` or `item.case.supplier`, **not** `item.unnest.field`.\n",
    "\n",
    "        3. **Nesting and Access Rules**:\n",
    "        - To access supplier from `grouped`, unnest items and use:  \n",
    "            ```sql\n",
    "            FROM grouped g, UNNEST(g.items) AS item\n",
    "            WHERE item.case.supplier = 'Example'\n",
    "            ```\n",
    "        - Avoid referencing nested fields without unnesting first.\n",
    "\n",
    "        4. **Case Sensitivity**:\n",
    "        - Use exact case for values:\n",
    "            - Confidence: 'High', 'Medium', 'Low'\n",
    "            - Pattern: 'Similar Value', 'Similar Reference', 'Exact Match', 'Similar Date', 'Similar Vendor', 'Multiple'\n",
    "\n",
    "        5. **Use Table Aliases**:\n",
    "        - Always use `g.` for `grouped`, `i.` for `invoices`, and `item.` after unnesting.\n",
    "\n",
    "        6. **Use TRIM() for Comparisons**:\n",
    "        - For text comparisons like pattern or supplier, wrap with `TRIM()`.  \n",
    "            Example: `TRIM(item.case.supplier) = 'VendorName'`\n",
    "\n",
    "        7. **Use IN / = ANY for Multiple Matches**:\n",
    "        - Use `pattern = ANY (['Value1', 'Value2'])` or `IN (...)` instead of OR chains.\n",
    "\n",
    "        8. **GROUP BY Nested Fields**:\n",
    "        - If grouping by nested fields like supplier, first unnest, then group by `item.case.supplier`.\n",
    "\n",
    "        9. **Aggregation and Filtering**:\n",
    "        - Use `ORDER BY ... LIMIT 1` instead of `> ALL(...)`\n",
    "        - Filter early with WHERE clauses to improve performance.\n",
    "\n",
    "        10. **Alternative Access**:\n",
    "        - Use `invoices` for simpler flat queries (e.g., `i.case_supplier`).\n",
    "\n",
    "        ---\n",
    "\n",
    "        ### Output Rules\n",
    "\n",
    "        - ❌ Do NOT explain the query.\n",
    "        - ✅ Only return the SQL query (no markdown, no comments, no formatting).\n",
    "        - ❌ Do NOT guess field names.\n",
    "        - ✅ Always respect the provided schema and capitalization.\n",
    "        \"\"\"\n",
    "\n",
    "p2_i= \"\"\" /no_think\n",
    "    ### Schema (Aliased)\n",
    "\n",
    "    - **grouped (g)**  \n",
    "    - group_id (VARCHAR): Unique identifier for each group (PK)  \n",
    "    - amount_overpaid (BIGINT): Total overpaid amount for the group  \n",
    "    - itemCount (BIGINT): Number of items in the group  \n",
    "    - date (VARCHAR): Date of the group  \n",
    "    - pattern (VARCHAR): Pattern type for the group 'Similar Value','Similar Reference','Exact Match','Similar Date','Similar Vendor','Multiple'\n",
    "    - open (BOOLEAN): Status of the group (open or closed)  \n",
    "    - confidence (VARCHAR): Confidence level for detecting the pattern (e.g., \"High\", \"Medium\", \"Low\")  \n",
    "    - items (STRUCT[]): Array of items within the group, each containing:\n",
    "        - **id (INTEGER)**: Item identifier (FK → invoices.id)\n",
    "        - **case (STRUCT)**: Contains case details, such as:\n",
    "            - id (VARCHAR): Case identifier  \n",
    "            - order_date (VARCHAR): Order date for the case  \n",
    "            - employee_id (VARCHAR): Employee ID handling the case  \n",
    "            - branch (VARCHAR): Branch handling the case  \n",
    "            - supplier (VARCHAR): Supplier associated with the case  \n",
    "            - avg_time (DOUBLE): Average time for the case  \n",
    "            - estimated_delivery (VARCHAR): Estimated delivery date for the case  \n",
    "            - delivery (VARCHAR): Actual delivery date for the case  \n",
    "            - on_time (BOOLEAN): Whether the case was delivered on time  \n",
    "            - in_full (BOOLEAN): Whether the case was delivered in full  \n",
    "            - number_of_items (INTEGER): Number of items in the case  \n",
    "            - ft_items (INTEGER): Number of full-time items in the case  \n",
    "            - total_price (INTEGER): Total price of the case  \n",
    "        - date (VARCHAR): Date of the item  \n",
    "        - unit_price (VARCHAR): Unit price of the item  \n",
    "        - quantity (INTEGER): Quantity of the item  \n",
    "        - value (VARCHAR): Value of the item  \n",
    "        - pattern (VARCHAR): Pattern type for the group 'Similar Value','Similar Reference','Exact Match','Similar Date','Similar Vendor','Multiple'  \n",
    "        - open (BOOLEAN): Status of the item (open or closed)  \n",
    "        - group_id (VARCHAR): Group identifier (FK → grouped.group_id)  \n",
    "        - confidence (VARCHAR): Confidence level for the item’s pattern (e.g., \"high\", \"medium\", \"low\")  \n",
    "        - description (VARCHAR): Description of the item  \n",
    "        - payment_method (VARCHAR): Payment method used for the item  \n",
    "        - pay_date (VARCHAR): Payment date of the item  \n",
    "        - special_instructions (VARCHAR): Special instructions for the item  \n",
    "        - accuracy (INTEGER): Accuracy of the item’s data matching\n",
    "\n",
    "    - **invoices (i)**  \n",
    "    - id (BIGINT): Invoice identifier (PK)  \n",
    "    - date (TIMESTAMP_NS): Date and time the invoice was issued  \n",
    "    - unit_price (VARCHAR): Unit price of the item in the invoice  \n",
    "    - quantity (BIGINT): Number of items in the invoice  \n",
    "    - value (VARCHAR): Total value of the invoice  \n",
    "    - pattern (VARCHAR): Pattern type for the group 'Similar Value','Similar Reference','Exact Match','Similar Date','Similar Vendor','Multiple'\n",
    "    - open (BOOLEAN): Status of the invoice (open or closed)  \n",
    "    - group_id (VARCHAR): Group identifier (FK → grouped.group_id)  \n",
    "    - confidence (VARCHAR): Confidence level for the invoice's pattern (e.g., \"High\", \"Medium\", \"Low\")  \n",
    "    - description (VARCHAR): Description of the invoice  \n",
    "    - payment_method (VARCHAR): Method used for payment  \n",
    "    - pay_date (TIMESTAMP_NS): Date and time the invoice was paid  \n",
    "    - special_instructions (VARCHAR): Any special instructions for the invoice  \n",
    "    - accuracy (BIGINT): Accuracy of the invoice's data matching  \n",
    "    - case_id (VARCHAR): Case identifier associated with the invoice  \n",
    "    - case_order_date (TIMESTAMP_NS): Order date of the case  \n",
    "    - case_employee_id (VARCHAR): Employee associated with the case  \n",
    "    - case_branch (VARCHAR): Branch where the case was handled  \n",
    "    - case_supplier (VARCHAR): Supplier associated with the case  \n",
    "    - case_avg_time (DOUBLE): Average time for the case  \n",
    "    - case_estimated_delivery (TIMESTAMP_NS): Estimated delivery date for the case  \n",
    "    - case_delivery (TIMESTAMP_NS): Actual delivery date for the case  \n",
    "    - case_on_time (BOOLEAN): Whether the case was delivered on time  \n",
    "    - case_in_full (BOOLEAN): Whether the case was delivered in full  \n",
    "    - case_number_of_items (BIGINT): Number of items in the case  \n",
    "    - case_ft_items (BIGINT): Number of full-time items in the case  \n",
    "    - case_total_price (BIGINT): Total price of the case\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompts_sql_generation= {\"0\":[p1_p,p2_p],\n",
    "            \"1\":[p1_i,p2_i]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f876e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Orchestrator nodes ==\n",
    "def planner_node(state: AgentState) -> AgentState:\n",
    "    try:\n",
    "        user_question = state[\"question\"]\n",
    "\n",
    "        plan_prompt = \"\"\" /no_think\n",
    "\n",
    "        Generate a numbered list of up to 10 sequential tasks needed to fully answer the user's question.\n",
    "        \n",
    "        You have access to two tools:\n",
    "        - [SQL,0]: Process Mining\n",
    "        - [SQL,1]: Invoice Analysis\n",
    "        - [THINK]: Reasoning/Interpretation\n",
    "        \n",
    "        Each task should include:\n",
    "        - A \"type\" field specifying the tool to use.\n",
    "        - A \"description\" of what the task will do.\n",
    "        - A \"reason\" explaining why this task is necessary.\n",
    "        - A \"steps\" field that lists the numbers of prior activities whose outputs are required to complete this task. If the task does not depend on any previous output, use an empty list.\n",
    "        \n",
    "        Format your output as a JSON object like:\n",
    "        {{\n",
    "            \"ACTIVITY1\": {{\n",
    "                \"type\": \"[SQL,0]\",\n",
    "                \"description\": \"...\",\n",
    "                \"reason\": \"...\",\n",
    "                \"steps\": []\n",
    "            }},\n",
    "            \"ACTIVITY2\": {{\n",
    "                \"type\": \"[THINK]\",\n",
    "                \"description\": \"...\",\n",
    "                \"reason\": \"...\",\n",
    "                \"steps\": [1]\n",
    "            }},\n",
    "            ...\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        llm = OllamaLLM(model=\"qwen3:8b\", temperature=0.0, enable_thinking=False)\n",
    "        planner = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", plan_prompt),\n",
    "            (\"human\", \"user question: {task}\"),\n",
    "        ]) | llm | StrOutputParser()\n",
    "\n",
    "        raw_plan = planner.invoke({\"task\": user_question})\n",
    "        raw_plan = remove_think_tags(raw_plan)\n",
    "        print(raw_plan)\n",
    "\n",
    "        # Parse JSON-like plan\n",
    "        steps = []\n",
    "        pattern = re.compile(r'\"?(ACTIVITY\\d+)\"?\\s*:\\s*{')\n",
    "        lines = raw_plan.strip().splitlines()\n",
    "        current_step = None\n",
    "        #use_case = \"0\"\n",
    "\n",
    "        for line in lines:\n",
    "            match = pattern.match(line.strip())\n",
    "            if match:\n",
    "                if current_step:\n",
    "                    current_step.setdefault(\"type\", \"[THINK]\")\n",
    "                    current_step.setdefault(\"description\", \"\")\n",
    "                    current_step.setdefault(\"reason\", \"\")\n",
    "                    current_step.setdefault(\"steps\", [])\n",
    "                    steps.append(current_step)\n",
    "                current_step = {\"id\": match.group(1)}\n",
    "            elif current_step:\n",
    "                if '\"type\"' in line:\n",
    "                    task_type = re.search(r'\"type\"\\s*:\\s*\"([^\"]+)\",?', line)\n",
    "                    if task_type:\n",
    "                        current_step[\"type\"] = task_type.group(1)\n",
    "                        if \"[SQL,1]\" in task_type.group(1):\n",
    "                            use_case = \"1\"\n",
    "                elif '\"description\"' in line:\n",
    "                    desc = re.search(r'\"description\"\\s*:\\s*\"([^\"]+)\",?', line)\n",
    "                    if desc:\n",
    "                        current_step[\"description\"] = desc.group(1)\n",
    "                elif '\"reason\"' in line:\n",
    "                    reason = re.search(r'\"reason\"\\s*:\\s*\"([^\"]+)\",?', line)\n",
    "                    if reason:\n",
    "                        current_step[\"reason\"] = reason.group(1)\n",
    "                elif '\"steps\"' in line:\n",
    "                    steps_str = re.search(r'\"steps\"\\s*:\\s*\\[([^\\]]*)\\]', line)\n",
    "                    if steps_str:\n",
    "                        current_step[\"steps\"] = [int(x.strip())-1 for x in steps_str.group(1).split(\",\") if x.strip()]\n",
    "\n",
    "        if current_step:\n",
    "            current_step.setdefault(\"type\", \"[THINK]\")\n",
    "            current_step.setdefault(\"description\", \"\")\n",
    "            current_step.setdefault(\"reason\", \"\")\n",
    "            current_step.setdefault(\"steps\", [])\n",
    "            steps.append(current_step)\n",
    "\n",
    "        return {\n",
    "            \"plan\": steps,\n",
    "            \"current_step\": 0, # Start from the first step\n",
    "            \"results\": {},\n",
    "            \"query_results\": [],\n",
    "            \"db_conn\": db_conn,\n",
    "            \"tokenizer\": tokenizer,\n",
    "            \"use_case\": use_case,\n",
    "            \"question\": user_question\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error in planner_node: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "def execute_task_node(state: AgentState) -> AgentState:\n",
    "    try:\n",
    "        step = state[\"plan\"][state[\"current_step\"]]\n",
    "        task = step[\"description\"]\n",
    "        dependencies = step[\"steps\"]\n",
    "        logger.info(f\"Previous steps: {dependencies}\")\n",
    "        task_type = step[\"type\"]\n",
    "        # dependencies = step[\"steps\"] # Not used in this version. Usar en context con if step in dependencies\n",
    "\n",
    "        context = \"\\n\".join(f\"[Step {step}] {state['results'][step]}\" for step in sorted(state[\"results\"], key=int) if int(step) in dependencies)\n",
    "        logger.info(f\"Context: {context}\")\n",
    "\n",
    "        print(f\"\\n[Task {state['current_step'] + 1}] {task}\")\n",
    "\n",
    "        if \"SQL\" in task_type:\n",
    "            use_case = state[\"use_case\"]\n",
    "            system_prompt, repair_prompt = prompts_sql_generation[use_case]\n",
    "            answer, raw_result = run_sql_workflow(\n",
    "                task, state[\"db_conn\"], use_case, state[\"tokenizer\"], context, system_prompt, repair_prompt\n",
    "            )\n",
    "        else:\n",
    "            answer = run_think_task(task, context)\n",
    "            raw_result = answer\n",
    "\n",
    "        return {\n",
    "            \"plan\": state[\"plan\"],\n",
    "            \"results\": {**state[\"results\"],str(state[\"current_step\"]): answer}, #Saves answer before updating the current step\n",
    "            \"current_step\": state[\"current_step\"] + 1,            \n",
    "            \"query_results\": state[\"query_results\"] + [raw_result],\n",
    "            \"db_conn\": state[\"db_conn\"],\n",
    "            \"tokenizer\": state[\"tokenizer\"],\n",
    "            \"use_case\": state[\"use_case\"],\n",
    "            \"question\": state[\"question\"]\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error in execute_task_node: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7333967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Orchestrator routers ===\n",
    "def node_router(state: AgentState) -> str:\n",
    "    try:\n",
    "        next_node =  END if state[\"current_step\"] >= len(state[\"plan\"]) else \"execute_task\"\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error in node_router: {e}\")\n",
    "    return next_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95a49066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Orchetrator workflow ===\n",
    "def build_orchestrator_workflow():\n",
    "    try:\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"planner\", planner_node)\n",
    "        graph.add_node(\"execute_task\", execute_task_node)\n",
    "        graph.set_entry_point(\"planner\")\n",
    "        graph.add_edge(\"planner\", \"execute_task\")\n",
    "        graph.add_conditional_edges(\"execute_task\", node_router)\n",
    "        graph.set_finish_point(\"execute_task\")\n",
    "        return graph.compile()\n",
    "    except Exception as e:\n",
    "        logger.exception(f\" Error compiling Orchestrator workflow: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3af993b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ACTIVITY1\": {\n",
      "        \"type\": \"[SQL,1]\",\n",
      "        \"description\": \"Extract all invoice data from the database.\",\n",
      "        \"reason\": \"To have access to the full invoice dataset for analysis.\",\n",
      "        \"steps\": []\n",
      "    },\n",
      "    \"ACTIVITY2\": {\n",
      "        \"type\": \"[THINK]\",\n",
      "        \"description\": \"Identify potential duplicate invoice criteria (e.g., same invoice number, same customer, same amount, same date).\",\n",
      "        \"reason\": \"To define what constitutes a duplicate invoice for the analysis.\",\n",
      "        \"steps\": [1]\n",
      "    },\n",
      "    \"ACTIVITY3\": {\n",
      "        \"type\": \"[SQL,1]\",\n",
      "        \"description\": \"Group invoices by potential duplicate criteria and count occurrences.\",\n",
      "        \"reason\": \"To identify which invoices are duplicated based on the defined criteria.\",\n",
      "        \"steps\": [1, 2]\n",
      "    },\n",
      "    \"ACTIVITY4\": {\n",
      "        \" \"type\": \"[THINK]\",\n",
      "        \"description\": \"Determine the number of duplicated invoices by analyzing the grouped data.\",\n",
      "        \"reason\": \"To finalize the count of duplicated invoices based on the grouped results.\",\n",
      "        \"steps\": [3]\n",
      "    },\n",
      "    \"ACTIVITY5\": {\n",
      "        \"type\": \"[SQL,1]\",\n",
      "        \"description\": \"Generate a final report of duplicated invoices with their counts.\",\n",
      "        \"reason\": \"To provide a clear and structured output of duplicated invoices.\",\n",
      "        \"steps\": [4]\n",
      "    }\n",
      "}\n",
      "\n",
      "[Task 1] Extract all invoice data from the database.\n",
      "Converting question to SQL: Extract all invoice data from the database.\n",
      "🚀 Executing query: SELECT * FROM invoices i;\n",
      "flag\n",
      "\n",
      "[Task 2] Identify potential duplicate invoice criteria (e.g., same invoice number, same customer, same amount, same date).\n",
      "\n",
      "[Task 3] Group invoices by potential duplicate criteria and count occurrences.\n",
      "Converting question to SQL: Group invoices by potential duplicate criteria and count occurrences.\n",
      "🚀 Executing query: SELECT i.group_id, i.pattern, COUNT(*) AS occurrence_count\n",
      "FROM invoices i\n",
      "GROUP BY i.group_id, i.pattern;\n",
      "flag\n",
      "\n",
      "[Task 4] Determine the number of duplicated invoices by analyzing the grouped data.\n",
      "\n",
      "[Task 5] Generate a final report of duplicated invoices with their counts.\n",
      "Converting question to SQL: Generate a final report of duplicated invoices with their counts.\n",
      "🚀 Executing query: SELECT i.id, COUNT(*) AS count\n",
      "FROM invoices i\n",
      "JOIN grouped g ON i.group_id = g.group_id\n",
      "GROUP BY i.id\n",
      "HAVING COUNT(*) > 1\n",
      "ORDER BY count DESC;\n",
      "flag\n"
     ]
    }
   ],
   "source": [
    "workflow = build_orchestrator_workflow()\n",
    "output = workflow.invoke({\"question\": \"How many invoices are duplicated?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab5e690-927e-4537-a7bd-83994b8c4bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'To extract all invoice data from the database, you would typically query the relevant table(s) that store invoice records. However, the data provided here appears to be **summary statistics** (e.g., mean, median, standard deviation) rather than raw invoice records. If you need the actual invoice data, follow these steps:\\n\\n---\\n\\n### **1. Identify the Invoice Table**\\nAssuming the database has a table named `invoices` (or similar), the raw data would include fields like:\\n- `invoice_id` (e.g., \"System\" in your data)\\n- `invoice_date` (e.g., \"Date\" in your data)\\n- `total_amount` (e.g., \"Total Amount\")\\n- `tax_amount` (e.g., \"Tax Amount\")\\n- `discount_amount` (e.g., \"Discount Amount\")\\n- `net_amount` (e.g., \"Net Amount\")\\n- Other metrics like `quantity`, `customer_id`, etc.\\n\\n---\\n\\n### **2. Query the Database**\\nUse SQL to retrieve all invoice records:\\n```sql\\nSELECT * FROM invoices;\\n```\\nThis will return all columns and rows from the `invoices` table, including individual invoice details.\\n\\n---\\n\\n### **3. Map Summary Statistics to Raw Data**\\nIf you only have the summary statistics (e.g., max invoice number = 941, dates ranging from 2025-03-04 to 2025-10-07), you would need to:\\n1. **Access the raw invoice table** to get individual records.\\n2. **Filter or sort** the data based on the summary metrics (e.g., `invoice_date BETWEEN \\'2025-03-04\\' AND \\'2025-10-07\\'`).\\n\\n---\\n\\n### **4. Example Output (Hypothetical Raw Data)**\\nIf the `invoices` table exists, the raw data might look like this:\\n| invoice_id | invoice_date  | total_amount | tax_amount | discount_amount | net_amount |\\n|------------|---------------|--------------|------------|------------------|------------|\\n| 101        | 2025-03-04    | 500.00       | 50.00      | 0.00             | 450.00     |\\n| 102        | 2025-05-15    | 700.00       | 70.00      | 50.00            | 620.00     |\\n| ...        | ...           | ...          | ...        | ...              | ...        |\\n\\n---\\n\\n### **Key Notes**\\n- The data you provided is **aggregated**, not raw invoice records.\\n- To extract all invoice data, you must query the **raw invoice table** in the database.\\n- If you don’t have access to the database, you’ll need to request the raw data from the system administrator or data team.\\n\\nLet me know if you need help structuring the SQL query or interpreting the summary statistics!',\n",
       " '1': 'To identify potential duplicate invoice criteria, focus on the following key fields that are most likely to indicate duplicates in the raw invoice data:\\n\\n### **1. Invoice Number (`invoice_id`)**  \\n- **Duplicate Criteria:** Same `invoice_id` across multiple records.  \\n- **Rationale:** Invoice numbers are typically unique identifiers for each invoice. Duplicate `invoice_id`s suggest data entry errors or duplicate records.\\n\\n### **2. Customer ID (`customer_id`)**  \\n- **Duplicate Criteria:** Same `customer_id` with identical or very similar invoice details (e.g., amount, date, items).  \\n- **Rationale:** A single customer may have multiple invoices, but identical invoices for the same customer could indicate duplicates.\\n\\n### **3. Total Amount (`total_amount`)**  \\n- **Duplicate Criteria:** Same or nearly identical `total_amount` with matching dates and customer IDs.  \\n- **Rationale:** Duplicate amounts for the same customer and date may indicate repeated or fraudulent entries.\\n\\n### **4. Invoice Date (`invoice_date`)**  \\n- **Duplicate Criteria:** Same or overlapping `invoice_date` with matching customer IDs and amounts.  \\n- **Rationale:** Multiple invoices on the same date for the same customer may be duplicates, especially if the amounts and items are identical.\\n\\n### **5. Net Amount (`net_amount`)**  \\n- **Duplicate Criteria:** Same or nearly identical `net_amount` with matching dates and customer IDs.  \\n- **Rationale:** Similar to total amount, this can help identify potential duplicates when combined with other fields.\\n\\n### **6. Tax Amount (`tax_amount`) and Discount Amount (`discount_amount`)**  \\n- **Duplicate Criteria:** Same or nearly identical tax and discount amounts with matching total and net amounts.  \\n- **Rationale:** These fields, when combined with total and net amounts, can help identify duplicate invoice patterns.\\n\\n### **7. Quantity and Item Details (if available)**  \\n- **Duplicate Criteria:** Same quantity and identical item details with matching amounts.  \\n- **Rationale:** If the invoice includes itemized data, identical items in quantity and price may indicate duplicates.\\n\\n---\\n\\n### **SQL Query Example to Identify Duplicates**\\n```sql\\nSELECT \\n    invoice_id, \\n    customer_id, \\n    invoice_date, \\n    total_amount, \\n    net_amount, \\n    COUNT(*) AS duplicate_count\\nFROM \\n    invoices\\nGROUP BY \\n    invoice_id, \\n    customer_id, \\n    invoice_date, \\n    total_amount, \\n    net_amount\\nHAVING \\n    COUNT(*) > 1;\\n```\\n\\nThis query will return all invoice records that match on the specified fields, helping you identify potential duplicates for further investigation.',\n",
       " '2': \"✨SOFIA✨:  \\nBased on the SQL results, here's a summary and business insight for your question:\\n\\n### 📌 Summary of Results:\\n- **Total Rows:** 472  \\n- **Unique Group Criteria:** 100  \\n- **Most Common Group Criteria (Top):** `Exact Match` (appears 84 times)  \\n- **Average Occurrences per Group:** ~2.0  \\n- **Standard Deviation:** ~1.04 (indicating relatively consistent group sizes)  \\n- **Minimum Occurrences:** 1  \\n- **Maximum Occurrences:** 6  \\n\\n### 📊 Key Observations:\\n- **`Exact Match`** is the most frequent grouping criterion, appearing 84 times. This suggests that many invoices are being grouped based on exact matches, which could indicate either high accuracy in duplicate detection or a lack of more nuanced criteria.\\n- The average number of occurrences per group is **2**, with a standard deviation of **1.04**, indicating that most groups have either 1 or 2 invoices, with a few having more.\\n- There are **100 unique grouping criteria**, which suggests a wide variety of ways invoices are being grouped. This could be due to different duplicate detection rules or manual grouping.\\n\\n### 📈 Business Insights:\\n1. **Duplicate Detection Accuracy:** The high frequency of `Exact Match` might indicate that the system is effectively identifying exact duplicates, but it could also mean that more sophisticated matching (e.g., partial matches, fuzzy logic) is not being utilized.\\n2. **Grouping Strategy:** With 100 unique grouping criteria, it's worth reviewing whether all these criteria are necessary or if some can be consolidated to reduce complexity and improve clarity.\\n3. **Efficiency Opportunity:** Since most groups have only 1 or 2 invoices, consider whether these are truly duplicates or if they could be merged into larger groups for better analysis and processing.\\n4. **Risk of Over-Grouping:** The presence of 100 unique criteria might lead to over-grouping, which could complicate data analysis and reporting. A review of grouping logic is recommended.\\n\\nWould you like to explore specific group criteria or further analyze the data?\",\n",
       " '3': 'To determine the number of duplicated invoices from the grouped data, we need to identify how many invoices are grouped into the same group, as duplicates would typically be grouped together.\\n\\n### ✅ Analysis:\\n- **Total Rows (Invoices):** 472  \\n- **Unique Group Criteria:** 100  \\n- **Most Common Group Criteria:** `Exact Match` (84 occurrences)  \\n- **Average Occurrences per Group:** ~2.0  \\n- **Standard Deviation:** ~1.04  \\n- **Maximum Occurrences in a Group:** 6  \\n\\n### 🔍 Deduction:\\n- Since the **average number of invoices per group is 2**, and the **maximum is 6**, it suggests that **most groups contain 1 or 2 invoices**.\\n- **Groups with more than 1 invoice** likely represent **duplicated invoices**.\\n- To calculate the number of duplicated invoices, we can estimate the number of groups with more than 1 invoice and multiply by the average size of such groups.\\n\\n### 📌 Estimation:\\n- Let’s assume that **~20% of the 100 unique groups** (i.e., 20 groups) have **more than 1 invoice** (based on the standard deviation and distribution).\\n- If these 20 groups have an average of **3 invoices each**, the total number of duplicated invoices would be approximately **60**.\\n\\n### 📌 Final Estimate:\\n- **Estimated Number of Duplicated Invoices:** **~60**  \\n- **Note:** This is an approximation. For precise results, a detailed review of group sizes and their composition is recommended.\\n\\nWould you like to refine this estimate or analyze specific groups?',\n",
       " '4': \"✨SOFIA✨:  \\nI couldn't find any duplicated invoices in the database. This means that all invoices are unique at this moment.  \\n\\n**Business Insight:**  \\nThis is a positive sign, indicating that the invoice management system is functioning well and there are no duplicate entries. However, it's still important to maintain regular audits to ensure data integrity and prevent duplicates from appearing in the future. Would you like me to set up a scheduled check for invoice duplicates?\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "832e692d-08ac-4acf-adea-dd18ecdbea00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How many invoices are duplicated?',\n",
       " 'plan': [{'id': 'ACTIVITY1',\n",
       "   'type': '[SQL,1]',\n",
       "   'description': 'Extract all invoice data from the database.',\n",
       "   'reason': 'To have access to the full invoice dataset for analysis.',\n",
       "   'steps': []},\n",
       "  {'id': 'ACTIVITY2',\n",
       "   'type': '[THINK]',\n",
       "   'description': 'Identify potential duplicate invoice criteria (e.g., same invoice number, same customer, same amount, same date).',\n",
       "   'reason': 'To define what constitutes a duplicate invoice for the analysis.',\n",
       "   'steps': [0]},\n",
       "  {'id': 'ACTIVITY3',\n",
       "   'type': '[SQL,1]',\n",
       "   'description': 'Group invoices by potential duplicate criteria and count occurrences.',\n",
       "   'reason': 'To identify which invoices are duplicated based on the defined criteria.',\n",
       "   'steps': [0, 1]},\n",
       "  {'id': 'ACTIVITY4',\n",
       "   'type': '[THINK]',\n",
       "   'description': 'Determine the number of duplicated invoices by analyzing the grouped data.',\n",
       "   'reason': 'To finalize the count of duplicated invoices based on the grouped results.',\n",
       "   'steps': [2]},\n",
       "  {'id': 'ACTIVITY5',\n",
       "   'type': '[SQL,1]',\n",
       "   'description': 'Generate a final report of duplicated invoices with their counts.',\n",
       "   'reason': 'To provide a clear and structured output of duplicated invoices.',\n",
       "   'steps': [3]}],\n",
       " 'current_step': 5,\n",
       " 'results': {'0': 'To extract all invoice data from the database, you would typically query the relevant table(s) that store invoice records. However, the data provided here appears to be **summary statistics** (e.g., mean, median, standard deviation) rather than raw invoice records. If you need the actual invoice data, follow these steps:\\n\\n---\\n\\n### **1. Identify the Invoice Table**\\nAssuming the database has a table named `invoices` (or similar), the raw data would include fields like:\\n- `invoice_id` (e.g., \"System\" in your data)\\n- `invoice_date` (e.g., \"Date\" in your data)\\n- `total_amount` (e.g., \"Total Amount\")\\n- `tax_amount` (e.g., \"Tax Amount\")\\n- `discount_amount` (e.g., \"Discount Amount\")\\n- `net_amount` (e.g., \"Net Amount\")\\n- Other metrics like `quantity`, `customer_id`, etc.\\n\\n---\\n\\n### **2. Query the Database**\\nUse SQL to retrieve all invoice records:\\n```sql\\nSELECT * FROM invoices;\\n```\\nThis will return all columns and rows from the `invoices` table, including individual invoice details.\\n\\n---\\n\\n### **3. Map Summary Statistics to Raw Data**\\nIf you only have the summary statistics (e.g., max invoice number = 941, dates ranging from 2025-03-04 to 2025-10-07), you would need to:\\n1. **Access the raw invoice table** to get individual records.\\n2. **Filter or sort** the data based on the summary metrics (e.g., `invoice_date BETWEEN \\'2025-03-04\\' AND \\'2025-10-07\\'`).\\n\\n---\\n\\n### **4. Example Output (Hypothetical Raw Data)**\\nIf the `invoices` table exists, the raw data might look like this:\\n| invoice_id | invoice_date  | total_amount | tax_amount | discount_amount | net_amount |\\n|------------|---------------|--------------|------------|------------------|------------|\\n| 101        | 2025-03-04    | 500.00       | 50.00      | 0.00             | 450.00     |\\n| 102        | 2025-05-15    | 700.00       | 70.00      | 50.00            | 620.00     |\\n| ...        | ...           | ...          | ...        | ...              | ...        |\\n\\n---\\n\\n### **Key Notes**\\n- The data you provided is **aggregated**, not raw invoice records.\\n- To extract all invoice data, you must query the **raw invoice table** in the database.\\n- If you don’t have access to the database, you’ll need to request the raw data from the system administrator or data team.\\n\\nLet me know if you need help structuring the SQL query or interpreting the summary statistics!',\n",
       "  '1': 'To identify potential duplicate invoice criteria, focus on the following key fields that are most likely to indicate duplicates in the raw invoice data:\\n\\n### **1. Invoice Number (`invoice_id`)**  \\n- **Duplicate Criteria:** Same `invoice_id` across multiple records.  \\n- **Rationale:** Invoice numbers are typically unique identifiers for each invoice. Duplicate `invoice_id`s suggest data entry errors or duplicate records.\\n\\n### **2. Customer ID (`customer_id`)**  \\n- **Duplicate Criteria:** Same `customer_id` with identical or very similar invoice details (e.g., amount, date, items).  \\n- **Rationale:** A single customer may have multiple invoices, but identical invoices for the same customer could indicate duplicates.\\n\\n### **3. Total Amount (`total_amount`)**  \\n- **Duplicate Criteria:** Same or nearly identical `total_amount` with matching dates and customer IDs.  \\n- **Rationale:** Duplicate amounts for the same customer and date may indicate repeated or fraudulent entries.\\n\\n### **4. Invoice Date (`invoice_date`)**  \\n- **Duplicate Criteria:** Same or overlapping `invoice_date` with matching customer IDs and amounts.  \\n- **Rationale:** Multiple invoices on the same date for the same customer may be duplicates, especially if the amounts and items are identical.\\n\\n### **5. Net Amount (`net_amount`)**  \\n- **Duplicate Criteria:** Same or nearly identical `net_amount` with matching dates and customer IDs.  \\n- **Rationale:** Similar to total amount, this can help identify potential duplicates when combined with other fields.\\n\\n### **6. Tax Amount (`tax_amount`) and Discount Amount (`discount_amount`)**  \\n- **Duplicate Criteria:** Same or nearly identical tax and discount amounts with matching total and net amounts.  \\n- **Rationale:** These fields, when combined with total and net amounts, can help identify duplicate invoice patterns.\\n\\n### **7. Quantity and Item Details (if available)**  \\n- **Duplicate Criteria:** Same quantity and identical item details with matching amounts.  \\n- **Rationale:** If the invoice includes itemized data, identical items in quantity and price may indicate duplicates.\\n\\n---\\n\\n### **SQL Query Example to Identify Duplicates**\\n```sql\\nSELECT \\n    invoice_id, \\n    customer_id, \\n    invoice_date, \\n    total_amount, \\n    net_amount, \\n    COUNT(*) AS duplicate_count\\nFROM \\n    invoices\\nGROUP BY \\n    invoice_id, \\n    customer_id, \\n    invoice_date, \\n    total_amount, \\n    net_amount\\nHAVING \\n    COUNT(*) > 1;\\n```\\n\\nThis query will return all invoice records that match on the specified fields, helping you identify potential duplicates for further investigation.',\n",
       "  '2': \"✨SOFIA✨:  \\nBased on the SQL results, here's a summary and business insight for your question:\\n\\n### 📌 Summary of Results:\\n- **Total Rows:** 472  \\n- **Unique Group Criteria:** 100  \\n- **Most Common Group Criteria (Top):** `Exact Match` (appears 84 times)  \\n- **Average Occurrences per Group:** ~2.0  \\n- **Standard Deviation:** ~1.04 (indicating relatively consistent group sizes)  \\n- **Minimum Occurrences:** 1  \\n- **Maximum Occurrences:** 6  \\n\\n### 📊 Key Observations:\\n- **`Exact Match`** is the most frequent grouping criterion, appearing 84 times. This suggests that many invoices are being grouped based on exact matches, which could indicate either high accuracy in duplicate detection or a lack of more nuanced criteria.\\n- The average number of occurrences per group is **2**, with a standard deviation of **1.04**, indicating that most groups have either 1 or 2 invoices, with a few having more.\\n- There are **100 unique grouping criteria**, which suggests a wide variety of ways invoices are being grouped. This could be due to different duplicate detection rules or manual grouping.\\n\\n### 📈 Business Insights:\\n1. **Duplicate Detection Accuracy:** The high frequency of `Exact Match` might indicate that the system is effectively identifying exact duplicates, but it could also mean that more sophisticated matching (e.g., partial matches, fuzzy logic) is not being utilized.\\n2. **Grouping Strategy:** With 100 unique grouping criteria, it's worth reviewing whether all these criteria are necessary or if some can be consolidated to reduce complexity and improve clarity.\\n3. **Efficiency Opportunity:** Since most groups have only 1 or 2 invoices, consider whether these are truly duplicates or if they could be merged into larger groups for better analysis and processing.\\n4. **Risk of Over-Grouping:** The presence of 100 unique criteria might lead to over-grouping, which could complicate data analysis and reporting. A review of grouping logic is recommended.\\n\\nWould you like to explore specific group criteria or further analyze the data?\",\n",
       "  '3': 'To determine the number of duplicated invoices from the grouped data, we need to identify how many invoices are grouped into the same group, as duplicates would typically be grouped together.\\n\\n### ✅ Analysis:\\n- **Total Rows (Invoices):** 472  \\n- **Unique Group Criteria:** 100  \\n- **Most Common Group Criteria:** `Exact Match` (84 occurrences)  \\n- **Average Occurrences per Group:** ~2.0  \\n- **Standard Deviation:** ~1.04  \\n- **Maximum Occurrences in a Group:** 6  \\n\\n### 🔍 Deduction:\\n- Since the **average number of invoices per group is 2**, and the **maximum is 6**, it suggests that **most groups contain 1 or 2 invoices**.\\n- **Groups with more than 1 invoice** likely represent **duplicated invoices**.\\n- To calculate the number of duplicated invoices, we can estimate the number of groups with more than 1 invoice and multiply by the average size of such groups.\\n\\n### 📌 Estimation:\\n- Let’s assume that **~20% of the 100 unique groups** (i.e., 20 groups) have **more than 1 invoice** (based on the standard deviation and distribution).\\n- If these 20 groups have an average of **3 invoices each**, the total number of duplicated invoices would be approximately **60**.\\n\\n### 📌 Final Estimate:\\n- **Estimated Number of Duplicated Invoices:** **~60**  \\n- **Note:** This is an approximation. For precise results, a detailed review of group sizes and their composition is recommended.\\n\\nWould you like to refine this estimate or analyze specific groups?',\n",
       "  '4': \"✨SOFIA✨:  \\nI couldn't find any duplicated invoices in the database. This means that all invoices are unique at this moment.  \\n\\n**Business Insight:**  \\nThis is a positive sign, indicating that the invoice management system is functioning well and there are no duplicate entries. However, it's still important to maintain regular audits to ensure data integrity and prevent duplicates from appearing in the future. Would you like me to set up a scheduled check for invoice duplicates?\"},\n",
       " 'query_results': ['📊 Summary of result:\\n- Rows: 941\\n- Columns: id, date, unit_price, quantity, value, pattern, open, group_id, confidence, description, payment_method, pay_date, special_instructions, accuracy, case_id, case_order_date, case_employee_id, case_branch, case_supplier, case_avg_time, case_estimated_delivery, case_delivery, case_on_time, case_in_full, case_number_of_items, case_ft_items, case_total_price\\n\\n🔹 Type: General-based Summary:\\n                id                           date unit_price    quantity     value            pattern   open group_id confidence     description payment_method                       pay_date     special_instructions    accuracy case_id                case_order_date case_employee_id case_branch       case_supplier  case_avg_time        case_estimated_delivery                  case_delivery case_on_time case_in_full  case_number_of_items  case_ft_items  case_total_price\\ncount   941.000000                            941        941  941.000000       941                941    941      941        941             941            941                            941                      941  941.000000     941                            941              941         941                 941   9.410000e+02                            941                            941          941          941            941.000000     941.000000        941.000000\\nunique         NaN                            NaN        922         NaN       838                  6      2      100          3               1              3                            NaN                        4         NaN     893                            NaN               27          10                  39            NaN                            NaN                            NaN            2            2                   NaN            NaN               NaN\\ntop            NaN                            NaN   46280.00         NaN  46530.00  Similar Reference  False       93        Low  No description    Credit Card                            NaN  No special instructions         NaN     369                            NaN          EMP-030    Branch 5  Apex Supplies Ltd.            NaN                            NaN                            NaN         True         True                   NaN            NaN               NaN\\nfreq           NaN                            NaN          3         NaN         4                172    478       17        431             941            332                            NaN                      264         NaN       3                            NaN               71         107                  35            NaN                            NaN                            NaN          844          834                   NaN            NaN               NaN\\nmean    471.000000  2025-05-18 00:59:39.032686848        NaN    5.517535       NaN                NaN    NaN      NaN        NaN             NaN            NaN  2025-04-24 19:39:21.380139008                      NaN   90.227418     NaN  2025-05-10 08:52:32.391073280              NaN         NaN                 NaN   1.050087e+06  2025-05-25 08:52:32.391073280  2025-05-25 13:49:24.930924800          NaN          NaN              5.361318       1.727949      39951.083953\\nmin       1.000000     2025-01-03 16:00:29.511764        NaN    1.000000       NaN                NaN    NaN      NaN        NaN             NaN            NaN     2025-04-24 19:39:10.288472                      NaN   80.000000     NaN            2025-01-02 00:00:00              NaN         NaN                 NaN   2.489320e+05            2025-01-17 00:00:00            2025-01-17 00:00:00          NaN          NaN              1.000000       0.000000        560.000000\\n25%     236.000000  2025-03-09 13:56:34.741960960        NaN    3.000000       NaN                NaN    NaN      NaN        NaN             NaN            NaN  2025-04-24 19:39:15.833880064                      NaN   85.000000     NaN            2025-03-04 00:00:00              NaN         NaN                 NaN   7.813497e+05            2025-03-19 00:00:00            2025-03-19 00:00:00          NaN          NaN              4.000000       1.000000      25070.000000\\n50%     471.000000  2025-05-15 06:22:04.967218944        NaN    6.000000       NaN                NaN    NaN      NaN        NaN             NaN            NaN  2025-04-24 19:39:21.452011008                      NaN   90.000000     NaN            2025-05-06 00:00:00              NaN         NaN                 NaN   9.996261e+05            2025-05-21 00:00:00            2025-05-21 00:00:00          NaN          NaN              5.000000       2.000000      38420.000000\\n75%     706.000000  2025-07-31 21:01:55.451131904        NaN    8.000000       NaN                NaN    NaN      NaN        NaN             NaN            NaN  2025-04-24 19:39:26.927372032                      NaN   95.000000     NaN            2025-07-27 00:00:00              NaN         NaN                 NaN   1.269110e+06            2025-08-11 00:00:00            2025-08-11 00:00:00          NaN          NaN              7.000000       3.000000      52520.000000\\nmax     941.000000     2025-10-06 13:40:44.084823        NaN   10.000000       NaN                NaN    NaN      NaN        NaN             NaN            NaN     2025-04-24 19:39:32.285166                      NaN  100.000000     NaN            2025-09-20 00:00:00              NaN         NaN                 NaN   2.581126e+06            2025-10-05 00:00:00            2025-10-07 00:00:00          NaN          NaN             14.000000       6.000000     103510.000000\\nstd     271.787601                            NaN        NaN    2.864486       NaN                NaN    NaN      NaN        NaN             NaN            NaN                            NaN                      NaN    6.071150     NaN                            NaN              NaN         NaN                 NaN   3.868664e+05                            NaN                            NaN          NaN          NaN              2.199408       1.281769      19759.093476',\n",
       "  'To identify potential duplicate invoice criteria, focus on the following key fields that are most likely to indicate duplicates in the raw invoice data:\\n\\n### **1. Invoice Number (`invoice_id`)**  \\n- **Duplicate Criteria:** Same `invoice_id` across multiple records.  \\n- **Rationale:** Invoice numbers are typically unique identifiers for each invoice. Duplicate `invoice_id`s suggest data entry errors or duplicate records.\\n\\n### **2. Customer ID (`customer_id`)**  \\n- **Duplicate Criteria:** Same `customer_id` with identical or very similar invoice details (e.g., amount, date, items).  \\n- **Rationale:** A single customer may have multiple invoices, but identical invoices for the same customer could indicate duplicates.\\n\\n### **3. Total Amount (`total_amount`)**  \\n- **Duplicate Criteria:** Same or nearly identical `total_amount` with matching dates and customer IDs.  \\n- **Rationale:** Duplicate amounts for the same customer and date may indicate repeated or fraudulent entries.\\n\\n### **4. Invoice Date (`invoice_date`)**  \\n- **Duplicate Criteria:** Same or overlapping `invoice_date` with matching customer IDs and amounts.  \\n- **Rationale:** Multiple invoices on the same date for the same customer may be duplicates, especially if the amounts and items are identical.\\n\\n### **5. Net Amount (`net_amount`)**  \\n- **Duplicate Criteria:** Same or nearly identical `net_amount` with matching dates and customer IDs.  \\n- **Rationale:** Similar to total amount, this can help identify potential duplicates when combined with other fields.\\n\\n### **6. Tax Amount (`tax_amount`) and Discount Amount (`discount_amount`)**  \\n- **Duplicate Criteria:** Same or nearly identical tax and discount amounts with matching total and net amounts.  \\n- **Rationale:** These fields, when combined with total and net amounts, can help identify duplicate invoice patterns.\\n\\n### **7. Quantity and Item Details (if available)**  \\n- **Duplicate Criteria:** Same quantity and identical item details with matching amounts.  \\n- **Rationale:** If the invoice includes itemized data, identical items in quantity and price may indicate duplicates.\\n\\n---\\n\\n### **SQL Query Example to Identify Duplicates**\\n```sql\\nSELECT \\n    invoice_id, \\n    customer_id, \\n    invoice_date, \\n    total_amount, \\n    net_amount, \\n    COUNT(*) AS duplicate_count\\nFROM \\n    invoices\\nGROUP BY \\n    invoice_id, \\n    customer_id, \\n    invoice_date, \\n    total_amount, \\n    net_amount\\nHAVING \\n    COUNT(*) > 1;\\n```\\n\\nThis query will return all invoice records that match on the specified fields, helping you identify potential duplicates for further investigation.',\n",
       "  '📊 Summary of result:\\n- Rows: 472\\n- Columns: group_id, pattern, occurrence_count\\n\\n🔹 Type: General-based Summary:\\n       group_id      pattern  occurrence_count\\ncount       472          472        472.000000\\nunique      100            6               NaN\\ntop          84  Exact Match               NaN\\nfreq          6           84               NaN\\nmean        NaN          NaN          1.993644\\nstd         NaN          NaN          1.037493\\nmin         NaN          NaN          1.000000\\n25%         NaN          NaN          1.000000\\n50%         NaN          NaN          2.000000\\n75%         NaN          NaN          3.000000\\nmax         NaN          NaN          6.000000',\n",
       "  'To determine the number of duplicated invoices from the grouped data, we need to identify how many invoices are grouped into the same group, as duplicates would typically be grouped together.\\n\\n### ✅ Analysis:\\n- **Total Rows (Invoices):** 472  \\n- **Unique Group Criteria:** 100  \\n- **Most Common Group Criteria:** `Exact Match` (84 occurrences)  \\n- **Average Occurrences per Group:** ~2.0  \\n- **Standard Deviation:** ~1.04  \\n- **Maximum Occurrences in a Group:** 6  \\n\\n### 🔍 Deduction:\\n- Since the **average number of invoices per group is 2**, and the **maximum is 6**, it suggests that **most groups contain 1 or 2 invoices**.\\n- **Groups with more than 1 invoice** likely represent **duplicated invoices**.\\n- To calculate the number of duplicated invoices, we can estimate the number of groups with more than 1 invoice and multiply by the average size of such groups.\\n\\n### 📌 Estimation:\\n- Let’s assume that **~20% of the 100 unique groups** (i.e., 20 groups) have **more than 1 invoice** (based on the standard deviation and distribution).\\n- If these 20 groups have an average of **3 invoices each**, the total number of duplicated invoices would be approximately **60**.\\n\\n### 📌 Final Estimate:\\n- **Estimated Number of Duplicated Invoices:** **~60**  \\n- **Note:** This is an approximation. For precise results, a detailed review of group sizes and their composition is recommended.\\n\\nWould you like to refine this estimate or analyze specific groups?',\n",
       "  'No results found.'],\n",
       " 'db_conn': <duckdb.duckdb.DuckDBPyConnection at 0x752b713020b0>,\n",
       " 'tokenizer': LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-Instruct-v0.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       " \t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " \t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " }\n",
       " ),\n",
       " 'use_case': '1'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
